{
  "best_global_step": 5427,
  "best_metric": 0.3766483074783845,
  "best_model_checkpoint": "rigorous_experiments/exp_asymmetric_loss_20250903_175621/checkpoint-5427",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5427,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009214042200313277,
      "grad_norm": 26.322357177734375,
      "learning_rate": 8.839779005524863e-07,
      "loss": 15.2876,
      "step": 50
    },
    {
      "epoch": 0.018428084400626554,
      "grad_norm": 19.27958106994629,
      "learning_rate": 1.804788213627993e-06,
      "loss": 12.4933,
      "step": 100
    },
    {
      "epoch": 0.027642126600939832,
      "grad_norm": 16.133298873901367,
      "learning_rate": 2.707182320441989e-06,
      "loss": 7.9077,
      "step": 150
    },
    {
      "epoch": 0.03685616880125311,
      "grad_norm": 18.822757720947266,
      "learning_rate": 3.6279926335174957e-06,
      "loss": 6.0381,
      "step": 200
    },
    {
      "epoch": 0.046070211001566386,
      "grad_norm": 17.561025619506836,
      "learning_rate": 4.5488029465930025e-06,
      "loss": 5.4876,
      "step": 250
    },
    {
      "epoch": 0.055284253201879664,
      "grad_norm": 17.36026954650879,
      "learning_rate": 5.469613259668509e-06,
      "loss": 5.2221,
      "step": 300
    },
    {
      "epoch": 0.06449829540219294,
      "grad_norm": 21.210186004638672,
      "learning_rate": 6.390423572744015e-06,
      "loss": 5.2571,
      "step": 350
    },
    {
      "epoch": 0.07371233760250621,
      "grad_norm": 18.702905654907227,
      "learning_rate": 7.311233885819522e-06,
      "loss": 5.0961,
      "step": 400
    },
    {
      "epoch": 0.0829263798028195,
      "grad_norm": 20.048572540283203,
      "learning_rate": 8.213627992633517e-06,
      "loss": 4.9002,
      "step": 450
    },
    {
      "epoch": 0.09214042200313277,
      "grad_norm": 22.74019432067871,
      "learning_rate": 9.134438305709025e-06,
      "loss": 4.8579,
      "step": 500
    },
    {
      "epoch": 0.10135446420344606,
      "grad_norm": 17.062360763549805,
      "learning_rate": 9.999990690404355e-06,
      "loss": 4.7521,
      "step": 550
    },
    {
      "epoch": 0.11056850640375933,
      "grad_norm": 16.511600494384766,
      "learning_rate": 9.997094652269132e-06,
      "loss": 4.5642,
      "step": 600
    },
    {
      "epoch": 0.1197825486040726,
      "grad_norm": 13.959589958190918,
      "learning_rate": 9.989030065791042e-06,
      "loss": 4.421,
      "step": 650
    },
    {
      "epoch": 0.12899659080438589,
      "grad_norm": 24.414100646972656,
      "learning_rate": 9.975805272257965e-06,
      "loss": 4.3634,
      "step": 700
    },
    {
      "epoch": 0.13821063300469916,
      "grad_norm": 16.95358657836914,
      "learning_rate": 9.957433950215027e-06,
      "loss": 4.3573,
      "step": 750
    },
    {
      "epoch": 0.14742467520501243,
      "grad_norm": 13.908490180969238,
      "learning_rate": 9.933935101316735e-06,
      "loss": 3.8931,
      "step": 800
    },
    {
      "epoch": 0.15663871740532573,
      "grad_norm": 13.987748146057129,
      "learning_rate": 9.90533303067335e-06,
      "loss": 3.9286,
      "step": 850
    },
    {
      "epoch": 0.165852759605639,
      "grad_norm": 16.63077735900879,
      "learning_rate": 9.87165732171187e-06,
      "loss": 3.976,
      "step": 900
    },
    {
      "epoch": 0.17506680180595227,
      "grad_norm": 23.249446868896484,
      "learning_rate": 9.83294280557756e-06,
      "loss": 3.6967,
      "step": 950
    },
    {
      "epoch": 0.18428084400626554,
      "grad_norm": 18.23784637451172,
      "learning_rate": 9.789229525107735e-06,
      "loss": 3.711,
      "step": 1000
    },
    {
      "epoch": 0.19349488620657881,
      "grad_norm": 16.180940628051758,
      "learning_rate": 9.740562693415027e-06,
      "loss": 3.769,
      "step": 1050
    },
    {
      "epoch": 0.2027089284068921,
      "grad_norm": 15.86282730102539,
      "learning_rate": 9.686992647122972e-06,
      "loss": 3.9726,
      "step": 1100
    },
    {
      "epoch": 0.21192297060720539,
      "grad_norm": 22.521766662597656,
      "learning_rate": 9.628574794302312e-06,
      "loss": 3.6802,
      "step": 1150
    },
    {
      "epoch": 0.22113701280751866,
      "grad_norm": 10.326937675476074,
      "learning_rate": 9.56536955716183e-06,
      "loss": 3.5854,
      "step": 1200
    },
    {
      "epoch": 0.23035105500783193,
      "grad_norm": 12.102545738220215,
      "learning_rate": 9.497442309553017e-06,
      "loss": 3.7782,
      "step": 1250
    },
    {
      "epoch": 0.2395650972081452,
      "grad_norm": 27.051681518554688,
      "learning_rate": 9.424863309353197e-06,
      "loss": 3.4337,
      "step": 1300
    },
    {
      "epoch": 0.2487791394084585,
      "grad_norm": 18.572816848754883,
      "learning_rate": 9.347707625797062e-06,
      "loss": 3.442,
      "step": 1350
    },
    {
      "epoch": 0.25799318160877177,
      "grad_norm": 10.93892765045166,
      "learning_rate": 9.266055061831751e-06,
      "loss": 3.498,
      "step": 1400
    },
    {
      "epoch": 0.26720722380908507,
      "grad_norm": 19.211387634277344,
      "learning_rate": 9.17999007157581e-06,
      "loss": 3.5256,
      "step": 1450
    },
    {
      "epoch": 0.2764212660093983,
      "grad_norm": 14.367579460144043,
      "learning_rate": 9.089601672967412e-06,
      "loss": 3.5517,
      "step": 1500
    },
    {
      "epoch": 0.2856353082097116,
      "grad_norm": 17.897367477416992,
      "learning_rate": 8.994983355692131e-06,
      "loss": 3.2153,
      "step": 1550
    },
    {
      "epoch": 0.29484935041002486,
      "grad_norm": 23.75231170654297,
      "learning_rate": 8.896232984485575e-06,
      "loss": 3.5544,
      "step": 1600
    },
    {
      "epoch": 0.30406339261033816,
      "grad_norm": 20.12201499938965,
      "learning_rate": 8.793452697910847e-06,
      "loss": 3.5606,
      "step": 1650
    },
    {
      "epoch": 0.31327743481065146,
      "grad_norm": 14.933423042297363,
      "learning_rate": 8.68674880271553e-06,
      "loss": 3.4991,
      "step": 1700
    },
    {
      "epoch": 0.3224914770109647,
      "grad_norm": 25.775381088256836,
      "learning_rate": 8.576231663877491e-06,
      "loss": 3.4223,
      "step": 1750
    },
    {
      "epoch": 0.331705519211278,
      "grad_norm": 21.400686264038086,
      "learning_rate": 8.462015590453197e-06,
      "loss": 3.2859,
      "step": 1800
    },
    {
      "epoch": 0.34091956141159124,
      "grad_norm": 17.75775718688965,
      "learning_rate": 8.344218717346653e-06,
      "loss": 3.4436,
      "step": 1850
    },
    {
      "epoch": 0.35013360361190454,
      "grad_norm": 18.04353141784668,
      "learning_rate": 8.222962883121196e-06,
      "loss": 3.2958,
      "step": 1900
    },
    {
      "epoch": 0.35934764581221784,
      "grad_norm": 25.654443740844727,
      "learning_rate": 8.09837350398057e-06,
      "loss": 3.4229,
      "step": 1950
    },
    {
      "epoch": 0.3685616880125311,
      "grad_norm": 16.512470245361328,
      "learning_rate": 7.970579444049613e-06,
      "loss": 3.0145,
      "step": 2000
    },
    {
      "epoch": 0.3777757302128444,
      "grad_norm": 19.153711318969727,
      "learning_rate": 7.839712882088715e-06,
      "loss": 3.3801,
      "step": 2050
    },
    {
      "epoch": 0.38698977241315763,
      "grad_norm": 9.881811141967773,
      "learning_rate": 7.705909174779916e-06,
      "loss": 3.243,
      "step": 2100
    },
    {
      "epoch": 0.39620381461347093,
      "grad_norm": 16.365671157836914,
      "learning_rate": 7.569306716726035e-06,
      "loss": 3.1559,
      "step": 2150
    },
    {
      "epoch": 0.4054178568137842,
      "grad_norm": 15.71166706085205,
      "learning_rate": 7.430046797307675e-06,
      "loss": 3.1453,
      "step": 2200
    },
    {
      "epoch": 0.41463189901409747,
      "grad_norm": 13.758679389953613,
      "learning_rate": 7.288273454546091e-06,
      "loss": 3.0555,
      "step": 2250
    },
    {
      "epoch": 0.42384594121441077,
      "grad_norm": 16.168977737426758,
      "learning_rate": 7.1441333261231305e-06,
      "loss": 3.2369,
      "step": 2300
    },
    {
      "epoch": 0.433059983414724,
      "grad_norm": 15.492110252380371,
      "learning_rate": 6.997775497712319e-06,
      "loss": 3.0487,
      "step": 2350
    },
    {
      "epoch": 0.4422740256150373,
      "grad_norm": 21.284442901611328,
      "learning_rate": 6.8493513487779525e-06,
      "loss": 3.4809,
      "step": 2400
    },
    {
      "epoch": 0.4514880678153506,
      "grad_norm": 15.480669021606445,
      "learning_rate": 6.699014396001707e-06,
      "loss": 3.2053,
      "step": 2450
    },
    {
      "epoch": 0.46070211001566386,
      "grad_norm": 20.461637496948242,
      "learning_rate": 6.546920134498681e-06,
      "loss": 3.1901,
      "step": 2500
    },
    {
      "epoch": 0.46991615221597716,
      "grad_norm": 20.148427963256836,
      "learning_rate": 6.393225876987159e-06,
      "loss": 3.1829,
      "step": 2550
    },
    {
      "epoch": 0.4791301944162904,
      "grad_norm": 22.320585250854492,
      "learning_rate": 6.238090591078371e-06,
      "loss": 3.1556,
      "step": 2600
    },
    {
      "epoch": 0.4883442366166037,
      "grad_norm": 18.950090408325195,
      "learning_rate": 6.081674734854603e-06,
      "loss": 3.215,
      "step": 2650
    },
    {
      "epoch": 0.497558278816917,
      "grad_norm": 20.082290649414062,
      "learning_rate": 5.924140090905687e-06,
      "loss": 3.4652,
      "step": 2700
    },
    {
      "epoch": 0.5067723210172302,
      "grad_norm": 20.831581115722656,
      "learning_rate": 5.765649598995544e-06,
      "loss": 3.3544,
      "step": 2750
    },
    {
      "epoch": 0.5159863632175435,
      "grad_norm": 23.233800888061523,
      "learning_rate": 5.606367187531846e-06,
      "loss": 3.1358,
      "step": 2800
    },
    {
      "epoch": 0.5252004054178568,
      "grad_norm": 22.253116607666016,
      "learning_rate": 5.446457604013109e-06,
      "loss": 3.3092,
      "step": 2850
    },
    {
      "epoch": 0.5344144476181701,
      "grad_norm": 22.489377975463867,
      "learning_rate": 5.286086244628601e-06,
      "loss": 3.1477,
      "step": 2900
    },
    {
      "epoch": 0.5436284898184833,
      "grad_norm": 16.141597747802734,
      "learning_rate": 5.125418983187301e-06,
      "loss": 3.1085,
      "step": 2950
    },
    {
      "epoch": 0.5528425320187966,
      "grad_norm": 11.790830612182617,
      "learning_rate": 4.964621999552841e-06,
      "loss": 3.0312,
      "step": 3000
    },
    {
      "epoch": 0.5620565742191099,
      "grad_norm": 21.039661407470703,
      "learning_rate": 4.803861607761904e-06,
      "loss": 3.2271,
      "step": 3050
    },
    {
      "epoch": 0.5712706164194232,
      "grad_norm": 23.716190338134766,
      "learning_rate": 4.643304084003839e-06,
      "loss": 2.9677,
      "step": 3100
    },
    {
      "epoch": 0.5804846586197365,
      "grad_norm": 16.461685180664062,
      "learning_rate": 4.483115494639419e-06,
      "loss": 3.2645,
      "step": 3150
    },
    {
      "epoch": 0.5896987008200497,
      "grad_norm": 14.889370918273926,
      "learning_rate": 4.323461524436643e-06,
      "loss": 3.0324,
      "step": 3200
    },
    {
      "epoch": 0.598912743020363,
      "grad_norm": 14.445113182067871,
      "learning_rate": 4.1645073052011934e-06,
      "loss": 3.0473,
      "step": 3250
    },
    {
      "epoch": 0.6081267852206763,
      "grad_norm": 24.842529296875,
      "learning_rate": 4.0064172449788674e-06,
      "loss": 3.1886,
      "step": 3300
    },
    {
      "epoch": 0.6173408274209896,
      "grad_norm": 16.077381134033203,
      "learning_rate": 3.849354858006562e-06,
      "loss": 3.3464,
      "step": 3350
    },
    {
      "epoch": 0.6265548696213029,
      "grad_norm": 17.731971740722656,
      "learning_rate": 3.6934825955877684e-06,
      "loss": 3.1148,
      "step": 3400
    },
    {
      "epoch": 0.6357689118216161,
      "grad_norm": 16.638668060302734,
      "learning_rate": 3.5389616780674416e-06,
      "loss": 3.234,
      "step": 3450
    },
    {
      "epoch": 0.6449829540219294,
      "grad_norm": 20.849836349487305,
      "learning_rate": 3.3859519280800878e-06,
      "loss": 2.8975,
      "step": 3500
    },
    {
      "epoch": 0.6541969962222427,
      "grad_norm": 22.537906646728516,
      "learning_rate": 3.234611605243496e-06,
      "loss": 2.8059,
      "step": 3550
    },
    {
      "epoch": 0.663411038422556,
      "grad_norm": 16.305587768554688,
      "learning_rate": 3.0850972424691384e-06,
      "loss": 3.0426,
      "step": 3600
    },
    {
      "epoch": 0.6726250806228693,
      "grad_norm": 21.446430206298828,
      "learning_rate": 2.9375634840584967e-06,
      "loss": 2.8826,
      "step": 3650
    },
    {
      "epoch": 0.6818391228231825,
      "grad_norm": 17.032642364501953,
      "learning_rate": 2.792162925752821e-06,
      "loss": 3.0271,
      "step": 3700
    },
    {
      "epoch": 0.6910531650234958,
      "grad_norm": 18.0098819732666,
      "learning_rate": 2.649045956901717e-06,
      "loss": 2.9561,
      "step": 3750
    },
    {
      "epoch": 0.7002672072238091,
      "grad_norm": 18.47528076171875,
      "learning_rate": 2.5083606049138463e-06,
      "loss": 2.9035,
      "step": 3800
    },
    {
      "epoch": 0.7094812494241224,
      "grad_norm": 21.97574806213379,
      "learning_rate": 2.3702523821505854e-06,
      "loss": 3.0896,
      "step": 3850
    },
    {
      "epoch": 0.7186952916244357,
      "grad_norm": 19.258520126342773,
      "learning_rate": 2.2348641354210415e-06,
      "loss": 3.041,
      "step": 3900
    },
    {
      "epoch": 0.7279093338247489,
      "grad_norm": 19.386245727539062,
      "learning_rate": 2.1023358982340824e-06,
      "loss": 2.9802,
      "step": 3950
    },
    {
      "epoch": 0.7371233760250622,
      "grad_norm": 15.724126815795898,
      "learning_rate": 1.972804745960166e-06,
      "loss": 2.7304,
      "step": 4000
    },
    {
      "epoch": 0.7463374182253755,
      "grad_norm": 16.17937469482422,
      "learning_rate": 1.8464046540528408e-06,
      "loss": 3.1403,
      "step": 4050
    },
    {
      "epoch": 0.7555514604256888,
      "grad_norm": 18.906700134277344,
      "learning_rate": 1.723266359476483e-06,
      "loss": 3.0571,
      "step": 4100
    },
    {
      "epoch": 0.7647655026260021,
      "grad_norm": 15.951338768005371,
      "learning_rate": 1.6035172254836784e-06,
      "loss": 3.048,
      "step": 4150
    },
    {
      "epoch": 0.7739795448263153,
      "grad_norm": 20.38833999633789,
      "learning_rate": 1.4872811098820378e-06,
      "loss": 3.0761,
      "step": 4200
    },
    {
      "epoch": 0.7831935870266286,
      "grad_norm": 21.067096710205078,
      "learning_rate": 1.3746782369267519e-06,
      "loss": 2.9719,
      "step": 4250
    },
    {
      "epoch": 0.7924076292269419,
      "grad_norm": 14.170092582702637,
      "learning_rate": 1.2658250729713517e-06,
      "loss": 2.9359,
      "step": 4300
    },
    {
      "epoch": 0.8016216714272552,
      "grad_norm": 14.191234588623047,
      "learning_rate": 1.1608342060053267e-06,
      "loss": 2.9654,
      "step": 4350
    },
    {
      "epoch": 0.8108357136275685,
      "grad_norm": 20.12967300415039,
      "learning_rate": 1.059814229203157e-06,
      "loss": 2.868,
      "step": 4400
    },
    {
      "epoch": 0.8200497558278816,
      "grad_norm": 16.963319778442383,
      "learning_rate": 9.628696286052403e-07,
      "loss": 2.8694,
      "step": 4450
    },
    {
      "epoch": 0.8292637980281949,
      "grad_norm": 6.1350860595703125,
      "learning_rate": 8.70100675046856e-07,
      "loss": 2.9132,
      "step": 4500
    },
    {
      "epoch": 0.8384778402285082,
      "grad_norm": 21.496553421020508,
      "learning_rate": 7.816033204469825e-07,
      "loss": 2.9822,
      "step": 4550
    },
    {
      "epoch": 0.8476918824288215,
      "grad_norm": 19.643386840820312,
      "learning_rate": 6.974690985641891e-07,
      "loss": 3.129,
      "step": 4600
    },
    {
      "epoch": 0.8569059246291348,
      "grad_norm": 26.723554611206055,
      "learning_rate": 6.177850303223059e-07,
      "loss": 2.9883,
      "step": 4650
    },
    {
      "epoch": 0.866119966829448,
      "grad_norm": 17.80628776550293,
      "learning_rate": 5.426335338037409e-07,
      "loss": 2.9441,
      "step": 4700
    },
    {
      "epoch": 0.8753340090297613,
      "grad_norm": 18.371112823486328,
      "learning_rate": 4.720923390035886e-07,
      "loss": 2.9716,
      "step": 4750
    },
    {
      "epoch": 0.8845480512300746,
      "grad_norm": 18.32879638671875,
      "learning_rate": 4.0623440743265575e-07,
      "loss": 2.87,
      "step": 4800
    },
    {
      "epoch": 0.8937620934303879,
      "grad_norm": 28.00373077392578,
      "learning_rate": 3.4630300716694985e-07,
      "loss": 3.07,
      "step": 4850
    },
    {
      "epoch": 0.9029761356307012,
      "grad_norm": 22.034379959106445,
      "learning_rate": 2.899141613720502e-07,
      "loss": 3.1045,
      "step": 4900
    },
    {
      "epoch": 0.9121901778310144,
      "grad_norm": 20.920021057128906,
      "learning_rate": 2.383970076402503e-07,
      "loss": 3.0547,
      "step": 4950
    },
    {
      "epoch": 0.9214042200313277,
      "grad_norm": 17.634361267089844,
      "learning_rate": 1.9180483071359946e-07,
      "loss": 3.0413,
      "step": 5000
    },
    {
      "epoch": 0.930618262231641,
      "grad_norm": 16.793806076049805,
      "learning_rate": 1.5018582137806548e-07,
      "loss": 2.8588,
      "step": 5050
    },
    {
      "epoch": 0.9398323044319543,
      "grad_norm": 17.559322357177734,
      "learning_rate": 1.1358302661928722e-07,
      "loss": 2.9628,
      "step": 5100
    },
    {
      "epoch": 0.9490463466322676,
      "grad_norm": 16.86149787902832,
      "learning_rate": 8.203430509861998e-08,
      "loss": 3.006,
      "step": 5150
    },
    {
      "epoch": 0.9582603888325808,
      "grad_norm": 22.98859977722168,
      "learning_rate": 5.557228799551395e-08,
      "loss": 3.0559,
      "step": 5200
    },
    {
      "epoch": 0.9674744310328941,
      "grad_norm": 14.483688354492188,
      "learning_rate": 3.422434525674201e-08,
      "loss": 2.812,
      "step": 5250
    },
    {
      "epoch": 0.9766884732332074,
      "grad_norm": 14.479398727416992,
      "learning_rate": 1.8012557287367394e-08,
      "loss": 2.9124,
      "step": 5300
    },
    {
      "epoch": 0.9859025154335207,
      "grad_norm": 19.65667152404785,
      "learning_rate": 6.953692112748877e-09,
      "loss": 2.8965,
      "step": 5350
    },
    {
      "epoch": 0.995116557633834,
      "grad_norm": 18.34380531311035,
      "learning_rate": 1.0591880351895623e-09,
      "loss": 2.9377,
      "step": 5400
    },
    {
      "epoch": 1.0,
      "eval_avg_preds_t1": 25.225396240324365,
      "eval_avg_preds_t2": 8.96129745669001,
      "eval_avg_preds_t3": 3.962956137117582,
      "eval_avg_preds_t4": 2.2263177294507925,
      "eval_avg_preds_t5": 1.4342056763730189,
      "eval_avg_preds_t6": 0.8862882417987468,
      "eval_avg_preds_t7": 0.488573534832289,
      "eval_avg_preds_t8": 0.20438628824179875,
      "eval_avg_preds_t9": 0.05068190195355695,
      "eval_class_imbalance_ratio": 135.84616088867188,
      "eval_f1_admiration": 0.5034373347435219,
      "eval_f1_amusement": 0.7579787234042553,
      "eval_f1_anger": 0.33707865168539325,
      "eval_f1_annoyance": 0.2718544719555331,
      "eval_f1_approval": 0.2860770207363521,
      "eval_f1_caring": 0.3234567901234568,
      "eval_f1_confusion": 0.30414746543778803,
      "eval_f1_curiosity": 0.468,
      "eval_f1_desire": 0.3253333333333333,
      "eval_f1_disappointment": 0.20967741935483872,
      "eval_f1_disapproval": 0.336283185840708,
      "eval_f1_disgust": 0.25859247135842883,
      "eval_f1_embarrassment": 0.3010752688172043,
      "eval_f1_excitement": 0.2127659574468085,
      "eval_f1_fear": 0.48322147651006714,
      "eval_f1_gratitude": 0.7649667405764967,
      "eval_f1_grief": 0.13333333333333333,
      "eval_f1_joy": 0.34022988505747126,
      "eval_f1_love": 0.6995645863570392,
      "eval_f1_macro": 0.3766483074783845,
      "eval_f1_macro_t1": 0.07932458903134665,
      "eval_f1_macro_t2": 0.19512459269339377,
      "eval_f1_macro_t3": 0.3766483074783845,
      "eval_f1_macro_t4": 0.46266565734099663,
      "eval_f1_macro_t5": 0.490365978278505,
      "eval_f1_macro_t6": 0.43896101688834227,
      "eval_f1_macro_t7": 0.31987282339797674,
      "eval_f1_macro_t8": 0.14717933478928877,
      "eval_f1_macro_t9": 0.03315243532634837,
      "eval_f1_micro": 0.41380052361654057,
      "eval_f1_micro_t1": 0.08903129428354031,
      "eval_f1_micro_t2": 0.22700167260562867,
      "eval_f1_micro_t3": 0.41380052361654057,
      "eval_f1_micro_t4": 0.5503791982665223,
      "eval_f1_micro_t5": 0.6116367744668832,
      "eval_f1_micro_t6": 0.5939762266511752,
      "eval_f1_micro_t7": 0.47945963902114935,
      "eval_f1_micro_t8": 0.2707971691814661,
      "eval_f1_micro_t9": 0.08174305033809166,
      "eval_f1_nervousness": 0.20952380952380953,
      "eval_f1_neutral": 0.5719436250409702,
      "eval_f1_optimism": 0.36465324384787473,
      "eval_f1_pride": 0.43243243243243246,
      "eval_f1_realization": 0.13503649635036497,
      "eval_f1_relief": 0.16216216216216217,
      "eval_f1_remorse": 0.6428571428571429,
      "eval_f1_sadness": 0.3409395973154362,
      "eval_f1_surprise": 0.3695299837925446,
      "eval_f1_weighted": 0.46606923345346435,
      "eval_f1_weighted_t1": 0.2041876870447016,
      "eval_f1_weighted_t2": 0.3103886370492102,
      "eval_f1_weighted_t3": 0.46606923345346435,
      "eval_f1_weighted_t4": 0.5633170939163171,
      "eval_f1_weighted_t5": 0.6001805594079286,
      "eval_f1_weighted_t6": 0.5588165813097539,
      "eval_f1_weighted_t7": 0.4285892605359186,
      "eval_f1_weighted_t8": 0.21784879235199556,
      "eval_f1_weighted_t9": 0.050577374306418885,
      "eval_loss": 1.430518627166748,
      "eval_precision_admiration": 0.33927298645759085,
      "eval_precision_amusement": 0.6347438752783965,
      "eval_precision_anger": 0.21045918367346939,
      "eval_precision_annoyance": 0.16050119331742244,
      "eval_precision_approval": 0.17192268565615462,
      "eval_precision_caring": 0.1993911719939117,
      "eval_precision_confusion": 0.18435754189944134,
      "eval_precision_curiosity": 0.31117021276595747,
      "eval_precision_desire": 0.20469798657718122,
      "eval_precision_disappointment": 0.12070566388115135,
      "eval_precision_disapproval": 0.20985556499575192,
      "eval_precision_disgust": 0.15369649805447472,
      "eval_precision_embarrassment": 0.18543046357615894,
      "eval_precision_excitement": 0.12315270935960591,
      "eval_precision_fear": 0.34615384615384615,
      "eval_precision_gratitude": 0.6341911764705882,
      "eval_precision_grief": 0.11764705882352941,
      "eval_precision_joy": 0.21203438395415472,
      "eval_precision_love": 0.551487414187643,
      "eval_precision_macro": 0.26164746336505457,
      "eval_precision_macro_t1": 0.04402995334539196,
      "eval_precision_macro_t2": 0.11404649529309666,
      "eval_precision_macro_t3": 0.26164746336505457,
      "eval_precision_macro_t4": 0.39763477972679967,
      "eval_precision_macro_t5": 0.4824646910282976,
      "eval_precision_macro_t6": 0.5821123285959882,
      "eval_precision_macro_t7": 0.5926894486726573,
      "eval_precision_macro_t8": 0.43086781116913914,
      "eval_precision_macro_t9": 0.07102118413905487,
      "eval_precision_micro": 0.26828814584011534,
      "eval_precision_micro_t1": 0.04659063511430304,
      "eval_precision_micro_t2": 0.128393385982231,
      "eval_precision_micro_t3": 0.26828814584011534,
      "eval_precision_micro_t4": 0.4205298013245033,
      "eval_precision_micro_t5": 0.5565407350295554,
      "eval_precision_micro_t6": 0.6909960490746517,
      "eval_precision_micro_t7": 0.8166729536024142,
      "eval_precision_micro_t8": 0.9143372407574392,
      "eval_precision_micro_t9": 0.9890909090909091,
      "eval_precision_nervousness": 0.13095238095238096,
      "eval_precision_neutral": 0.40244464944649444,
      "eval_precision_optimism": 0.23795620437956205,
      "eval_precision_pride": 0.36363636363636365,
      "eval_precision_realization": 0.07636738906088751,
      "eval_precision_relief": 0.10714285714285714,
      "eval_precision_remorse": 0.4921875,
      "eval_precision_sadness": 0.21096345514950166,
      "eval_precision_surprise": 0.2336065573770492,
      "eval_prediction_entropy": 8.09379768371582,
      "eval_recall_admiration": 0.9754098360655737,
      "eval_recall_amusement": 0.9405940594059405,
      "eval_recall_anger": 0.8461538461538461,
      "eval_recall_annoyance": 0.8877887788778878,
      "eval_recall_approval": 0.8513853904282116,
      "eval_recall_caring": 0.8562091503267973,
      "eval_recall_confusion": 0.868421052631579,
      "eval_recall_curiosity": 0.9435483870967742,
      "eval_recall_desire": 0.7922077922077922,
      "eval_recall_disappointment": 0.7975460122699386,
      "eval_recall_disapproval": 0.8458904109589042,
      "eval_recall_disgust": 0.8144329896907216,
      "eval_recall_embarrassment": 0.8,
      "eval_recall_excitement": 0.78125,
      "eval_recall_fear": 0.8,
      "eval_recall_gratitude": 0.9636871508379888,
      "eval_recall_grief": 0.15384615384615385,
      "eval_recall_joy": 0.8604651162790697,
      "eval_recall_love": 0.9563492063492064,
      "eval_recall_macro": 0.7919519686545907,
      "eval_recall_macro_t1": 0.9973727940020893,
      "eval_recall_macro_t2": 0.9301283836193195,
      "eval_recall_macro_t3": 0.7919519686545907,
      "eval_recall_macro_t4": 0.641044880183652,
      "eval_recall_macro_t5": 0.5257484248928506,
      "eval_recall_macro_t6": 0.3942326535722769,
      "eval_recall_macro_t7": 0.2485054157061613,
      "eval_recall_macro_t8": 0.10794915288688876,
      "eval_recall_macro_t9": 0.0276384296735454,
      "eval_recall_micro": 0.9042319749216301,
      "eval_recall_micro_t1": 0.9995297805642633,
      "eval_recall_micro_t2": 0.9785266457680251,
      "eval_recall_micro_t3": 0.9042319749216301,
      "eval_recall_micro_t4": 0.7962382445141066,
      "eval_recall_micro_t5": 0.6788401253918496,
      "eval_recall_micro_t6": 0.520846394984326,
      "eval_recall_micro_t7": 0.3393416927899687,
      "eval_recall_micro_t8": 0.15893416927899687,
      "eval_recall_micro_t9": 0.042633228840125395,
      "eval_recall_nervousness": 0.5238095238095238,
      "eval_recall_neutral": 0.9881087202718006,
      "eval_recall_optimism": 0.7799043062200957,
      "eval_recall_pride": 0.5333333333333333,
      "eval_recall_realization": 0.5826771653543307,
      "eval_recall_relief": 0.3333333333333333,
      "eval_recall_remorse": 0.9264705882352942,
      "eval_recall_sadness": 0.8881118881118881,
      "eval_recall_surprise": 0.8837209302325582,
      "eval_runtime": 144.548,
      "eval_samples_per_second": 37.538,
      "eval_steps_per_second": 18.769,
      "step": 5427
    }
  ],
  "logging_steps": 50,
  "max_steps": 5427,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.022948375939072e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
