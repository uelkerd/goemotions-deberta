{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b002030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  2 22:03:23 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:C1:00.0 Off |                  N/A |\n",
      "| 30%   26C    P8             38W /  350W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  |   00000000:C2:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8             40W /  350W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install torch==2.3.1+cu118 torchvision==0.18.1+cu118 torchaudio==2.3.1+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip -q install \"transformers>=4.44\" \"accelerate>=0.31\" \"datasets>=2.20\" \"evaluate\" \"scikit-learn\" \"peft>=0.11\" \"tensorboard\" \"pyarrow<18\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be63cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4222739976.py, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 55\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"Assumes JSONL with {\"text\": str, \"labels\": List[int]} per line; labels are multi-hot.\"\"\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Write train_samo.py to the working directory\n",
    "SCRIPT_PATH = \"train_samo.py\"\n",
    "SCRIPT_CONTENT = r\"\"\"#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# SAMO - GoEmotions Multi-Label Trainer (2x3090-ready)\n",
    "#\n",
    "# Launch examples (2 GPUs):\n",
    "#   accelerate launch --num_processes=2 --mixed_precision=fp16 \\\n",
    "#     train_samo.py --train_json /path/train.jsonl --val_json /path/val.jsonl \\\n",
    "#     --output_dir ./samo_out --thresholds_json ./optimal_thresholds.json\n",
    "#\n",
    "# Or with torchrun:\n",
    "#   torchrun --standalone --nproc_per_node=2 train_samo.py \\\n",
    "#     --train_json /path/train.jsonl --val_json /path/val.jsonl\n",
    "import os, json, random, argparse, warnings\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def set_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def enable_tf32():\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "class JsonlMultiLabelDataset(Dataset):\n",
    "    \"\"\"Assumes JSONL with {\"text\": str, \"labels\": List[int]} per line; labels are multi-hot.\"\"\"\n",
    "    def __init__(self, path: str, tokenizer, max_length: int):\n",
    "        self.examples = []\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                obj = json.loads(line)\n",
    "                text = obj.get(\"text\", None)\n",
    "                labels = obj.get(\"labels\", None)\n",
    "                if text is None or labels is None:\n",
    "                    continue\n",
    "                self.examples.append({\"text\": text, \"labels\": labels})\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.examples[idx]\n",
    "        enc = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        labels = torch.tensor(item[\"labels\"], dtype=torch.float)\n",
    "        enc[\"labels\"] = labels\n",
    "        return enc\n",
    "\n",
    "\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_pos=0.0, gamma_neg=4.0, clip=0.05, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.clip = clip\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        x = torch.sigmoid(logits)\n",
    "        if self.clip and self.clip > 0:\n",
    "            x = (x - self.clip).clamp(min=0) / (1 - self.clip)\n",
    "        xs_pos = x\n",
    "        xs_neg = 1 - x\n",
    "        pos_loss = targets * torch.log(xs_pos.clamp(min=self.eps)) * ((1 - xs_pos) ** self.gamma_pos)\n",
    "        neg_loss = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps)) * (xs_pos ** self.gamma_neg)\n",
    "        loss = -(pos_loss + neg_loss)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class ASLTrainer(Trainer):\n",
    "    \"\"\"Trainer subclass with ASL and optional class-balanced positive weighting.\"\"\"\n",
    "    def __init__(self, *args, class_weights: torch.Tensor | None = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.criterion = AsymmetricLoss(gamma_pos=0.0, gamma_neg=4.0, clip=0.05)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = self.criterion(logits, labels)\n",
    "        if self.class_weights is not None:\n",
    "            pos_mask = (labels > 0.5).float()\n",
    "            cw = self.class_weights.to(logits.device)\n",
    "            weights = 1.0 + pos_mask * (cw - 1.0)  # emphasize positives of rare classes\n",
    "            loss = (loss * weights.mean(dim=1)).mean()\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "def compute_thresholded_metrics(logits: np.ndarray, y_true: np.ndarray, thresholds: np.ndarray):\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    y_pred = (probs >= thresholds[None, :]).astype(int)\n",
    "    f1_micro = f1_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    per_class = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
    "    return f1_micro, f1_macro, per_class\n",
    "\n",
    "\n",
    "def effective_num_weights(pos_counts: np.ndarray, beta: float = 0.999) -> np.ndarray:\n",
    "    eff_num = 1.0 - np.power(beta, pos_counts)\n",
    "    w = (1.0 - beta) / np.maximum(eff_num, 1e-8)\n",
    "    return w / (w.mean() + 1e-12)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"microsoft/deberta-v3-large\")\n",
    "    parser.add_argument(\"--train_json\", type=str, required=True)\n",
    "    parser.add_argument(\"--val_json\", type=str, required=True)\n",
    "    parser.add_argument(\"--max_length\", type=int, default=160)\n",
    "\n",
    "    parser.add_argument(\"--use_lora\", type=lambda x: str(x).lower() == 'true', default=True)\n",
    "    parser.add_argument(\"--lora_r\", type=int, default=16)\n",
    "    parser.add_argument(\"--lora_alpha\", type=int, default=32)\n",
    "    parser.add_argument(\"--lora_dropout\", type=float, default=0.1)\n",
    "\n",
    "    parser.add_argument(\"--per_device_train_batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=2)\n",
    "    parser.add_argument(\"--num_train_epochs\", type=int, default=4)\n",
    "\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=2e-5)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=0.01)\n",
    "    parser.add_argument(\"--lr_scheduler_type\", type=str, default=\"cosine\")\n",
    "    parser.add_argument(\"--warmup_ratio\", type=float, default=0.1)\n",
    "\n",
    "    parser.add_argument(\"--fp16\", type=lambda x: str(x).lower() == 'true', default=True)\n",
    "    parser.add_argument(\"--tf32\", type=lambda x: str(x).lower() == 'true', default=True)\n",
    "    parser.add_argument(\"--gradient_checkpointing\", type=lambda x: str(x).lower() == 'true', default=True)\n",
    "\n",
    "    parser.add_argument(\"--ddp_backend\", type=str, default=\"nccl\")\n",
    "\n",
    "    parser.add_argument(\"--thresholds_json\", type=str, default=None)\n",
    "    parser.add_argument(\"--min_threshold\", type=float, default=0.25)\n",
    "\n",
    "    parser.add_argument(\"--oversample_rare\", type=lambda x: str(x).lower() == 'true', default=True)\n",
    "    parser.add_argument(\"--effective_beta\", type=float, default=0.999)\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--output_dir\", type=str, default=\"./samo_out\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    set_seeds(args.seed)\n",
    "    if args.tf32:\n",
    "        enable_tf32()\n",
    "\n",
    "    os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name, use_fast=True)\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        args.model_name,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "    )\n",
    "\n",
    "    train_ds = JsonlMultiLabelDataset(args.train_json, tokenizer, args.max_length)\n",
    "    val_ds = JsonlMultiLabelDataset(args.val_json, tokenizer, args.max_length)\n",
    "\n",
    "    # Infer num_labels from first sample\n",
    "    first_labels = train_ds[0][\"labels\"]\n",
    "    num_labels = int(first_labels.numel())\n",
    "    config.num_labels = num_labels\n",
    "    id2label = {i: f\"label_{i}\" for i in range(num_labels)}\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "    config.id2label = id2label\n",
    "    config.label2id = label2id\n",
    "\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        args.model_name, config=config\n",
    "    )\n",
    "\n",
    "    model = base_model\n",
    "    if args.use_lora:\n",
    "        try:\n",
    "            from peft import LoraConfig, get_peft_model, TaskType\n",
    "            lcfg = LoraConfig(\n",
    "                r=args.lora_r,\n",
    "                lora_alpha=args.lora_alpha,\n",
    "                lora_dropout=args.lora_dropout,\n",
    "                bias=\"none\",\n",
    "                task_type=TaskType.SEQ_CLS,\n",
    "                target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"dense\"],\n",
    "            )\n",
    "            model = get_peft_model(base_model, lcfg)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"PEFT not available or failed ({e}); using base model\")\n",
    "\n",
    "    # Build label stats for class-balanced weights and oversampling\n",
    "    train_labels = []\n",
    "    for i in range(len(train_ds)):\n",
    "        train_labels.append(train_ds[i][\"labels\"].numpy())\n",
    "    Yt = np.stack(train_labels)  # [N, C]\n",
    "    pos_counts = Yt.sum(axis=0)  # [C]\n",
    "\n",
    "    class_w = effective_num_weights(pos_counts, beta=args.effective_beta)\n",
    "    class_w_t = torch.tensor(class_w, dtype=torch.float)\n",
    "\n",
    "    example_weights = (Yt * (1.0 / np.maximum(pos_counts, 1))).sum(axis=1)\n",
    "    example_weights = example_weights / (example_weights.mean() + 1e-8)\n",
    "\n",
    "    sampler = None\n",
    "    if args.oversample_rare:\n",
    "        sampler = WeightedRandomSampler(weights=example_weights, num_samples=len(example_weights), replacement=True)\n",
    "\n",
    "    collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # Patch Trainer dataloader to inject our sampler\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.args.per_device_train_batch_size,\n",
    "            sampler=(sampler if sampler is not None else None),\n",
    "            shuffle=(sampler is None),\n",
    "            collate_fn=self.data_collator,\n",
    "            drop_last=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    ASLTrainer.get_train_dataloader = get_train_dataloader\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=args.output_dir,\n",
    "        per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
    "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "        learning_rate=args.learning_rate,\n",
    "        lr_scheduler_type=args.lr_scheduler_type,\n",
    "        warmup_ratio=args.warmup_ratio,\n",
    "        num_train_epochs=args.num_train_epochs,\n",
    "        weight_decay=args.weight_decay,\n",
    "        fp16=args.fp16,\n",
    "        tf32=args.tf32,\n",
    "        gradient_checkpointing=args.gradient_checkpointing,\n",
    "        logging_steps=100,\n",
    "        save_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True,\n",
    "        ddp_backend=args.ddp_backend,\n",
    "        ddp_find_unused_parameters=False,\n",
    "        report_to=[\"tensorboard\"],\n",
    "    )\n",
    "\n",
    "    trainer = ASLTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tokenizer,\n",
    "        class_weights=class_w_t,\n",
    "    )\n",
    "\n",
    "    train_out = trainer.train()\n",
    "    trainer.save_model(args.output_dir)\n",
    "\n",
    "    eval_out = trainer.predict(val_ds)\n",
    "    logits = eval_out.predictions  # [N, C]\n",
    "    y_true = np.stack([val_ds[i][\"labels\"].numpy() for i in range(len(val_ds))])\n",
    "\n",
    "    if args.thresholds_json and os.path.exists(args.thresholds_json):\n",
    "        with open(args.thresholds_json, \"r\") as f:\n",
    "            thr = json.load(f)\n",
    "        thr = np.asarray(thr, dtype=np.float32)\n",
    "        if thr.shape[0] != logits.shape[1]:\n",
    "            warnings.warn(\"Thresholds length mismatch - falling back to 0.4\")\n",
    "            thr = np.full((logits.shape[1],), 0.4, dtype=np.float32)\n",
    "    else:\n",
    "        thr = np.full((logits.shape[1],), 0.4, dtype=np.float32)\n",
    "\n",
    "    thr = np.maximum(thr, args.min_threshold)\n",
    "\n",
    "    grid = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "    print(\"\\nPerformance at Different Thresholds:\")\n",
    "    print(\"Threshold  F1 Micro     F1 Macro\")\n",
    "    best_macro, best_t = -1, None\n",
    "    for t in grid:\n",
    "        tvec = np.maximum(np.full_like(thr, t), args.min_threshold)\n",
    "        f1_micro, f1_macro, _ = compute_thresholded_metrics(logits, y_true, tvec)\n",
    "        print(f\"{t:<10} {f1_micro:>8.4f}    {f1_macro:>8.4f}\")\n",
    "        if f1_macro > best_macro:\n",
    "            best_macro, best_t = f1_macro, tvec.copy()\n",
    "\n",
    "    f1_micro, f1_macro, per_class = compute_thresholded_metrics(logits, y_true, best_t)\n",
    "    print(\"\\nBest: f1_micro=%.4f, f1_macro=%.4f\" % (f1_micro, f1_macro))\n",
    "\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    with open(os.path.join(args.output_dir, \"optimal_thresholds.json\"), \"w\") as f:\n",
    "        json.dump(best_t.tolist(), f)\n",
    "\n",
    "    per_prec, per_rec, per_f1, per_support = per_class\n",
    "    report = {\n",
    "        \"f1_micro\": float(f1_micro),\n",
    "        \"f1_macro\": float(f1_macro),\n",
    "        \"per_class\": {\n",
    "            f\"label_{i}\": {\n",
    "                \"precision\": float(per_prec[i]),\n",
    "                \"recall\": float(per_rec[i]),\n",
    "                \"f1\": float(per_f1[i]),\n",
    "                \"support\": int(per_support[i]),\n",
    "            } for i in range(len(per_f1))\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(args.output_dir, \"eval_report.json\"), \"w\") as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "\n",
    "    print(\"\\nSaved:\")\n",
    "    print(\"  -\", os.path.join(args.output_dir, \"pytorch_model.bin\"))\n",
    "    print(\"  -\", os.path.join(args.output_dir, \"optimal_thresholds.json\"))\n",
    "    print(\"  -\", os.path.join(args.output_dir, \"eval_report.json\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "open(SCRIPT_PATH, \"w\", encoding=\"utf-8\").write(SCRIPT_CONTENT)\n",
    "import os, hashlib\n",
    "print(\"Wrote\", SCRIPT_PATH, \"size:\", os.path.getsize(SCRIPT_PATH), \"bytes\")\n",
    "print(\"sha256:\", hashlib.sha256(SCRIPT_CONTENT.encode()).hexdigest())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "accelerate config default\n",
    "python - <<'PY'\n",
    "from pathlib import Path\n",
    "p = Path(\"~/.cache/huggingface/accelerate/default_config.yaml\").expanduser()\n",
    "txt = p.read_text()\n",
    "txt = txt.replace(\"distributed_type: NO\", \"distributed_type: MULTI_GPU\")\n",
    "txt = txt.replace(\"mixed_precision: no\", \"mixed_precision: fp16\")\n",
    "txt = txt.replace(\"num_processes: 1\", \"num_processes: 2\")\n",
    "p.write_text(txt)\n",
    "print(\"Accelerate config:\", p)\n",
    "print(p.read_text())\n",
    "PY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aef7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "THR_JSON = \"/mnt/data/optimal_thresholds.json\"  # adjust if needed\n",
    "import os\n",
    "print(\"Using thresholds exists?\", os.path.exists(THR_JSON), \"->\", THR_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21405493",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_JSON = \"/workspace/data/train.jsonl\"  # <-- set your dataset path\n",
    "VAL_JSON   = \"/workspace/data/val.jsonl\"    # <-- set your dataset path\n",
    "OUT_DIR    = \"./samo_out\"\n",
    "!mkdir -p \"$OUT_DIR\"\n",
    "print(\"Train:\", TRAIN_JSON)\n",
    "print(\"Val  :\", VAL_JSON)\n",
    "print(\"Out  :\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --num_processes=2 --mixed_precision=fp16   train_samo.py   --train_json \"$TRAIN_JSON\" --val_json \"$VAL_JSON\"   --output_dir \"$OUT_DIR\"   --thresholds_json \"$THR_JSON\"   --per_device_train_batch_size 16 --per_device_eval_batch_size 32   --gradient_accumulation_steps 2   --num_train_epochs 4   --learning_rate 2e-5 --lr_scheduler_type cosine --warmup_ratio 0.1   --weight_decay 0.01 --fp16 true --tf32 true --gradient_checkpointing true   --ddp_backend nccl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85257851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "rep_path = os.path.join(\"samo_out\", \"eval_report.json\")\n",
    "if os.path.exists(rep_path):\n",
    "    rep = json.load(open(rep_path))\n",
    "    print(\"F1_micro:\", rep[\"f1_micro\"], \" F1_macro:\", rep[\"f1_macro\"])\n",
    "    pc = rep[\"per_class\"]\n",
    "    items = sorted(pc.items(), key=lambda kv: kv[1][\"f1\"])\n",
    "    print(\"\\nWorst 5:\")\n",
    "    for k,v in items[:5]: print(k, v)\n",
    "    print(\"\\nBest 5:\")\n",
    "    for k,v in items[-5:]: print(k, v)\n",
    "else:\n",
    "    print(\"eval_report.json not found at\", rep_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
