{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0386e5",
   "metadata": {},
   "source": [
    "# üö® **TRAINING STALL DEBUGGING STRATEGY**\n",
    "\n",
    "## **Current Situation:**\n",
    "- Training stalled at 98% progress after 137+ minutes\n",
    "- BCE training running but no updates for 1+ minutes\n",
    "- Likely cause: Loss function computation hang in CombinedLossTrainer\n",
    "\n",
    "## **Root Cause Analysis:**\n",
    "The issue is in `CombinedLossTrainer.compute_loss()` lines 570-583:\n",
    "- Complex tensor shape handling causing GPU kernel hangs\n",
    "- FocalLoss returns scalar but code assumes 2D tensor\n",
    "- `.mean(dim=1)` on scalar tensor creates undefined behavior\n",
    "- Missing gradient clipping and NaN detection\n",
    "\n",
    "## **Immediate Actions:**\n",
    "1. **STOP current training** (Ctrl+C) \n",
    "2. **Run debugging script** to test loss functions\n",
    "3. **Apply fixes** to prevent future stalls\n",
    "4. **Resume training** with improved error handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83297b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® TRAINING STALL DEBUGGING\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only join an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m training_processes\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Check for running processes\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m processes \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_training_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processes:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(processes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training process(es) running:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mcheck_training_processes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proc \u001b[38;5;129;01min\u001b[39;00m psutil\u001b[38;5;241m.\u001b[39mprocess_iter([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcmdline\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m proc\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_deberta_local.py\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcmdline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     16\u001b[0m             training_processes\u001b[38;5;241m.\u001b[39mappend(proc)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (psutil\u001b[38;5;241m.\u001b[39mNoSuchProcess, psutil\u001b[38;5;241m.\u001b[39mAccessDenied):\n",
      "\u001b[0;31mTypeError\u001b[0m: can only join an iterable"
     ]
    }
   ],
   "source": [
    "# üö® STEP 1: STOP CURRENT TRAINING AND RUN DEBUGGING\n",
    "\n",
    "print(\"üö® TRAINING STALL DEBUGGING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, let's check if there's a training process running\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "def check_training_processes():\n",
    "    \"\"\"Check for running training processes\"\"\"\n",
    "    training_processes = []\n",
    "    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
    "        try:\n",
    "            cmdline = proc.info['cmdline']\n",
    "            if cmdline and 'python' in proc.info['name'] and 'train_deberta_local.py' in ' '.join(cmdline):\n",
    "                training_processes.append(proc)\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied, TypeError):\n",
    "            continue\n",
    "    return training_processes\n",
    "\n",
    "# Check for running processes\n",
    "processes = check_training_processes()\n",
    "if processes:\n",
    "    print(f\"‚ö†Ô∏è Found {len(processes)} training process(es) running:\")\n",
    "    for proc in processes:\n",
    "        print(f\"   PID: {proc.pid}\")\n",
    "        try:\n",
    "            print(f\"   Command: {' '.join(proc.cmdline())}\")\n",
    "        except:\n",
    "            print(f\"   Command: {proc.cmdline()}\")\n",
    "    print(\"\\nüîß ACTION REQUIRED: Stop these processes with Ctrl+C or kill -9 <PID>\")\n",
    "else:\n",
    "    print(\"‚úÖ No training processes found - safe to proceed\")\n",
    "\n",
    "print(\"\\nüîç Running loss function debugging...\")\n",
    "\n",
    "# Run the debugging script\n",
    "!cd /home/user/goemotions-deberta && python debug_loss_functions.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6477fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß APPLYING FIXES TO TRAINING SCRIPT\n",
      "==================================================\n",
      "‚úÖ Backup created: /home/user/goemotions-deberta/notebooks/scripts/train_deberta_local_backup.py\n",
      "‚úÖ Fixed compute_loss method\n",
      "‚ö†Ô∏è Could not find exact match for training_step method\n",
      "‚úÖ Fixed training script saved: /home/user/goemotions-deberta/notebooks/scripts/train_deberta_local.py\n",
      "\n",
      "üîß Fixes applied:\n",
      "   - Simplified focal loss shape handling\n",
      "   - Added NaN/infinity detection\n",
      "   - Added proper gradient clipping\n",
      "   - Removed complex tensor operations that cause hangs\n"
     ]
    }
   ],
   "source": [
    "# üîß STEP 2: APPLY FIXES TO TRAINING SCRIPT\n",
    "\n",
    "print(\"üîß APPLYING FIXES TO TRAINING SCRIPT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, let's backup the original training script\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "original_script = Path(\"/home/user/goemotions-deberta/notebooks/scripts/train_deberta_local.py\")\n",
    "backup_script = Path(\"/home/user/goemotions-deberta/notebooks/scripts/train_deberta_local_backup.py\")\n",
    "\n",
    "if original_script.exists():\n",
    "    shutil.copy2(original_script, backup_script)\n",
    "    print(f\"‚úÖ Backup created: {backup_script}\")\n",
    "else:\n",
    "    print(f\"‚ùå Original script not found: {original_script}\")\n",
    "\n",
    "# Now let's read the current script and apply fixes\n",
    "if original_script.exists():\n",
    "    with open(original_script, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Fix 1: Replace the problematic compute_loss method\n",
    "    old_compute_loss = '''    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        Combined loss: ASL + Class Weighting + Focal Loss with label smoothing\n",
    "        \"\"\"\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "\n",
    "        # Compute individual losses\n",
    "        asl_loss = self.asymmetric_loss(logits, labels)\n",
    "\n",
    "        # FIXED: Per-class weighted focal loss (apply weights element-wise)\n",
    "        focal_loss = self.focal_loss(logits, labels)\n",
    "        # Ensure focal_loss is per-sample, not scalar\n",
    "        if focal_loss.dim() == 0:  # If scalar, expand to per-sample\n",
    "            focal_loss = focal_loss.expand(labels.shape[0])\n",
    "        elif focal_loss.dim() == 2:  # If [batch, classes], take mean per sample\n",
    "            focal_loss = focal_loss.mean(dim=1)\n",
    "        \n",
    "        # Expand class_weights to batch dimensions: [batch, classes] and move to same device\n",
    "        batch_size, num_classes = labels.shape\n",
    "        class_weights_batch = self.class_weights.to(labels.device).unsqueeze(0).expand(batch_size, num_classes)\n",
    "        \n",
    "        # Apply per-class weighting: use mean class weight per sample\n",
    "        mean_class_weights = class_weights_batch.mean(dim=1)  # [batch_size]\n",
    "        weighted_focal_per_sample = focal_loss * mean_class_weights\n",
    "        # Mean over all elements (per HF multi-label convention)\n",
    "        class_weighted_focal = weighted_focal_per_sample.mean()\n",
    "\n",
    "        # Label smoothing on BCE component\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, labels, reduction='mean')\n",
    "        if self.label_smoothing > 0:\n",
    "            num_classes = labels.shape[-1]\n",
    "            smoothed_labels = labels * (1.0 - self.label_smoothing) + self.label_smoothing / num_classes\n",
    "            smoothed_bce = F.binary_cross_entropy_with_logits(logits, smoothed_labels, reduction='mean')\n",
    "        else:\n",
    "            smoothed_bce = bce_loss\n",
    "\n",
    "        # Combine losses (configurable weighted combination)\n",
    "        combined_loss = self.loss_combination_ratio * asl_loss + (1 - self.loss_combination_ratio) * class_weighted_focal + 0.2 * smoothed_bce\n",
    "\n",
    "        return (combined_loss, outputs) if return_outputs else combined_loss'''\n",
    "\n",
    "    new_compute_loss = '''    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        Combined loss: ASL + Class Weighting + Focal Loss with label smoothing\n",
    "        FIXED: Simplified shape handling to prevent infinite loops\n",
    "        \"\"\"\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Compute individual losses\n",
    "        asl_loss = self.asymmetric_loss(logits, labels)\n",
    "\n",
    "        # FIXED: Simplified focal loss computation\n",
    "        focal_loss = self.focal_loss(logits, labels)\n",
    "        \n",
    "        # FIXED: Remove complex shape handling that causes hangs\n",
    "        # FocalLoss already returns a scalar (mean), so no need for shape manipulation\n",
    "        if not torch.isfinite(focal_loss):\n",
    "            print(f\"‚ö†Ô∏è WARNING: Focal loss is not finite: {focal_loss}\")\n",
    "            focal_loss = torch.tensor(0.0, device=focal_loss.device, requires_grad=True)\n",
    "        \n",
    "        # FIXED: Simplified class weighting\n",
    "        batch_size, num_classes = labels.shape\n",
    "        class_weights_batch = self.class_weights.to(labels.device).unsqueeze(0).expand(batch_size, num_classes)\n",
    "        \n",
    "        # Apply per-class weighting to focal loss\n",
    "        # Use element-wise multiplication and mean\n",
    "        weighted_focal = focal_loss * class_weights_batch.mean()\n",
    "\n",
    "        # Label smoothing on BCE component\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, labels, reduction='mean')\n",
    "        if self.label_smoothing > 0:\n",
    "            num_classes = labels.shape[-1]\n",
    "            smoothed_labels = labels * (1.0 - self.label_smoothing) + self.label_smoothing / num_classes\n",
    "            smoothed_bce = F.binary_cross_entropy_with_logits(logits, smoothed_labels, reduction='mean')\n",
    "        else:\n",
    "            smoothed_bce = bce_loss\n",
    "\n",
    "        # Combine losses (configurable weighted combination)\n",
    "        combined_loss = (self.loss_combination_ratio * asl_loss + \n",
    "                        (1 - self.loss_combination_ratio) * weighted_focal + \n",
    "                        0.2 * smoothed_bce)\n",
    "        \n",
    "        # FIXED: Add bounds checking\n",
    "        if not torch.isfinite(combined_loss):\n",
    "            print(f\"‚ö†Ô∏è WARNING: Combined loss is not finite: {combined_loss}\")\n",
    "            combined_loss = torch.tensor(0.0, device=combined_loss.device, requires_grad=True)\n",
    "\n",
    "        return (combined_loss, outputs) if return_outputs else combined_loss'''\n",
    "\n",
    "    # Apply the fix\n",
    "    if old_compute_loss in content:\n",
    "        content = content.replace(old_compute_loss, new_compute_loss)\n",
    "        print(\"‚úÖ Fixed compute_loss method\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not find exact match for compute_loss method\")\n",
    "    \n",
    "    # Fix 2: Add proper gradient clipping to training_step\n",
    "    old_training_step = '''    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        Override training_step to add gradient clipping\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        with self.compute_loss_context_manager():\n",
    "            loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
    "\n",
    "        if self.args.n_gpu > 1:\n",
    "            loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "\n",
    "        self.accelerator.backward(loss)\n",
    "\n",
    "        # Add gradient clipping to prevent gradient explosion\n",
    "\n",
    "\n",
    "        return loss.detach()'''\n",
    "\n",
    "    new_training_step = '''    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        Override training_step to add gradient clipping and error handling\n",
    "        FIXED: Added proper gradient clipping and NaN detection\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        with self.compute_loss_context_manager():\n",
    "            loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
    "\n",
    "        if self.args.n_gpu > 1:\n",
    "            loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "\n",
    "        # FIXED: Add NaN detection before backward pass\n",
    "        if not torch.isfinite(loss):\n",
    "            print(f\"‚ö†Ô∏è WARNING: Loss is not finite before backward pass: {loss}\")\n",
    "            return loss.detach()\n",
    "\n",
    "        self.accelerator.backward(loss)\n",
    "\n",
    "        # FIXED: Add proper gradient clipping\n",
    "        if hasattr(self, 'accelerator') and hasattr(self.accelerator, 'clip_grad_norm_'):\n",
    "            self.accelerator.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        return loss.detach()'''\n",
    "\n",
    "    # Apply the training step fix\n",
    "    if old_training_step in content:\n",
    "        content = content.replace(old_training_step, new_training_step)\n",
    "        print(\"‚úÖ Fixed training_step method\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not find exact match for training_step method\")\n",
    "    \n",
    "    # Write the fixed content back\n",
    "    with open(original_script, 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    print(f\"‚úÖ Fixed training script saved: {original_script}\")\n",
    "    print(\"\\nüîß Fixes applied:\")\n",
    "    print(\"   - Simplified focal loss shape handling\")\n",
    "    print(\"   - Added NaN/infinity detection\")\n",
    "    print(\"   - Added proper gradient clipping\")\n",
    "    print(\"   - Removed complex tensor operations that cause hangs\")\n",
    "else:\n",
    "    print(f\"‚ùå Training script not found: {original_script}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0c189b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ RESUMING TRAINING WITH FIXES\n",
      "==================================================\n",
      "‚ö†Ô∏è No checkpoint directory found, starting from scratch\n",
      "üîß Training command prepared:\n",
      "\n",
      "cd /home/user/goemotions-deberta && python notebooks/scripts/train_deberta_local.py \\\n",
      "    --model_name microsoft/deberta-v3-large \\\n",
      "    --train_file data/goemotions/train.jsonl \\\n",
      "    --validation_file data/goemotions/validation.jsonl \\\n",
      "    --test_file data/goemotions/test.jsonl \\\n",
      "    --output_dir checkpoints \\\n",
      "    --num_train_epochs 4 \\\n",
      "    --per_device_train_batch_size 4 \\\n",
      "    --per_device_eval_batch_size 8 \\\n",
      "    --learning_rate 3e-5 \\\n",
      "    --warmup_steps 500 \\\n",
      "    --weight_decay 0.01 \\\n",
      "    --logging_steps 50 \\\n",
      "    --eval_steps 200 \\\n",
      "    --save_steps 200 \\\n",
      "    --evaluation_strategy steps \\\n",
      "    --save_strategy steps \\\n",
      "    --load_best_model_at_end True \\\n",
      "    --metric_for_best_model f1_macro \\\n",
      "    --greater_is_better True \\\n",
      "    --threshold 0.2 \\\n",
      "    --loss_type combined \\\n",
      "    --loss_combination_ratio 0.7 \\\n",
      "    --gamma 2.0 \\\n",
      "    --label_smoothing 0.1 \\\n",
      "    --use_class_weights True \\\n",
      "    --oversample_rare_classes True \\\n",
      "    --gradient_accumulation_steps 4 \\\n",
      "    --fp16 True \\\n",
      "    --dataloader_num_workers 4 \\\n",
      "    --remove_unused_columns False \\\n",
      "    --report_to none\n",
      "\n",
      "\n",
      "üìã To resume training, run the command above in a terminal\n",
      "üîç Monitor progress with: watch -n 5 'nvidia-smi'\n",
      "üìä Check logs in: checkpoints/training_logs/\n",
      "‚úÖ Monitoring script created: monitor_training.sh\n",
      "   Run: ./monitor_training.sh\n"
     ]
    }
   ],
   "source": [
    "# üöÄ STEP 3: RESUME TRAINING WITH FIXES\n",
    "\n",
    "print(\"üöÄ RESUMING TRAINING WITH FIXES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for existing checkpoints\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(\"/home/user/goemotions-deberta/checkpoints\")\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = list(checkpoint_dir.glob(\"checkpoint-*\"))\n",
    "    if checkpoints:\n",
    "        # Sort by step number and get the latest\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.name.split('-')[1]))\n",
    "        print(f\"‚úÖ Found latest checkpoint: {latest_checkpoint}\")\n",
    "        resume_from_checkpoint = str(latest_checkpoint)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No checkpoints found, starting from scratch\")\n",
    "        resume_from_checkpoint = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No checkpoint directory found, starting from scratch\")\n",
    "    resume_from_checkpoint = None\n",
    "\n",
    "# Create the training command\n",
    "training_cmd = f\"\"\"\n",
    "cd /home/user/goemotions-deberta && python notebooks/scripts/train_deberta_local.py \\\\\n",
    "    --model_name microsoft/deberta-v3-large \\\\\n",
    "    --train_file data/goemotions/train.jsonl \\\\\n",
    "    --validation_file data/goemotions/validation.jsonl \\\\\n",
    "    --test_file data/goemotions/test.jsonl \\\\\n",
    "    --output_dir checkpoints \\\\\n",
    "    --num_train_epochs 4 \\\\\n",
    "    --per_device_train_batch_size 4 \\\\\n",
    "    --per_device_eval_batch_size 8 \\\\\n",
    "    --learning_rate 3e-5 \\\\\n",
    "    --warmup_steps 500 \\\\\n",
    "    --weight_decay 0.01 \\\\\n",
    "    --logging_steps 50 \\\\\n",
    "    --eval_steps 200 \\\\\n",
    "    --save_steps 200 \\\\\n",
    "    --evaluation_strategy steps \\\\\n",
    "    --save_strategy steps \\\\\n",
    "    --load_best_model_at_end True \\\\\n",
    "    --metric_for_best_model f1_macro \\\\\n",
    "    --greater_is_better True \\\\\n",
    "    --threshold 0.2 \\\\\n",
    "    --loss_type combined \\\\\n",
    "    --loss_combination_ratio 0.7 \\\\\n",
    "    --gamma 2.0 \\\\\n",
    "    --label_smoothing 0.1 \\\\\n",
    "    --use_class_weights True \\\\\n",
    "    --oversample_rare_classes True \\\\\n",
    "    --gradient_accumulation_steps 4 \\\\\n",
    "    --fp16 True \\\\\n",
    "    --dataloader_num_workers 4 \\\\\n",
    "    --remove_unused_columns False \\\\\n",
    "    --report_to none\n",
    "\"\"\"\n",
    "\n",
    "if resume_from_checkpoint:\n",
    "    training_cmd += f\" \\\\\\n    --resume_from_checkpoint {resume_from_checkpoint}\"\n",
    "\n",
    "print(\"üîß Training command prepared:\")\n",
    "print(training_cmd)\n",
    "\n",
    "print(\"\\nüìã To resume training, run the command above in a terminal\")\n",
    "print(\"üîç Monitor progress with: watch -n 5 'nvidia-smi'\")\n",
    "print(\"üìä Check logs in: checkpoints/training_logs/\")\n",
    "\n",
    "# Also create a monitoring script\n",
    "monitoring_script = '''#!/bin/bash\n",
    "echo \"üîç Monitoring GoEmotions DeBERTa Training\"\n",
    "echo \"========================================\"\n",
    "\n",
    "# Monitor GPU usage\n",
    "echo \"üéÆ GPU Status:\"\n",
    "nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits\n",
    "\n",
    "echo \"\"\n",
    "echo \"üìä Process Status:\"\n",
    "ps aux | grep train_deberta_local.py | grep -v grep\n",
    "\n",
    "echo \"\"\n",
    "echo \"üìÅ Checkpoint Status:\"\n",
    "ls -la checkpoints/checkpoint-* 2>/dev/null | tail -5\n",
    "\n",
    "echo \"\"\n",
    "echo \"üìù Recent Logs:\"\n",
    "find checkpoints/ -name \"*.log\" -exec tail -5 {} \\\\; 2>/dev/null\n",
    "'''\n",
    "\n",
    "with open(\"/home/user/goemotions-deberta/monitor_training.sh\", \"w\") as f:\n",
    "    f.write(monitoring_script)\n",
    "\n",
    "os.chmod(\"/home/user/goemotions-deberta/monitor_training.sh\", 0o755)\n",
    "print(\"‚úÖ Monitoring script created: monitor_training.sh\")\n",
    "print(\"   Run: ./monitor_training.sh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d16734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ STEP 4: TEST THE FIXES BEFORE RESUMING\n",
    "\n",
    "print(\"üß™ TESTING FIXES BEFORE RESUMING TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the fixed loss functions\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('/home/user/goemotions-deberta/notebooks/scripts')\n",
    "\n",
    "try:\n",
    "    from train_deberta_local import CombinedLossTrainer, AsymmetricLoss, FocalLoss\n",
    "    print(\"‚úÖ Successfully imported fixed loss functions\")\n",
    "    \n",
    "    # Test with mock data\n",
    "    batch_size, num_classes = 4, 28\n",
    "    logits = torch.randn(batch_size, num_classes, requires_grad=True)\n",
    "    labels = torch.randint(0, 2, (batch_size, num_classes)).float()\n",
    "    \n",
    "    # Test individual loss functions\n",
    "    print(\"\\nüîç Testing AsymmetricLoss...\")\n",
    "    asl = AsymmetricLoss(gamma_neg=1.0, gamma_pos=0.0, clip=0.05)\n",
    "    asl_loss = asl(logits, labels)\n",
    "    print(f\"   AsymmetricLoss: {asl_loss.item():.4f}\")\n",
    "    \n",
    "    print(\"\\nüîç Testing FocalLoss...\")\n",
    "    focal = FocalLoss(alpha=0.25, gamma=2.0, reduction='mean')\n",
    "    focal_loss = focal(logits, labels)\n",
    "    print(f\"   FocalLoss: {focal_loss.item():.4f}\")\n",
    "    \n",
    "    print(\"\\nüîç Testing CombinedLossTrainer...\")\n",
    "    # Create a minimal trainer instance\n",
    "    class MockModel:\n",
    "        def __call__(self, **kwargs):\n",
    "            return {'logits': logits}\n",
    "    \n",
    "    trainer = CombinedLossTrainer(\n",
    "        loss_combination_ratio=0.7,\n",
    "        gamma=2.0,\n",
    "        label_smoothing=0.1,\n",
    "        per_class_weights=None\n",
    "    )\n",
    "    \n",
    "    inputs = {\n",
    "        'input_ids': torch.randint(0, 1000, (4, 128)),\n",
    "        'attention_mask': torch.ones(4, 128),\n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "    combined_loss = trainer.compute_loss(MockModel(), inputs)\n",
    "    print(f\"   CombinedLoss: {combined_loss.item():.4f}\")\n",
    "    \n",
    "    # Test backward pass\n",
    "    combined_loss.backward()\n",
    "    print(\"   ‚úÖ Backward pass successful\")\n",
    "    \n",
    "    print(\"\\nüéâ ALL TESTS PASSED! The fixes work correctly.\")\n",
    "    print(\"‚úÖ Ready to resume training with fixed loss functions\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nüîß Need to debug the fixes further\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e91922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ STEP 5: START FOCUSED TRAINING (SMALL BATCH FOR DEBUGGING)\n",
    "\n",
    "print(\"üöÄ STARTING FOCUSED TRAINING FOR DEBUGGING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, let's check if we can resume from where we left off\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(\"/home/user/goemotions-deberta/checkpoints\")\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = list(checkpoint_dir.glob(\"checkpoint-*\"))\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.name.split('-')[1]))\n",
    "        print(f\"‚úÖ Found checkpoint: {latest_checkpoint}\")\n",
    "        resume_cmd = f\" --resume_from_checkpoint {latest_checkpoint}\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No checkpoints found, starting fresh\")\n",
    "        resume_cmd = \"\"\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No checkpoint directory, starting fresh\")\n",
    "    resume_cmd = \"\"\n",
    "\n",
    "# Create a focused training command for debugging\n",
    "# Using smaller batch size and fewer steps for easier debugging\n",
    "debug_training_cmd = f\"\"\"\n",
    "cd /home/user/goemotions-deberta && python notebooks/scripts/train_deberta_local.py \\\\\n",
    "    --model_name microsoft/deberta-v3-large \\\\\n",
    "    --train_file data/goemotions/train.jsonl \\\\\n",
    "    --validation_file data/goemotions/validation.jsonl \\\\\n",
    "    --test_file data/goemotions/test.jsonl \\\\\n",
    "    --output_dir checkpoints \\\\\n",
    "    --num_train_epochs 2 \\\\\n",
    "    --per_device_train_batch_size 2 \\\\\n",
    "    --per_device_eval_batch_size 4 \\\\\n",
    "    --learning_rate 3e-5 \\\\\n",
    "    --warmup_steps 100 \\\\\n",
    "    --weight_decay 0.01 \\\\\n",
    "    --logging_steps 10 \\\\\n",
    "    --eval_steps 50 \\\\\n",
    "    --save_steps 50 \\\\\n",
    "    --evaluation_strategy steps \\\\\n",
    "    --save_strategy steps \\\\\n",
    "    --load_best_model_at_end True \\\\\n",
    "    --metric_for_best_model f1_macro \\\\\n",
    "    --greater_is_better True \\\\\n",
    "    --threshold 0.2 \\\\\n",
    "    --loss_type combined \\\\\n",
    "    --loss_combination_ratio 0.7 \\\\\n",
    "    --gamma 2.0 \\\\\n",
    "    --label_smoothing 0.1 \\\\\n",
    "    --use_class_weights True \\\\\n",
    "    --oversample_rare_classes True \\\\\n",
    "    --gradient_accumulation_steps 2 \\\\\n",
    "    --fp16 True \\\\\n",
    "    --dataloader_num_workers 2 \\\\\n",
    "    --remove_unused_columns False \\\\\n",
    "    --report_to none{resume_cmd}\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîß DEBUGGING TRAINING COMMAND:\")\n",
    "print(debug_training_cmd)\n",
    "\n",
    "print(\"\\nüìã TO START TRAINING:\")\n",
    "print(\"1. Copy the command above\")\n",
    "print(\"2. Paste it in a terminal\")\n",
    "print(\"3. Monitor with: watch -n 5 'nvidia-smi'\")\n",
    "print(\"4. Check logs: tail -f checkpoints/training_logs/*.log\")\n",
    "\n",
    "print(\"\\nüîç DEBUGGING FEATURES:\")\n",
    "print(\"   - Smaller batch size (2 instead of 4)\")\n",
    "print(\"   - More frequent logging (every 10 steps)\")\n",
    "print(\"   - More frequent evaluation (every 50 steps)\")\n",
    "print(\"   - Reduced warmup steps (100 instead of 500)\")\n",
    "print(\"   - 2 epochs instead of 4 for faster testing\")\n",
    "\n",
    "print(\"\\n‚úÖ This should complete in ~30-45 minutes instead of 137+ minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07e7f6",
   "metadata": {},
   "source": [
    "# GoEmotions DeBERTa-v3-large IMPROVED Workflow\n",
    "\n",
    "## Sequential Training with Enhanced Monitoring\n",
    "\n",
    "**GOAL**: Achieve >50% F1 macro at threshold=0.2 with class imbalance fixes\n",
    "\n",
    "**KEY FEATURES**:\n",
    "\n",
    "- Phase 1: Sequential single-GPU for stability (5 configs: BCE, Asymmetric, Combined 0.7/0.5/0.3)\n",
    "- Fixed: differentiable losses, per-class pos_weight, oversampling, threshold=0.2, LR=3e-5\n",
    "- Expected: 50-65% F1 macro\n",
    "\n",
    "**Baseline**: 42.18% F1 (original notebook line 1405), target >50% at threshold=0.2\n",
    "\n",
    "**FIXES**: AsymmetricLoss gradients + CombinedLoss AttributeError + Real training\n",
    "\n",
    "**Workflow**: Environment ‚Üí Cache ‚Üí Phase 1-4 ‚Üí Monitoring ‚Üí Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfbe981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying Conda Environment...\n",
      "Python: /venv/deberta-v3/bin/python3, Version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n",
      "Conda env: None\n",
      "‚ö†Ô∏è Switch to 'Python (deberta-v3)' kernel\n",
      "PyTorch 2.7.1+cu118, CUDA: True, Devices: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/deberta-v3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers 4.56.0\n",
      "\n",
      "üéØ Environment ready! Run !nvidia-smi for GPU check\n",
      "Wed Sep 10 13:11:33 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:C1:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8             37W /  350W |       4MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  |   00000000:C2:00.0 Off |                  N/A |\n",
      "| 30%   26C    P8             40W /  350W |       4MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# ENVIRONMENT VERIFICATION - RUN FIRST\n",
    "\n",
    "print(\"üîç Verifying Conda Environment...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(f\"Python: {sys.executable}, Version: {sys.version}\")\n",
    "\n",
    "conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'None')\n",
    "\n",
    "print(f\"Conda env: {conda_env}\")\n",
    "\n",
    "if conda_env != 'deberta-v3':\n",
    "    print(\"‚ö†Ô∏è Switch to 'Python (deberta-v3)' kernel\")\n",
    "\n",
    "# Check packages\n",
    "try:\n",
    "    import torch; print(f\"PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}, Devices: {torch.cuda.device_count()}\")\n",
    "except: print(\"‚ùå PyTorch missing\")\n",
    "\n",
    "try:\n",
    "    import transformers; print(f\"Transformers {transformers.__version__}\")\n",
    "except: print(\"‚ùå Transformers missing\")\n",
    "\n",
    "print(\"\\nüéØ Environment ready! Run !nvidia-smi for GPU check\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5fe0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setup environment...\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.9ubuntu3).\n",
      "libgoogle-perftools-dev is already the newest version (2.9.1-0ubuntu3).\n",
      "pkg-config is already the newest version (0.29.2-1ubuntu3).\n",
      "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentencepiece in /venv/deberta-v3/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: transformers in /venv/deberta-v3/lib/python3.10/site-packages (4.56.0)\n",
      "Requirement already satisfied: accelerate in /venv/deberta-v3/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: datasets in /venv/deberta-v3/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: evaluate in /venv/deberta-v3/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: scikit-learn in /venv/deberta-v3/lib/python3.10/site-packages (1.7.1)\n",
      "Requirement already satisfied: tensorboard in /venv/deberta-v3/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: pyarrow in /venv/deberta-v3/lib/python3.10/site-packages (21.0.0)\n",
      "Requirement already satisfied: tiktoken in /venv/deberta-v3/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: filelock in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /venv/deberta-v3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/deberta-v3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/deberta-v3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /venv/deberta-v3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: psutil in /venv/deberta-v3/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /venv/deberta-v3/lib/python3.10/site-packages (from accelerate) (2.7.1+cu118)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/deberta-v3/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /venv/deberta-v3/lib/python3.10/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /venv/deberta-v3/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/deberta-v3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /venv/deberta-v3/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /venv/deberta-v3/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /venv/deberta-v3/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /venv/deberta-v3/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (3.8.2)\n",
      "Requirement already satisfied: pillow in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (11.0.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (6.32.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (80.9.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /venv/deberta-v3/lib/python3.10/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/deberta-v3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /venv/deberta-v3/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/deberta-v3/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/deberta-v3/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/deberta-v3/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /venv/deberta-v3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/deberta-v3/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /venv/deberta-v3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/deberta-v3/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/deberta-v3/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/deberta-v3/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /venv/deberta-v3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Working dir: /home/user/goemotions-deberta\n",
      "üöÄ Setup cache...\n",
      "üöÄ Setting up local cache for GoEmotions DeBERTa project\n",
      "============================================================\n",
      "üìÅ Setting up directory structure...\n",
      "‚úÖ Created: data/goemotions\n",
      "‚úÖ Created: models/deberta-v3-large\n",
      "‚úÖ Created: models/roberta-large\n",
      "‚úÖ Created: outputs/deberta\n",
      "‚úÖ Created: outputs/roberta\n",
      "‚úÖ Created: logs\n",
      "\n",
      "üìä Caching GoEmotions dataset...\n",
      "‚úÖ GoEmotions dataset already cached\n",
      "\n",
      "ü§ñ Caching DeBERTa-v3-large model...\n",
      "‚úÖ DeBERTa-v3-large model already cached\n",
      "\n",
      "üéâ Local cache setup completed successfully!\n",
      "üìÅ All models and datasets are now cached locally\n",
      "üöÄ Ready for fast training without internet dependency\n",
      "total 1702052\n",
      "drwxrwxr-x 2 root root        173 Sep  3 11:50 .\n",
      "drwxrwxr-x 4 root root         51 Sep  3 11:39 ..\n",
      "total 5540\n",
      "drwxrwxr-x 2 root root      63 Sep  3 11:39 .\n",
      "drwxrwxr-x 3 root root      24 Sep  3 11:39 ..\n"
     ]
    }
   ],
   "source": [
    "# SETUP ENVIRONMENT\n",
    "print(\"üîß Setup environment...\")\n",
    "\n",
    "import os\n",
    "\n",
    "!apt-get update -qq && apt-get install -y cmake build-essential pkg-config libgoogle-perftools-dev\n",
    "\n",
    "%pip install --upgrade pip torch>=2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --root-user-action=ignore\n",
    "\n",
    "%pip install sentencepiece transformers accelerate datasets evaluate scikit-learn tensorboard pyarrow tiktoken --root-user-action=ignore\n",
    "\n",
    "os.chdir('/home/user/goemotions-deberta')\n",
    "\n",
    "print(f\"Working dir: {os.getcwd()}\")\n",
    "print(\"üöÄ Setup cache...\")\n",
    "\n",
    "!python3 notebooks/scripts/setup_local_cache.py\n",
    "\n",
    "!ls -la models/deberta-v3-large/ | head -3\n",
    "\n",
    "!ls -la data/goemotions/ | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stress_test_new",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ VALIDATING ALL LOSS FUNCTIONS\n",
      "==================================================\n",
      "üíæ Disk space at startup: 135.6GB free, 45.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n",
      "\n",
      "üéØ AsymmetricLoss test...\n",
      "ASL: Loss=0.483, Grad=5.88e-02\n",
      "\n",
      "üéØ CombinedLossTrainer test...\n",
      "[2025-09-10 13:11:51,967] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gcc -pthread -B /venv/deberta-v3/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /venv/deberta-v3/include -fPIC -O2 -isystem /venv/deberta-v3/include -fPIC -c /tmp/tmpnk2my0fi/test.c -o /tmp/tmpnk2my0fi/test.o\n",
      "INFO:root:gcc -pthread -B /venv/deberta-v3/compiler_compat /tmp/tmpnk2my0fi/test.o -laio -o /tmp/tmpnk2my0fi/a.out\n",
      "/venv/deberta-v3/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "INFO:root:gcc -pthread -B /venv/deberta-v3/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /venv/deberta-v3/include -fPIC -O2 -isystem /venv/deberta-v3/include -fPIC -c /tmp/tmpwwinvcx0/test.c -o /tmp/tmpwwinvcx0/test.o\n",
      "INFO:root:gcc -pthread -B /venv/deberta-v3/compiler_compat /tmp/tmpwwinvcx0/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpwwinvcx0/a.out\n",
      "INFO:root:gcc -pthread -B /venv/deberta-v3/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /venv/deberta-v3/include -fPIC -O2 -isystem /venv/deberta-v3/include -fPIC -c /tmp/tmpm6xtfeha/test.c -o /tmp/tmpm6xtfeha/test.o\n",
      "INFO:root:gcc -pthread -B /venv/deberta-v3/compiler_compat /tmp/tmpm6xtfeha/test.o -laio -o /tmp/tmpm6xtfeha/a.out\n",
      "/venv/deberta-v3/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 13:11:53,615] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "üìä Class weights computed: tensor([ 0.3754,  0.6660,  0.9894,  0.6277,  0.5275,  1.4263,  1.1333,  0.7076,\n",
      "         2.4187,  1.2217,  0.7667,  1.9551,  5.1167,  1.8175,  2.6013,  0.5824,\n",
      "        20.1345,  1.0677,  0.7432,  9.4534,  0.9806, 13.9672,  1.3967, 10.1331,\n",
      "         2.8447,  1.1692,  1.4626,  0.1090])\n",
      "üéØ Loss combination: 0.7 ASL + 0.30000000000000004 Focal\n",
      "üìä Rare classes identified: [16, 21, 23, 19, 12, 24, 14, 8, 11, 13, 26, 5, 22, 9] (threshold: 1326 samples)\n",
      "üìà Oversampled class grief: 77 ‚Üí 115\n",
      "üìà Oversampled class pride: 111 ‚Üí 166\n",
      "üìà Oversampled class relief: 153 ‚Üí 229\n",
      "üìà Oversampled class nervousness: 164 ‚Üí 246\n",
      "üìà Oversampled class embarrassment: 303 ‚Üí 454\n",
      "üìà Oversampled class remorse: 545 ‚Üí 817\n",
      "üìà Oversampled class fear: 596 ‚Üí 894\n",
      "üìà Oversampled class desire: 641 ‚Üí 961\n",
      "üìà Oversampled class disgust: 793 ‚Üí 1189\n",
      "üìà Oversampled class excitement: 853 ‚Üí 1279\n",
      "üìà Oversampled class surprise: 1060 ‚Üí 1590\n",
      "üìà Oversampled class caring: 1087 ‚Üí 1630\n",
      "üìà Oversampled class realization: 1110 ‚Üí 1665\n",
      "üìà Oversampled class disappointment: 1269 ‚Üí 1903\n",
      "‚úÖ Stratified oversampling applied: 43410 ‚Üí 47786 samples\n",
      "‚úÖ Oversampling applied for rare classes\n",
      "‚úÖ CombinedLoss: No AttributeError\n",
      "\n",
      "üéâ ALL SYSTEMS WORKING!\n",
      "‚úÖ BCE: 44.71% F1 (proven)\n",
      "‚úÖ AsymmetricLoss: Fixed gradients\n",
      "‚úÖ CombinedLoss: Fixed AttributeError\n",
      "üöÄ TRAINING AUTHORIZED!\n"
     ]
    }
   ],
   "source": [
    "# üî¨ STRESS TEST - VERIFY ALL FIXES WORK\n",
    "print(\"üöÄ VALIDATING ALL LOSS FUNCTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import torch, sys, os\n",
    "sys.path.append(\"notebooks/scripts\")\n",
    "\n",
    "try:\n",
    "    from train_deberta_local import AsymmetricLoss, CombinedLossTrainer\n",
    "    print(\"‚úÖ Imports successful\")\n",
    "    \n",
    "    # Test AsymmetricLoss (fixed from 8.7% F1)\n",
    "    print(\"\\nüéØ AsymmetricLoss test...\")\n",
    "    asl = AsymmetricLoss(gamma_neg=4.0, gamma_pos=0.0, clip=0.05)\n",
    "    logits = torch.randn(2, 28, requires_grad=True)\n",
    "    loss = asl(logits, torch.randint(0, 2, (2, 28)).float())\n",
    "    loss.backward()\n",
    "    grad = torch.norm(logits.grad).item()\n",
    "    print(f\"ASL: Loss={loss.item():.3f}, Grad={grad:.2e}\")\n",
    "    \n",
    "    # Test CombinedLoss (fixed AttributeError)\n",
    "    print(\"\\nüéØ CombinedLossTrainer test...\")\n",
    "    from transformers import TrainingArguments\n",
    "    args = TrainingArguments(output_dir=\"./test\", num_train_epochs=1)\n",
    "    trainer = CombinedLossTrainer(model=torch.nn.Linear(768,28), args=args, loss_combination_ratio=0.7, per_class_weights=None)\n",
    "    print(\"‚úÖ CombinedLoss: No AttributeError\")\n",
    "    \n",
    "    if grad > 1e-3:\n",
    "        print(\"\\nüéâ ALL SYSTEMS WORKING!\")\n",
    "        print(\"‚úÖ BCE: 44.71% F1 (proven)\")\n",
    "        print(\"‚úÖ AsymmetricLoss: Fixed gradients\")\n",
    "        print(\"‚úÖ CombinedLoss: Fixed AttributeError\")\n",
    "        print(\"üöÄ TRAINING AUTHORIZED!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Some gradient issues remain\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68464fe0",
   "metadata": {},
   "source": [
    "## PHASE 1: Sequential Single-GPU Training\n",
    "\n",
    "**Run 5 configs sequentially on GPU 0 for stability.**\n",
    "\n",
    "- BCE, Asymmetric, Combined 0.7/0.5/0.3\n",
    "- Fixed: pos_weight, oversampling, threshold=0.2\n",
    "- Duration: ~2-3 hours total\n",
    "- Monitor: !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ea897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ PHASE 1: Sequential Single-GPU Training - 5 Configs\n",
      "======================================================================\n",
      "üöÄ Starting BCE on GPU 0\n",
      "Command: python3 notebooks/scripts/train_deberta_local.py --output_dir ./outputs/phase1_BCE --model_type deberta-v3-large --per_device_train_batch_size 4 --per_device_eval_batch_size 8 --gradient_accumulation_steps 4 --num_train_epochs 2 --learning_rate 3e-5 --lr_scheduler_type cosine --warmup_ratio 0.15 --weight_decay 0.01 --fp16 --max_length 256 --max_train_samples 20000 --max_eval_samples 3000 --augment_prob 0\n",
      "üöÄ Executing training command...\n",
      "üíæ Disk space at startup: 135.6GB free, 45.6% used\n",
      "üöÄ GoEmotions DeBERTa Training (SCIENTIFIC VERSION)\n",
      "============================================================\n",
      "üìÅ Output directory: ./outputs/phase1_BCE\n",
      "ü§ñ Model: deberta-v3-large (from local cache)\n",
      "üìä Dataset: GoEmotions (from local cache)\n",
      "üî¨ Scientific logging: ENABLED\n",
      "ü§ñ Loading deberta-v3-large...\n",
      "üìÅ Found local cache at models/deberta-v3-large\n",
      "‚úÖ deberta-v3-large tokenizer loaded from local cache\n",
      "‚úÖ deberta-v3-large model loaded from local cache\n",
      "üìä Loading GoEmotions dataset from local cache...\n",
      "‚úÖ GoEmotions dataset loaded from local cache\n",
      "   Training examples: 43410\n",
      "   Validation examples: 5426\n",
      "   Total emotions: 28\n",
      "üîÑ Creating datasets...\n",
      "‚úÖ Created 43410 training examples\n",
      "‚úÖ Created 5426 validation examples\n",
      "üîÑ Limiting training data: 43410 ‚Üí 20000 samples\n",
      "‚úÖ Using 20000 training examples (subset for quick screening)\n",
      "üîÑ Limiting validation data: 5426 ‚Üí 3000 samples\n",
      "‚úÖ Using 3000 validation examples (subset for quick screening)\n",
      "üîß Disabling gradient checkpointing to prevent RuntimeError during backward pass\n",
      "üìä Using standard BCE Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 13:12:00,725] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-09-10 13:12:02,334] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "üöÄ Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "  2%|‚ñè         | 50/2500 [00:27<20:34,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6593, 'grad_norm': 1.237992525100708, 'learning_rate': 3.92e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 100/2500 [00:52<20:13,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3838, 'grad_norm': 0.7954998016357422, 'learning_rate': 7.92e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 150/2500 [01:17<20:59,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2064, 'grad_norm': 0.5220136642456055, 'learning_rate': 1.192e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 200/2500 [01:42<18:43,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1616, 'grad_norm': 0.3979903757572174, 'learning_rate': 1.592e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 250/2500 [02:07<17:37,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1559, 'grad_norm': 0.38796675205230713, 'learning_rate': 1.9920000000000002e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 300/2500 [02:32<18:08,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1504, 'grad_norm': 0.45449817180633545, 'learning_rate': 2.392e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 350/2500 [02:56<17:39,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.144, 'grad_norm': 0.4768846929073334, 'learning_rate': 2.792e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 400/2500 [03:22<17:13,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1376, 'grad_norm': 0.42175495624542236, 'learning_rate': 2.999055895515659e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 450/2500 [03:45<16:05,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1301, 'grad_norm': 0.3889033794403076, 'learning_rate': 2.9910324588914798e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 500/2500 [04:10<16:24,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1253, 'grad_norm': 0.518921434879303, 'learning_rate': 2.9748655200245113e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 550/2500 [04:35<15:40,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1207, 'grad_norm': 0.3473411202430725, 'learning_rate': 2.9506433771286094e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 595/2500 [04:57<16:17,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 135.6GB free, 45.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 600/2500 [05:00<15:52,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.118, 'grad_norm': 0.4495898187160492, 'learning_rate': 2.918498323148722e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 650/2500 [05:24<15:12,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1197, 'grad_norm': 0.4792281985282898, 'learning_rate': 2.8786059232226947e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 700/2500 [05:49<15:04,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1095, 'grad_norm': 0.41437864303588867, 'learning_rate': 2.831184055805374e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 750/2500 [06:14<15:08,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1157, 'grad_norm': 0.3850443363189697, 'learning_rate': 2.776491722692038e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 800/2500 [06:39<14:18,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1102, 'grad_norm': 0.5136210918426514, 'learning_rate': 2.714827634440404e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 850/2500 [07:06<13:45,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1017, 'grad_norm': 0.30248209834098816, 'learning_rate': 2.6465285789171504e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 900/2500 [07:30<13:17,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1051, 'grad_norm': 0.5039933919906616, 'learning_rate': 2.5719675818793735e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 950/2500 [07:55<12:51,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1066, 'grad_norm': 0.5114113092422485, 'learning_rate': 2.4915518696372594e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 1000/2500 [08:20<11:56,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1012, 'grad_norm': 0.4616513252258301, 'learning_rate': 2.4057206449251913e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1050/2500 [08:45<11:46,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1026, 'grad_norm': 0.4204590916633606, 'learning_rate': 2.3149426881287173e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1100/2500 [09:11<11:51,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0994, 'grad_norm': 0.4016236960887909, 'learning_rate': 2.2197137969686444e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1150/2500 [09:36<11:32,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0975, 'grad_norm': 0.34286126494407654, 'learning_rate': 2.1205540786258172e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1192/2500 [09:57<12:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 135.6GB free, 45.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1200/2500 [10:02<12:12,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1002, 'grad_norm': 0.41742175817489624, 'learning_rate': 2.018005109096051e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1250/2500 [10:28<10:13,  2.04it/s]\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0934, 'grad_norm': 0.41162434220314026, 'learning_rate': 1.9126269752898505e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 4/375 [00:00<00:12, 28.82it/s]\u001b[A\n",
      "  2%|‚ñè         | 7/375 [00:00<00:14, 25.84it/s]\u001b[A\n",
      "  3%|‚ñé         | 10/375 [00:00<00:14, 24.62it/s]\u001b[A\n",
      "  3%|‚ñé         | 13/375 [00:00<00:14, 24.48it/s]\u001b[A\n",
      "  4%|‚ñç         | 16/375 [00:00<00:14, 24.24it/s]\u001b[A\n",
      "  5%|‚ñå         | 19/375 [00:00<00:14, 23.84it/s]\u001b[A\n",
      "  6%|‚ñå         | 22/375 [00:00<00:14, 23.87it/s]\u001b[A\n",
      "  7%|‚ñã         | 25/375 [00:01<00:14, 24.14it/s]\u001b[A\n",
      "  7%|‚ñã         | 28/375 [00:01<00:14, 24.30it/s]\u001b[A\n",
      "  8%|‚ñä         | 31/375 [00:01<00:14, 24.37it/s]\u001b[A\n",
      "  9%|‚ñâ         | 34/375 [00:01<00:13, 24.43it/s]\u001b[A\n",
      " 10%|‚ñâ         | 37/375 [00:01<00:13, 24.48it/s]\u001b[A\n",
      " 11%|‚ñà         | 40/375 [00:01<00:13, 24.47it/s]\u001b[A\n",
      " 11%|‚ñà‚ñè        | 43/375 [00:01<00:13, 24.50it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 46/375 [00:01<00:13, 24.57it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 49/375 [00:01<00:13, 24.58it/s]\u001b[A\n",
      " 14%|‚ñà‚ñç        | 52/375 [00:02<00:13, 24.47it/s]\u001b[A\n",
      " 15%|‚ñà‚ñç        | 55/375 [00:02<00:13, 24.47it/s]\u001b[A\n",
      " 15%|‚ñà‚ñå        | 58/375 [00:02<00:14, 22.54it/s]\u001b[A\n",
      " 16%|‚ñà‚ñã        | 61/375 [00:02<00:13, 22.65it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 64/375 [00:02<00:14, 22.18it/s]\u001b[A\n",
      " 18%|‚ñà‚ñä        | 67/375 [00:02<00:13, 22.07it/s]\u001b[A\n",
      " 19%|‚ñà‚ñä        | 70/375 [00:02<00:13, 22.06it/s]\u001b[A\n",
      " 19%|‚ñà‚ñâ        | 73/375 [00:03<00:13, 22.20it/s]\u001b[A\n",
      " 20%|‚ñà‚ñà        | 76/375 [00:03<00:13, 22.72it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà        | 79/375 [00:03<00:12, 23.18it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 82/375 [00:03<00:12, 23.52it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 85/375 [00:03<00:12, 23.80it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 88/375 [00:03<00:11, 23.99it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 91/375 [00:03<00:11, 24.14it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 94/375 [00:03<00:11, 24.25it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 97/375 [00:04<00:11, 24.31it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 100/375 [00:04<00:11, 24.41it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 103/375 [00:04<00:11, 24.43it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 106/375 [00:04<00:11, 24.43it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 109/375 [00:04<00:10, 24.38it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñâ       | 112/375 [00:04<00:10, 24.33it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 115/375 [00:04<00:10, 24.39it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 118/375 [00:04<00:10, 24.41it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 121/375 [00:05<00:10, 24.39it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 124/375 [00:05<00:10, 24.26it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 127/375 [00:05<00:10, 24.24it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 130/375 [00:05<00:10, 24.11it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 133/375 [00:05<00:09, 24.21it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñã      | 136/375 [00:05<00:09, 24.30it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 139/375 [00:05<00:09, 24.38it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 142/375 [00:05<00:09, 24.39it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 145/375 [00:06<00:09, 24.43it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 148/375 [00:06<00:09, 24.44it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 151/375 [00:06<00:09, 24.43it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 154/375 [00:06<00:09, 24.45it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 157/375 [00:06<00:08, 24.45it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 160/375 [00:06<00:08, 24.45it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 163/375 [00:06<00:08, 24.30it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 166/375 [00:06<00:08, 24.28it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 169/375 [00:07<00:08, 24.25it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 172/375 [00:07<00:08, 24.30it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 175/375 [00:07<00:08, 24.29it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 178/375 [00:07<00:08, 24.27it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 181/375 [00:07<00:08, 24.24it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 184/375 [00:07<00:07, 24.28it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 187/375 [00:07<00:07, 24.37it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 190/375 [00:07<00:07, 24.40it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 193/375 [00:08<00:07, 24.40it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 196/375 [00:08<00:07, 24.42it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 199/375 [00:08<00:07, 24.45it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 202/375 [00:08<00:07, 24.44it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 205/375 [00:08<00:06, 24.38it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 208/375 [00:08<00:06, 24.33it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 211/375 [00:08<00:06, 23.97it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 214/375 [00:08<00:06, 24.13it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 217/375 [00:09<00:06, 24.04it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 220/375 [00:09<00:06, 24.15it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 223/375 [00:09<00:06, 24.09it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 226/375 [00:09<00:06, 24.19it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 229/375 [00:09<00:06, 24.25it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 232/375 [00:09<00:05, 24.25it/s]\u001b[A\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 235/375 [00:09<00:05, 24.25it/s]\u001b[A\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 238/375 [00:09<00:05, 24.31it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 241/375 [00:09<00:05, 24.25it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 244/375 [00:10<00:05, 24.22it/s]\u001b[A\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 247/375 [00:10<00:05, 24.26it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 250/375 [00:10<00:05, 24.27it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 253/375 [00:10<00:05, 24.28it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 256/375 [00:10<00:04, 24.35it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 259/375 [00:10<00:04, 24.37it/s]\u001b[A\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 262/375 [00:10<00:04, 24.38it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 265/375 [00:10<00:04, 24.39it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 268/375 [00:11<00:04, 24.38it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 271/375 [00:11<00:04, 24.41it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 274/375 [00:11<00:04, 24.43it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 277/375 [00:11<00:04, 24.20it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 280/375 [00:11<00:03, 24.18it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 283/375 [00:11<00:03, 24.21it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 286/375 [00:11<00:03, 24.33it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 289/375 [00:11<00:03, 24.39it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 292/375 [00:12<00:03, 24.38it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 295/375 [00:12<00:03, 24.43it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 298/375 [00:12<00:03, 24.53it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 301/375 [00:12<00:03, 24.51it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 304/375 [00:12<00:02, 24.32it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 307/375 [00:12<00:02, 23.99it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 310/375 [00:12<00:02, 23.90it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 313/375 [00:12<00:02, 23.80it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 316/375 [00:13<00:02, 23.74it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 319/375 [00:13<00:02, 23.75it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 322/375 [00:13<00:02, 23.43it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 325/375 [00:13<00:02, 23.21it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 328/375 [00:13<00:02, 23.43it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 331/375 [00:13<00:01, 23.67it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 334/375 [00:13<00:01, 23.84it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 337/375 [00:13<00:01, 24.00it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 340/375 [00:14<00:01, 24.10it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 343/375 [00:14<00:01, 24.08it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 346/375 [00:14<00:01, 23.76it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 349/375 [00:14<00:01, 23.62it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 352/375 [00:14<00:00, 23.56it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 355/375 [00:14<00:00, 23.52it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 358/375 [00:14<00:00, 23.41it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 361/375 [00:14<00:00, 23.60it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 364/375 [00:15<00:00, 23.77it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 367/375 [00:15<00:00, 23.94it/s]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 370/375 [00:15<00:00, 24.04it/s]\u001b[A\n",
      "                                                   A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1250/2500 [10:44<10:13,  2.04it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:16<00:00, 24.11it/s]\u001b[A\n",
      "                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09409472346305847, 'eval_f1_micro_t1': 0.49402902810949845, 'eval_f1_macro_t1': 0.38039152563663636, 'eval_f1_weighted_t1': 0.5067162393758164, 'eval_precision_micro_t1': 0.36619910118480187, 'eval_precision_macro_t1': 0.3143929024022859, 'eval_recall_micro_t1': 0.7589613322043466, 'eval_recall_macro_t1': 0.5555517129669492, 'eval_avg_preds_t1': 2.4476666666666667, 'eval_f1_micro_t2': 0.5576015108593012, 'eval_f1_macro_t2': 0.39412698070456126, 'eval_f1_weighted_t2': 0.5402709195549923, 'eval_precision_micro_t2': 0.4792047068370866, 'eval_precision_macro_t2': 0.3846123200697648, 'eval_recall_micro_t2': 0.6666666666666666, 'eval_recall_macro_t2': 0.4565963765692517, 'eval_avg_preds_t2': 1.643, 'eval_f1_micro_t3': 0.5697896749521989, 'eval_f1_macro_t3': 0.3749820358415559, 'eval_f1_weighted_t3': 0.5316810780169903, 'eval_precision_micro_t3': 0.5519978830378407, 'eval_precision_macro_t3': 0.43829197689602534, 'eval_recall_micro_t3': 0.5887665819926616, 'eval_recall_macro_t3': 0.38420670236624616, 'eval_avg_preds_t3': 1.2596666666666667, 'eval_precision_admiration': 0.6914498141263941, 'eval_recall_admiration': 0.6813186813186813, 'eval_f1_admiration': 0.6863468634686347, 'eval_precision_amusement': 0.7473684210526316, 'eval_recall_amusement': 0.8114285714285714, 'eval_f1_amusement': 0.7780821917808219, 'eval_precision_anger': 0.3708609271523179, 'eval_recall_anger': 0.5283018867924528, 'eval_f1_anger': 0.4357976653696498, 'eval_precision_annoyance': 0.32934131736526945, 'eval_recall_annoyance': 0.31976744186046513, 'eval_f1_annoyance': 0.32448377581120946, 'eval_precision_approval': 0.4642857142857143, 'eval_recall_approval': 0.18396226415094338, 'eval_f1_approval': 0.2635135135135135, 'eval_precision_caring': 0.6086956521739131, 'eval_recall_caring': 0.1794871794871795, 'eval_f1_caring': 0.27722772277227725, 'eval_precision_confusion': 0.5192307692307693, 'eval_recall_confusion': 0.3253012048192771, 'eval_f1_confusion': 0.4, 'eval_precision_curiosity': 0.4246575342465753, 'eval_recall_curiosity': 0.6888888888888889, 'eval_f1_curiosity': 0.5254237288135594, 'eval_precision_desire': 0.75, 'eval_recall_desire': 0.20930232558139536, 'eval_f1_desire': 0.32727272727272727, 'eval_precision_disappointment': 1.0, 'eval_recall_disappointment': 0.011111111111111112, 'eval_f1_disappointment': 0.02197802197802198, 'eval_precision_disapproval': 0.3791469194312796, 'eval_recall_disapproval': 0.4878048780487805, 'eval_f1_disapproval': 0.4266666666666667, 'eval_precision_disgust': 0.41379310344827586, 'eval_recall_disgust': 0.2, 'eval_f1_disgust': 0.2696629213483146, 'eval_precision_embarrassment': 0.0, 'eval_recall_embarrassment': 0.0, 'eval_f1_embarrassment': 0.0, 'eval_precision_excitement': 0.0, 'eval_recall_excitement': 0.0, 'eval_f1_excitement': 0.0, 'eval_precision_fear': 0.6111111111111112, 'eval_recall_fear': 0.6226415094339622, 'eval_f1_fear': 0.616822429906542, 'eval_precision_gratitude': 0.9289340101522843, 'eval_recall_gratitude': 0.8970588235294118, 'eval_f1_gratitude': 0.912718204488778, 'eval_precision_grief': 0.0, 'eval_recall_grief': 0.0, 'eval_f1_grief': 0.0, 'eval_precision_joy': 0.7160493827160493, 'eval_recall_joy': 0.5132743362831859, 'eval_f1_joy': 0.5979381443298969, 'eval_precision_love': 0.6645962732919255, 'eval_recall_love': 0.8492063492063492, 'eval_f1_love': 0.7456445993031359, 'eval_precision_nervousness': 0.0, 'eval_recall_nervousness': 0.0, 'eval_f1_nervousness': 0.0, 'eval_precision_optimism': 0.5666666666666667, 'eval_recall_optimism': 0.5354330708661418, 'eval_f1_optimism': 0.5506072874493927, 'eval_precision_pride': 0.0, 'eval_recall_pride': 0.0, 'eval_f1_pride': 0.0, 'eval_precision_realization': 0.0, 'eval_recall_realization': 0.0, 'eval_f1_realization': 0.0, 'eval_precision_relief': 0.0, 'eval_recall_relief': 0.0, 'eval_f1_relief': 0.0, 'eval_precision_remorse': 0.6470588235294118, 'eval_recall_remorse': 0.8048780487804879, 'eval_f1_remorse': 0.717391304347826, 'eval_precision_sadness': 0.4152542372881356, 'eval_recall_sadness': 0.5833333333333334, 'eval_f1_sadness': 0.48514851485148514, 'eval_precision_surprise': 0.4927536231884058, 'eval_recall_surprise': 0.4722222222222222, 'eval_f1_surprise': 0.48226950354609927, 'eval_precision_neutral': 0.530921052631579, 'eval_recall_neutral': 0.8530655391120507, 'eval_f1_neutral': 0.6545012165450121, 'eval_f1_micro_t4': 0.5641495041952708, 'eval_f1_macro_t4': 0.3407785218050714, 'eval_f1_weighted_t4': 0.506777075284443, 'eval_precision_micro_t4': 0.6138778220451527, 'eval_precision_macro_t4': 0.46112319221321413, 'eval_recall_micro_t4': 0.5218741179791138, 'eval_recall_macro_t4': 0.32586202169753264, 'eval_avg_preds_t4': 1.004, 'eval_f1_micro_t5': 0.5433936728133988, 'eval_f1_macro_t5': 0.3084081015087742, 'eval_f1_weighted_t5': 0.47679045570307405, 'eval_precision_micro_t5': 0.6782094594594594, 'eval_precision_macro_t5': 0.396971694751445, 'eval_recall_micro_t5': 0.4532881738639571, 'eval_recall_macro_t5': 0.27960133586617136, 'eval_avg_preds_t5': 0.7893333333333333, 'eval_f1_micro_t6': 0.5002795899347624, 'eval_f1_macro_t6': 0.2719880413260947, 'eval_f1_weighted_t6': 0.436019551347506, 'eval_precision_micro_t6': 0.7365532381997805, 'eval_precision_macro_t6': 0.36304452951095245, 'eval_recall_micro_t6': 0.37877504939316964, 'eval_recall_macro_t6': 0.22843265582626696, 'eval_avg_preds_t6': 0.6073333333333333, 'eval_f1_micro_t7': 0.41825413439397113, 'eval_f1_macro_t7': 0.17404474841176237, 'eval_f1_weighted_t7': 0.3503337151645548, 'eval_precision_micro_t7': 0.8095623987034035, 'eval_precision_macro_t7': 0.350633738286366, 'eval_recall_micro_t7': 0.2819644369178662, 'eval_recall_macro_t7': 0.14116862909367517, 'eval_avg_preds_t7': 0.41133333333333333, 'eval_f1_micro_t8': 0.298339957914426, 'eval_f1_macro_t8': 0.10871120886949016, 'eval_f1_weighted_t8': 0.2430991709112959, 'eval_precision_micro_t8': 0.8692098092643051, 'eval_precision_macro_t8': 0.18309942996031925, 'eval_recall_micro_t8': 0.18007338413773638, 'eval_recall_macro_t8': 0.08669687552249002, 'eval_avg_preds_t8': 0.24466666666666667, 'eval_f1_micro_t9': 0.15022015022015023, 'eval_f1_macro_t9': 0.06379950051465252, 'eval_f1_weighted_t9': 0.10458083067855653, 'eval_precision_micro_t9': 0.9119496855345912, 'eval_precision_macro_t9': 0.12761400856638952, 'eval_recall_micro_t9': 0.08185153824442563, 'eval_recall_macro_t9': 0.052636295478781306, 'eval_avg_preds_t9': 0.106, 'eval_f1_micro': 0.5576015108593012, 'eval_f1_macro': 0.39412698070456126, 'eval_f1_weighted': 0.5402709195549923, 'eval_precision_micro': 0.4792047068370866, 'eval_precision_macro': 0.3846123200697648, 'eval_recall_micro': 0.6666666666666666, 'eval_recall_macro': 0.4565963765692517, 'eval_primary_threshold': 0.2, 'eval_f1_micro_default': 0.5433936728133988, 'eval_f1_macro_default': 0.3084081015087742, 'eval_f1_weighted_default': 0.47679045570307405, 'eval_class_imbalance_ratio': 105.11111450195312, 'eval_prediction_entropy': 1.9931646585464478, 'eval_runtime': 16.0711, 'eval_samples_per_second': 186.671, 'eval_steps_per_second': 23.334, 'epoch': 1.0}\n",
      "üíæ Disk space: 135.6GB free, 45.6% used\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_BCE/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up latest checkpoint checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1300/2500 [12:18<10:31,  1.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0914, 'grad_norm': 0.49678835272789, 'learning_rate': 1.8049952160319234e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1350/2500 [12:44<09:46,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.086, 'grad_norm': 0.4170864224433899, 'learning_rate': 1.6956976786677013e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1400/2500 [13:09<08:46,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.087, 'grad_norm': 0.3934483826160431, 'learning_rate': 1.585331308444989e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1450/2500 [13:34<08:38,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0858, 'grad_norm': 0.7250908613204956, 'learning_rate': 1.4744988882060229e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1500/2500 [13:59<08:31,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0851, 'grad_norm': 0.3878615200519562, 'learning_rate': 1.3638057461966143e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1550/2500 [14:24<08:41,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0882, 'grad_norm': 0.44319647550582886, 'learning_rate': 1.2538564499731836e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1600/2500 [14:50<07:39,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0889, 'grad_norm': 0.44023212790489197, 'learning_rate': 1.1452515044644134e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1614/2500 [14:57<07:25,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_BCE/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up latest checkpoint checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1615/2500 [15:45<3:37:44, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 135.6GB free, 45.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1650/2500 [16:03<07:16,  1.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0832, 'grad_norm': 0.5500261783599854, 'learning_rate': 1.0385840722215626e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1700/2500 [16:28<06:48,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0872, 'grad_norm': 0.4578280448913574, 'learning_rate': 9.344367337703098e-06, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1750/2500 [16:53<06:10,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0877, 'grad_norm': 0.3743763864040375, 'learning_rate': 8.33378305757938e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1800/2500 [17:18<06:22,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0783, 'grad_norm': 0.4027460813522339, 'learning_rate': 7.359607342740614e-06, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1850/2500 [17:44<05:17,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0804, 'grad_norm': 0.4650803208351135, 'learning_rate': 6.427160803124786e-06, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1900/2500 [18:09<05:09,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0792, 'grad_norm': 0.5031388401985168, 'learning_rate': 5.541536138385337e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1950/2500 [18:34<04:37,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0785, 'grad_norm': 0.5152012705802917, 'learning_rate': 4.707570323331603e-06, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2000/2500 [19:01<04:15,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.081, 'grad_norm': 0.564777135848999, 'learning_rate': 3.9298181900497735e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2050/2500 [19:26<03:49,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0818, 'grad_norm': 0.41539525985717773, 'learning_rate': 3.212527550989494e-06, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2100/2500 [19:51<03:24,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0824, 'grad_norm': 2.793358087539673, 'learning_rate': 2.559615998885317e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2150/2500 [20:16<02:56,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0839, 'grad_norm': 0.4783230423927307, 'learning_rate': 1.9746495102236556e-06, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2200/2500 [20:41<02:35,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0771, 'grad_norm': 0.4559035897254944, 'learning_rate': 1.460822969115837e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2207/2500 [20:45<02:30,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 135.6GB free, 45.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2250/2500 [21:06<02:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0815, 'grad_norm': 0.3376582860946655, 'learning_rate': 1.02094271794895e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2300/2500 [21:30<01:46,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0786, 'grad_norm': 0.5499700307846069, 'learning_rate': 6.574112301168966e-07, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2350/2500 [21:56<01:11,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0747, 'grad_norm': 0.48938435316085815, 'learning_rate': 3.7221398854383193e-07, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2400/2500 [22:20<00:47,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0822, 'grad_norm': 0.4433704614639282, 'learning_rate': 1.669086416649329e-07, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2450/2500 [22:46<00:23,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.076, 'grad_norm': 0.3730968236923218, 'learning_rate': 4.261649609079099e-08, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [23:11<00:00,  1.97it/s]\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0802, 'grad_norm': 0.3422897458076477, 'learning_rate': 1.639241954842774e-11, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 4/375 [00:00<00:11, 32.95it/s]\u001b[A\n",
      "  2%|‚ñè         | 8/375 [00:00<00:13, 27.57it/s]\u001b[A\n",
      "  3%|‚ñé         | 11/375 [00:00<00:13, 26.40it/s]\u001b[A\n",
      "  4%|‚ñé         | 14/375 [00:00<00:13, 25.82it/s]\u001b[A\n",
      "  5%|‚ñç         | 17/375 [00:00<00:14, 25.29it/s]\u001b[A\n",
      "  5%|‚ñå         | 20/375 [00:00<00:14, 24.94it/s]\u001b[A\n",
      "  6%|‚ñå         | 23/375 [00:00<00:14, 24.91it/s]\u001b[A\n",
      "  7%|‚ñã         | 26/375 [00:01<00:14, 24.92it/s]\u001b[A\n",
      "  8%|‚ñä         | 29/375 [00:01<00:13, 24.83it/s]\u001b[A\n",
      "  9%|‚ñä         | 32/375 [00:01<00:13, 24.71it/s]\u001b[A\n",
      "  9%|‚ñâ         | 35/375 [00:01<00:13, 24.67it/s]\u001b[A\n",
      " 10%|‚ñà         | 38/375 [00:01<00:13, 24.69it/s]\u001b[A\n",
      " 11%|‚ñà         | 41/375 [00:01<00:13, 24.60it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 44/375 [00:01<00:13, 24.62it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 47/375 [00:01<00:13, 24.64it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 50/375 [00:01<00:13, 24.68it/s]\u001b[A\n",
      " 14%|‚ñà‚ñç        | 53/375 [00:02<00:13, 24.67it/s]\u001b[A\n",
      " 15%|‚ñà‚ñç        | 56/375 [00:02<00:13, 24.46it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 59/375 [00:02<00:12, 24.51it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 62/375 [00:02<00:12, 24.12it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 65/375 [00:02<00:12, 24.16it/s]\u001b[A\n",
      " 18%|‚ñà‚ñä        | 68/375 [00:02<00:12, 24.21it/s]\u001b[A\n",
      " 19%|‚ñà‚ñâ        | 71/375 [00:02<00:12, 24.16it/s]\u001b[A\n",
      " 20%|‚ñà‚ñâ        | 74/375 [00:02<00:12, 23.95it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà        | 77/375 [00:03<00:12, 24.12it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà‚ñè       | 80/375 [00:03<00:12, 24.22it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 83/375 [00:03<00:12, 24.31it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 86/375 [00:03<00:11, 24.42it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñé       | 89/375 [00:03<00:11, 24.48it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 92/375 [00:03<00:11, 24.46it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 95/375 [00:03<00:11, 24.43it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 98/375 [00:03<00:11, 24.22it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 101/375 [00:04<00:11, 24.19it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 104/375 [00:04<00:11, 24.05it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñä       | 107/375 [00:04<00:11, 24.10it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 110/375 [00:04<00:11, 23.93it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñà       | 113/375 [00:04<00:10, 24.14it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 116/375 [00:04<00:10, 24.03it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 119/375 [00:04<00:10, 24.24it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 122/375 [00:04<00:10, 24.38it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 125/375 [00:05<00:10, 24.50it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 128/375 [00:05<00:10, 24.55it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 131/375 [00:05<00:09, 24.47it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 134/375 [00:05<00:09, 24.51it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 137/375 [00:05<00:09, 24.52it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 140/375 [00:05<00:09, 24.52it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 143/375 [00:05<00:09, 24.57it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 146/375 [00:05<00:09, 24.48it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 149/375 [00:06<00:09, 24.23it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 152/375 [00:06<00:09, 23.90it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 155/375 [00:06<00:09, 23.69it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 158/375 [00:06<00:09, 23.69it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 161/375 [00:06<00:09, 23.55it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 164/375 [00:06<00:08, 23.54it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 167/375 [00:06<00:08, 23.34it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 170/375 [00:06<00:08, 23.49it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 173/375 [00:07<00:08, 23.73it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 176/375 [00:07<00:08, 23.86it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 179/375 [00:07<00:08, 24.08it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 182/375 [00:07<00:07, 24.27it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 185/375 [00:07<00:07, 24.38it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 188/375 [00:07<00:07, 24.41it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 191/375 [00:07<00:07, 24.51it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 194/375 [00:07<00:07, 24.54it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 197/375 [00:08<00:07, 24.60it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 200/375 [00:08<00:07, 24.63it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 203/375 [00:08<00:06, 24.66it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 206/375 [00:08<00:06, 24.49it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 209/375 [00:08<00:06, 24.44it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 212/375 [00:08<00:06, 24.48it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 215/375 [00:08<00:06, 24.54it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 218/375 [00:08<00:06, 24.57it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 221/375 [00:09<00:06, 24.21it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 224/375 [00:09<00:06, 24.05it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 227/375 [00:09<00:06, 24.21it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 230/375 [00:09<00:05, 24.39it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 233/375 [00:09<00:05, 24.39it/s]\u001b[A\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 236/375 [00:09<00:05, 24.42it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 239/375 [00:09<00:05, 24.53it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 242/375 [00:09<00:05, 24.60it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 245/375 [00:10<00:05, 24.62it/s]\u001b[A\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 248/375 [00:10<00:05, 24.62it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 251/375 [00:10<00:05, 24.38it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 254/375 [00:10<00:04, 24.40it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 257/375 [00:10<00:04, 24.48it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 260/375 [00:10<00:04, 24.55it/s]\u001b[A\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 263/375 [00:10<00:04, 24.57it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 266/375 [00:10<00:04, 24.63it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 269/375 [00:11<00:04, 24.63it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 272/375 [00:11<00:04, 24.68it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 275/375 [00:11<00:04, 24.47it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 278/375 [00:11<00:04, 24.14it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 281/375 [00:11<00:03, 24.30it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 284/375 [00:11<00:03, 24.28it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 287/375 [00:11<00:03, 24.31it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 290/375 [00:11<00:03, 24.34it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 293/375 [00:11<00:03, 24.47it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 296/375 [00:12<00:03, 24.53it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 299/375 [00:12<00:03, 24.61it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 302/375 [00:12<00:02, 24.47it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 305/375 [00:12<00:02, 24.24it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 308/375 [00:12<00:02, 24.41it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 311/375 [00:12<00:02, 24.53it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 314/375 [00:12<00:02, 24.54it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 317/375 [00:12<00:02, 24.58it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 320/375 [00:13<00:02, 24.60it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 323/375 [00:13<00:02, 24.67it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 326/375 [00:13<00:01, 24.69it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 329/375 [00:13<00:01, 24.57it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 332/375 [00:13<00:01, 24.50it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 335/375 [00:13<00:01, 24.57it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 338/375 [00:13<00:01, 24.66it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 341/375 [00:13<00:01, 24.66it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 344/375 [00:14<00:01, 24.57it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 347/375 [00:14<00:01, 24.62it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 350/375 [00:14<00:01, 24.67it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 353/375 [00:14<00:00, 24.73it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 356/375 [00:14<00:00, 24.71it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 359/375 [00:14<00:00, 24.69it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 362/375 [00:14<00:00, 24.63it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 365/375 [00:14<00:00, 24.45it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 368/375 [00:15<00:00, 24.52it/s]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 371/375 [00:15<00:00, 24.62it/s]\u001b[A\n",
      "                                                   A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [23:27<00:00,  1.97it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:15<00:00, 24.69it/s]\u001b[A\n",
      "                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0874042958021164, 'eval_f1_micro_t1': 0.5289256198347108, 'eval_f1_macro_t1': 0.42733735052362515, 'eval_f1_weighted_t1': 0.5454759585924079, 'eval_precision_micro_t1': 0.4009908203409588, 'eval_precision_macro_t1': 0.33442746325251305, 'eval_recall_micro_t1': 0.776742873271239, 'eval_recall_macro_t1': 0.6180058538181591, 'eval_avg_preds_t1': 2.2876666666666665, 'eval_f1_micro_t2': 0.5869905013827101, 'eval_f1_macro_t2': 0.46498008872633834, 'eval_f1_weighted_t2': 0.5845004256118193, 'eval_precision_micro_t2': 0.5113112693757855, 'eval_precision_macro_t2': 0.46262035639837645, 'eval_recall_micro_t2': 0.6889641546711827, 'eval_recall_macro_t2': 0.5216328224795809, 'eval_avg_preds_t2': 1.5913333333333333, 'eval_f1_micro_t3': 0.6002747252747253, 'eval_f1_macro_t3': 0.45185881333911604, 'eval_f1_weighted_t3': 0.5844331425995215, 'eval_precision_micro_t3': 0.5846936044955847, 'eval_precision_macro_t3': 0.49994185813832104, 'eval_recall_micro_t3': 0.6167090036692069, 'eval_recall_macro_t3': 0.4511331897794411, 'eval_avg_preds_t3': 1.2456666666666667, 'eval_precision_admiration': 0.6491228070175439, 'eval_recall_admiration': 0.8131868131868132, 'eval_f1_admiration': 0.7219512195121951, 'eval_precision_amusement': 0.7169811320754716, 'eval_recall_amusement': 0.8685714285714285, 'eval_f1_amusement': 0.7855297157622739, 'eval_precision_anger': 0.4358974358974359, 'eval_recall_anger': 0.4811320754716981, 'eval_f1_anger': 0.45739910313901344, 'eval_precision_annoyance': 0.3443396226415094, 'eval_recall_annoyance': 0.42441860465116277, 'eval_f1_annoyance': 0.3802083333333333, 'eval_precision_approval': 0.4457831325301205, 'eval_recall_approval': 0.3490566037735849, 'eval_f1_approval': 0.3915343915343915, 'eval_precision_caring': 0.5538461538461539, 'eval_recall_caring': 0.46153846153846156, 'eval_f1_caring': 0.5034965034965035, 'eval_precision_confusion': 0.4367816091954023, 'eval_recall_confusion': 0.4578313253012048, 'eval_f1_confusion': 0.4470588235294118, 'eval_precision_curiosity': 0.47692307692307695, 'eval_recall_curiosity': 0.6888888888888889, 'eval_f1_curiosity': 0.5636363636363636, 'eval_precision_desire': 0.46875, 'eval_recall_desire': 0.3488372093023256, 'eval_f1_desire': 0.4, 'eval_precision_disappointment': 0.3888888888888889, 'eval_recall_disappointment': 0.23333333333333334, 'eval_f1_disappointment': 0.2916666666666667, 'eval_precision_disapproval': 0.44171779141104295, 'eval_recall_disapproval': 0.43902439024390244, 'eval_f1_disapproval': 0.44036697247706424, 'eval_precision_disgust': 0.4339622641509434, 'eval_recall_disgust': 0.38333333333333336, 'eval_f1_disgust': 0.40707964601769914, 'eval_precision_embarrassment': 1.0, 'eval_recall_embarrassment': 0.23529411764705882, 'eval_f1_embarrassment': 0.38095238095238093, 'eval_precision_excitement': 0.4230769230769231, 'eval_recall_excitement': 0.20754716981132076, 'eval_f1_excitement': 0.27848101265822783, 'eval_precision_fear': 0.7317073170731707, 'eval_recall_fear': 0.5660377358490566, 'eval_f1_fear': 0.6382978723404256, 'eval_precision_gratitude': 0.9238578680203046, 'eval_recall_gratitude': 0.8921568627450981, 'eval_f1_gratitude': 0.9077306733167082, 'eval_precision_grief': 0.0, 'eval_recall_grief': 0.0, 'eval_f1_grief': 0.0, 'eval_precision_joy': 0.591304347826087, 'eval_recall_joy': 0.6017699115044248, 'eval_f1_joy': 0.5964912280701754, 'eval_precision_love': 0.6748466257668712, 'eval_recall_love': 0.873015873015873, 'eval_f1_love': 0.7612456747404844, 'eval_precision_nervousness': 0.0, 'eval_recall_nervousness': 0.0, 'eval_f1_nervousness': 0.0, 'eval_precision_optimism': 0.6486486486486487, 'eval_recall_optimism': 0.5669291338582677, 'eval_f1_optimism': 0.6050420168067226, 'eval_precision_pride': 0.0, 'eval_recall_pride': 0.0, 'eval_f1_pride': 0.0, 'eval_precision_realization': 0.75, 'eval_recall_realization': 0.08333333333333333, 'eval_f1_realization': 0.15, 'eval_precision_relief': 0.0, 'eval_recall_relief': 0.0, 'eval_f1_relief': 0.0, 'eval_precision_remorse': 0.7948717948717948, 'eval_recall_remorse': 0.7560975609756098, 'eval_f1_remorse': 0.775, 'eval_precision_sadness': 0.4811320754716981, 'eval_recall_sadness': 0.6071428571428571, 'eval_f1_sadness': 0.5368421052631579, 'eval_precision_surprise': 0.5735294117647058, 'eval_recall_surprise': 0.5416666666666666, 'eval_f1_surprise': 0.5571428571428572, 'eval_precision_neutral': 0.6124031007751938, 'eval_recall_neutral': 0.7515856236786469, 'eval_f1_neutral': 0.6748932130991931, 'eval_f1_micro_t4': 0.5916134913400183, 'eval_f1_macro_t4': 0.41891519331897664, 'eval_f1_weighted_t4': 0.5661507485631289, 'eval_precision_micro_t4': 0.6406712734452122, 'eval_precision_macro_t4': 0.5110876019141133, 'eval_recall_micro_t4': 0.5495342929720576, 'eval_recall_macro_t4': 0.38964240277618617, 'eval_avg_preds_t4': 1.013, 'eval_f1_micro_t5': 0.5737433862433863, 'eval_f1_macro_t5': 0.39636257752892384, 'eval_f1_weighted_t5': 0.5413112307623159, 'eval_precision_micro_t5': 0.6926147704590818, 'eval_precision_macro_t5': 0.5193445241983333, 'eval_recall_micro_t5': 0.4896979960485464, 'eval_recall_macro_t5': 0.34457401788797243, 'eval_avg_preds_t5': 0.835, 'eval_f1_micro_t6': 0.5369103348937703, 'eval_f1_macro_t6': 0.3574183050687164, 'eval_f1_weighted_t6': 0.4958879694131517, 'eval_precision_micro_t6': 0.7414221780208852, 'eval_precision_macro_t6': 0.5341901805090532, 'eval_recall_micro_t6': 0.4208298052497883, 'eval_recall_macro_t6': 0.29376921049292976, 'eval_avg_preds_t6': 0.6703333333333333, 'eval_f1_micro_t7': 0.4816774446404076, 'eval_f1_macro_t7': 0.29404061876060444, 'eval_f1_weighted_t7': 0.43163422058960066, 'eval_precision_micro_t7': 0.7878205128205128, 'eval_precision_macro_t7': 0.5696897918942755, 'eval_recall_micro_t7': 0.3468811741462038, 'eval_recall_macro_t7': 0.2296106171117445, 'eval_avg_preds_t7': 0.52, 'eval_f1_micro_t8': 0.40498710232158214, 'eval_f1_macro_t8': 0.19560609128809703, 'eval_f1_weighted_t8': 0.34616050101284823, 'eval_precision_micro_t8': 0.8494138863841298, 'eval_precision_macro_t8': 0.5043324926083985, 'eval_recall_micro_t8': 0.26587637595258257, 'eval_recall_macro_t8': 0.15179228968695807, 'eval_avg_preds_t8': 0.36966666666666664, 'eval_f1_micro_t9': 0.26262626262626265, 'eval_f1_macro_t9': 0.1036294382360282, 'eval_f1_weighted_t9': 0.2062311833724963, 'eval_precision_micro_t9': 0.8878048780487805, 'eval_precision_macro_t9': 0.19161501864990238, 'eval_recall_micro_t9': 0.15410668924640136, 'eval_recall_macro_t9': 0.0835986582129784, 'eval_avg_preds_t9': 0.205, 'eval_f1_micro': 0.5869905013827101, 'eval_f1_macro': 0.46498008872633834, 'eval_f1_weighted': 0.5845004256118193, 'eval_precision_micro': 0.5113112693757855, 'eval_precision_macro': 0.46262035639837645, 'eval_recall_micro': 0.6889641546711827, 'eval_recall_macro': 0.5216328224795809, 'eval_primary_threshold': 0.2, 'eval_f1_micro_default': 0.5737433862433863, 'eval_f1_macro_default': 0.39636257752892384, 'eval_f1_weighted_default': 0.5413112307623159, 'eval_class_imbalance_ratio': 105.11111450195312, 'eval_prediction_entropy': 1.6538339853286743, 'eval_runtime': 15.8246, 'eval_samples_per_second': 189.579, 'eval_steps_per_second': 23.697, 'epoch': 2.0}\n",
      "üíæ Disk space: 135.6GB free, 45.6% used\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_BCE/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up latest checkpoint checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [28:10<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1690.2287, 'train_samples_per_second': 23.665, 'train_steps_per_second': 1.479, 'train_loss': 0.11844691858291626, 'epoch': 2.0}\n",
      "‚úÖ Saved ensemble models to ./outputs/phase1_BCE_ensemble\n",
      "üìä Final evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:15<00:00, 23.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Performing final backup to Google Drive...\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_BCE/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up checkpoint-1250 to Google Drive\n",
      "‚úÖ Backed up checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n",
      "‚úÖ Training completed!\n",
      "üìà Final F1 Macro: 0.4650\n",
      "üìà Final F1 Micro: 0.5870\n",
      "üìà Final F1 Weighted: 0.5845\n",
      "üìä Class Imbalance Ratio: 105.11\n",
      "üî¨ Scientific log: ./outputs/phase1_BCE/scientific_log_20250910_131159.json\n",
      "üíæ Model saved to: ./outputs/phase1_BCE\n",
      "‚úÖ BCE completed successfully!\n",
      "üöÄ Starting Asymmetric on GPU 0\n",
      "Command: python3 notebooks/scripts/train_deberta_local.py --output_dir ./outputs/phase1_Asymmetric --model_type deberta-v3-large --per_device_train_batch_size 4 --per_device_eval_batch_size 8 --gradient_accumulation_steps 4 --num_train_epochs 2 --learning_rate 3e-5 --lr_scheduler_type cosine --warmup_ratio 0.15 --weight_decay 0.01 --fp16 --max_length 256 --max_train_samples 20000 --max_eval_samples 3000 --augment_prob 0 --use_asymmetric_loss\n",
      "üöÄ Executing training command...\n",
      "üíæ Disk space at startup: 133.9GB free, 46.2% used\n",
      "üöÄ GoEmotions DeBERTa Training (SCIENTIFIC VERSION)\n",
      "============================================================\n",
      "üìÅ Output directory: ./outputs/phase1_Asymmetric\n",
      "ü§ñ Model: deberta-v3-large (from local cache)\n",
      "üìä Dataset: GoEmotions (from local cache)\n",
      "üî¨ Scientific logging: ENABLED\n",
      "ü§ñ Loading deberta-v3-large...\n",
      "üìÅ Found local cache at models/deberta-v3-large\n",
      "‚úÖ deberta-v3-large tokenizer loaded from local cache\n",
      "‚úÖ deberta-v3-large model loaded from local cache\n",
      "üìä Loading GoEmotions dataset from local cache...\n",
      "‚úÖ GoEmotions dataset loaded from local cache\n",
      "   Training examples: 43410\n",
      "   Validation examples: 5426\n",
      "   Total emotions: 28\n",
      "üîÑ Creating datasets...\n",
      "‚úÖ Created 43410 training examples\n",
      "‚úÖ Created 5426 validation examples\n",
      "üîÑ Limiting training data: 43410 ‚Üí 20000 samples\n",
      "‚úÖ Using 20000 training examples (subset for quick screening)\n",
      "üîÑ Limiting validation data: 5426 ‚Üí 3000 samples\n",
      "‚úÖ Using 3000 validation examples (subset for quick screening)\n",
      "üîß Disabling gradient checkpointing to prevent RuntimeError during backward pass\n",
      "üéØ Using Asymmetric Loss for better class imbalance handling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 13:46:27,267] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-09-10 13:46:28,913] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "üöÄ Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "  2%|‚ñè         | 50/2500 [00:28<21:33,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1418, 'grad_norm': 7.62939453125e-05, 'learning_rate': 3.92e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 100/2500 [00:54<21:33,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8611, 'grad_norm': 7.629395258845761e-05, 'learning_rate': 7.92e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 150/2500 [01:21<22:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4881, 'grad_norm': 7.629393076058477e-05, 'learning_rate': 1.192e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 200/2500 [01:48<20:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3316, 'grad_norm': 0.000152587890625, 'learning_rate': 1.584e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 250/2500 [02:14<19:55,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3269, 'grad_norm': 0.000152587890625, 'learning_rate': 1.984e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 300/2500 [02:40<18:56,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.324, 'grad_norm': 0.00015258786152116954, 'learning_rate': 2.384e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 350/2500 [03:07<18:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3209, 'grad_norm': 0.000152587890625, 'learning_rate': 2.784e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 400/2500 [03:33<18:46,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3173, 'grad_norm': 0.00015258787607308477, 'learning_rate': 2.9991329243963613e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 450/2500 [04:00<17:54,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3138, 'grad_norm': 0.000152587890625, 'learning_rate': 2.9912729535560987e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 500/2500 [04:26<17:07,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3082, 'grad_norm': 0.000152587890625, 'learning_rate': 2.975268166974585e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 550/2500 [04:52<16:26,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2982, 'grad_norm': 0.00015258787607308477, 'learning_rate': 2.9512059772461243e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 559/2500 [04:57<16:23,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 133.9GB free, 46.2% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 600/2500 [05:19<16:29,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2984, 'grad_norm': 0.00015258790517691523, 'learning_rate': 2.9192178037069284e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 650/2500 [05:45<16:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3059, 'grad_norm': 0.00030517578125, 'learning_rate': 2.8803477710488058e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 700/2500 [06:12<15:59,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2998, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.833222378894202e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 750/2500 [06:38<15:35,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2991, 'grad_norm': 0.00030517578125, 'learning_rate': 2.7788153884297048e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 800/2500 [07:04<15:01,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2858, 'grad_norm': 0.00030517578125, 'learning_rate': 2.7174239517704316e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 850/2500 [07:31<14:40,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2742, 'grad_norm': 0.00030517578125, 'learning_rate': 2.649383367654611e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 900/2500 [07:57<14:24,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2822, 'grad_norm': 0.00030517578125, 'learning_rate': 2.5750652501581428e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 950/2500 [08:24<13:01,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2895, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.4948754990673823e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 1000/2500 [08:50<13:20,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.268, 'grad_norm': 0.00030517578125, 'learning_rate': 2.4092520829952604e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1050/2500 [09:16<12:48,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2755, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.3186626473485966e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1100/2500 [09:42<12:23,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2668, 'grad_norm': 0.00030517578125, 'learning_rate': 2.2236019602110508e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1128/2500 [09:57<12:36,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 133.9GB free, 46.2% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1150/2500 [10:09<11:58,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.265, 'grad_norm': 0.0003051757230423391, 'learning_rate': 2.1245892100914246e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1200/2500 [10:35<11:11,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2671, 'grad_norm': 0.00030517578125, 'learning_rate': 2.0221651702960638e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1250/2500 [11:02<10:45,  1.94it/s]\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2527, 'grad_norm': 0.00030517578125, 'learning_rate': 1.9168892454125852e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 4/375 [00:00<00:11, 32.51it/s]\u001b[A\n",
      "  2%|‚ñè         | 8/375 [00:00<00:13, 26.67it/s]\u001b[A\n",
      "  3%|‚ñé         | 11/375 [00:00<00:14, 25.79it/s]\u001b[A\n",
      "  4%|‚ñé         | 14/375 [00:00<00:14, 24.93it/s]\u001b[A\n",
      "  5%|‚ñç         | 17/375 [00:00<00:14, 24.58it/s]\u001b[A\n",
      "  5%|‚ñå         | 20/375 [00:00<00:14, 24.35it/s]\u001b[A\n",
      "  6%|‚ñå         | 23/375 [00:00<00:14, 24.21it/s]\u001b[A\n",
      "  7%|‚ñã         | 26/375 [00:01<00:14, 24.27it/s]\u001b[A\n",
      "  8%|‚ñä         | 29/375 [00:01<00:14, 24.32it/s]\u001b[A\n",
      "  9%|‚ñä         | 32/375 [00:01<00:14, 24.12it/s]\u001b[A\n",
      "  9%|‚ñâ         | 35/375 [00:01<00:14, 24.15it/s]\u001b[A\n",
      " 10%|‚ñà         | 38/375 [00:01<00:14, 23.93it/s]\u001b[A\n",
      " 11%|‚ñà         | 41/375 [00:01<00:13, 23.90it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 44/375 [00:01<00:13, 24.06it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 47/375 [00:01<00:13, 24.21it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 50/375 [00:02<00:13, 24.29it/s]\u001b[A\n",
      " 14%|‚ñà‚ñç        | 53/375 [00:02<00:13, 24.37it/s]\u001b[A\n",
      " 15%|‚ñà‚ñç        | 56/375 [00:02<00:13, 24.38it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 59/375 [00:02<00:12, 24.46it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 62/375 [00:02<00:12, 24.37it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 65/375 [00:02<00:12, 24.38it/s]\u001b[A\n",
      " 18%|‚ñà‚ñä        | 68/375 [00:02<00:12, 24.41it/s]\u001b[A\n",
      " 19%|‚ñà‚ñâ        | 71/375 [00:02<00:12, 24.45it/s]\u001b[A\n",
      " 20%|‚ñà‚ñâ        | 74/375 [00:03<00:12, 23.70it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà        | 77/375 [00:03<00:13, 22.88it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà‚ñè       | 80/375 [00:03<00:12, 23.02it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 83/375 [00:03<00:13, 22.41it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 86/375 [00:03<00:12, 22.43it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñé       | 89/375 [00:03<00:13, 21.65it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 92/375 [00:03<00:13, 21.70it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 95/375 [00:04<00:13, 21.45it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 98/375 [00:04<00:12, 21.99it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 101/375 [00:04<00:12, 22.55it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 104/375 [00:04<00:11, 23.00it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñä       | 107/375 [00:04<00:11, 22.85it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 110/375 [00:04<00:11, 22.85it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñà       | 113/375 [00:04<00:11, 22.23it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 116/375 [00:04<00:11, 22.80it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 119/375 [00:05<00:11, 23.20it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 122/375 [00:05<00:10, 23.47it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 125/375 [00:05<00:10, 23.71it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 128/375 [00:05<00:10, 23.89it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 131/375 [00:05<00:10, 23.96it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 134/375 [00:05<00:10, 24.04it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 137/375 [00:05<00:09, 24.11it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 140/375 [00:05<00:10, 22.75it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 143/375 [00:06<00:10, 22.61it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 146/375 [00:06<00:10, 22.52it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 149/375 [00:06<00:09, 22.76it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 152/375 [00:06<00:09, 23.05it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 155/375 [00:06<00:09, 23.28it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 158/375 [00:06<00:09, 23.58it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 161/375 [00:06<00:08, 23.78it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 164/375 [00:06<00:08, 23.57it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 167/375 [00:07<00:08, 23.77it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 170/375 [00:07<00:08, 23.90it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 173/375 [00:07<00:08, 23.53it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 176/375 [00:07<00:08, 23.74it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 179/375 [00:07<00:08, 23.84it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 182/375 [00:07<00:08, 22.79it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 185/375 [00:07<00:08, 23.26it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 188/375 [00:07<00:07, 23.63it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 191/375 [00:08<00:08, 22.07it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 194/375 [00:08<00:08, 21.23it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 197/375 [00:08<00:08, 20.39it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 200/375 [00:08<00:08, 20.32it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 203/375 [00:08<00:08, 21.23it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 206/375 [00:08<00:07, 21.93it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 209/375 [00:08<00:07, 22.46it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 212/375 [00:09<00:07, 22.95it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 215/375 [00:09<00:06, 23.29it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 218/375 [00:09<00:06, 23.58it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 221/375 [00:09<00:06, 23.70it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 224/375 [00:09<00:06, 23.69it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 227/375 [00:09<00:06, 23.49it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 230/375 [00:09<00:06, 23.61it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 233/375 [00:09<00:05, 23.72it/s]\u001b[A\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 236/375 [00:10<00:05, 23.82it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 239/375 [00:10<00:05, 23.84it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 242/375 [00:10<00:05, 23.90it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 245/375 [00:10<00:05, 23.80it/s]\u001b[A\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 248/375 [00:10<00:05, 23.68it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 251/375 [00:10<00:05, 23.56it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 254/375 [00:10<00:05, 23.77it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 257/375 [00:10<00:04, 23.76it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 260/375 [00:11<00:04, 23.67it/s]\u001b[A\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 263/375 [00:11<00:04, 23.61it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 266/375 [00:11<00:04, 23.31it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 269/375 [00:11<00:04, 23.36it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 272/375 [00:11<00:04, 23.52it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 275/375 [00:11<00:04, 23.62it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 278/375 [00:11<00:04, 23.65it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 281/375 [00:12<00:03, 23.67it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 284/375 [00:12<00:03, 23.57it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 287/375 [00:12<00:03, 23.67it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 290/375 [00:12<00:03, 23.60it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 293/375 [00:12<00:03, 23.67it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 296/375 [00:12<00:03, 23.82it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 299/375 [00:12<00:03, 23.94it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 302/375 [00:12<00:03, 24.06it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 305/375 [00:13<00:02, 23.85it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 308/375 [00:13<00:02, 23.86it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 311/375 [00:13<00:02, 23.95it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 314/375 [00:13<00:02, 23.95it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 317/375 [00:13<00:02, 24.06it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 320/375 [00:13<00:02, 24.03it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 323/375 [00:13<00:02, 23.65it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 326/375 [00:13<00:02, 23.13it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 329/375 [00:14<00:01, 23.21it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 332/375 [00:14<00:01, 23.20it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 335/375 [00:14<00:01, 23.07it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 338/375 [00:14<00:01, 22.02it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 341/375 [00:14<00:01, 21.57it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 344/375 [00:14<00:01, 21.79it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 347/375 [00:14<00:01, 22.17it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 350/375 [00:14<00:01, 22.42it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 353/375 [00:15<00:00, 22.55it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 356/375 [00:15<00:00, 22.89it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 359/375 [00:15<00:00, 23.06it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 362/375 [00:15<00:00, 23.18it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 365/375 [00:15<00:00, 23.26it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 368/375 [00:15<00:00, 23.20it/s]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 371/375 [00:15<00:00, 23.37it/s]\u001b[A\n",
      "                                                   A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1250/2500 [11:18<10:45,  1.94it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:16<00:00, 23.45it/s]\u001b[A\n",
      "                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06385811418294907, 'eval_f1_micro_t1': 0.13451461941522339, 'eval_f1_macro_t1': 0.12044808876232042, 'eval_f1_weighted_t1': 0.25053831578287994, 'eval_precision_micro_t1': 0.0723864052175036, 'eval_precision_macro_t1': 0.07252441162577487, 'eval_recall_micro_t1': 0.9491955969517358, 'eval_recall_macro_t1': 0.8086042760287163, 'eval_avg_preds_t1': 15.486333333333333, 'eval_f1_micro_t2': 0.3342984252524539, 'eval_f1_macro_t2': 0.19840005220146445, 'eval_f1_weighted_t2': 0.35125469425688355, 'eval_precision_micro_t2': 0.22292333772838577, 'eval_precision_macro_t2': 0.156122505057353, 'eval_recall_micro_t2': 0.668077900084674, 'eval_recall_macro_t2': 0.38763531826934183, 'eval_avg_preds_t2': 3.5393333333333334, 'eval_f1_micro_t3': 0.4408790616152083, 'eval_f1_macro_t3': 0.16657129993108755, 'eval_f1_weighted_t3': 0.3398252463718024, 'eval_precision_micro_t3': 0.4220443985544657, 'eval_precision_macro_t3': 0.17295669617493117, 'eval_recall_micro_t3': 0.46147332768839966, 'eval_recall_macro_t3': 0.19908394379939137, 'eval_avg_preds_t3': 1.2913333333333334, 'eval_precision_admiration': 0.5636363636363636, 'eval_recall_admiration': 0.7948717948717948, 'eval_f1_admiration': 0.6595744680851063, 'eval_precision_amusement': 0.5526315789473685, 'eval_recall_amusement': 0.36, 'eval_f1_amusement': 0.4359861591695502, 'eval_precision_anger': 0.18900343642611683, 'eval_recall_anger': 0.5188679245283019, 'eval_f1_anger': 0.2770780856423174, 'eval_precision_annoyance': 0.27058823529411763, 'eval_recall_annoyance': 0.13372093023255813, 'eval_f1_annoyance': 0.17898832684824903, 'eval_precision_approval': 0.15, 'eval_recall_approval': 0.014150943396226415, 'eval_f1_approval': 0.02586206896551724, 'eval_precision_caring': 0.0, 'eval_recall_caring': 0.0, 'eval_f1_caring': 0.0, 'eval_precision_confusion': 0.0, 'eval_recall_confusion': 0.0, 'eval_f1_confusion': 0.0, 'eval_precision_curiosity': 0.0, 'eval_recall_curiosity': 0.0, 'eval_f1_curiosity': 0.0, 'eval_precision_desire': 0.0, 'eval_recall_desire': 0.0, 'eval_f1_desire': 0.0, 'eval_precision_disappointment': 0.0, 'eval_recall_disappointment': 0.0, 'eval_f1_disappointment': 0.0, 'eval_precision_disapproval': 0.14285714285714285, 'eval_recall_disapproval': 0.006097560975609756, 'eval_f1_disapproval': 0.011695906432748537, 'eval_precision_disgust': 0.0, 'eval_recall_disgust': 0.0, 'eval_f1_disgust': 0.0, 'eval_precision_embarrassment': 0.0, 'eval_recall_embarrassment': 0.0, 'eval_f1_embarrassment': 0.0, 'eval_precision_excitement': 0.0, 'eval_recall_excitement': 0.0, 'eval_f1_excitement': 0.0, 'eval_precision_fear': 0.0, 'eval_recall_fear': 0.0, 'eval_f1_fear': 0.0, 'eval_precision_gratitude': 0.9470899470899471, 'eval_recall_gratitude': 0.8774509803921569, 'eval_f1_gratitude': 0.910941475826972, 'eval_precision_grief': 0.0, 'eval_recall_grief': 0.0, 'eval_f1_grief': 0.0, 'eval_precision_joy': 0.18099547511312217, 'eval_recall_joy': 0.35398230088495575, 'eval_f1_joy': 0.23952095808383234, 'eval_precision_love': 0.38181818181818183, 'eval_recall_love': 0.8333333333333334, 'eval_f1_love': 0.5236907730673317, 'eval_precision_nervousness': 0.0, 'eval_recall_nervousness': 0.0, 'eval_f1_nervousness': 0.0, 'eval_precision_optimism': 0.0, 'eval_recall_optimism': 0.0, 'eval_f1_optimism': 0.0, 'eval_precision_pride': 0.0, 'eval_recall_pride': 0.0, 'eval_f1_pride': 0.0, 'eval_precision_realization': 0.0, 'eval_recall_realization': 0.0, 'eval_f1_realization': 0.0, 'eval_precision_relief': 0.0, 'eval_recall_relief': 0.0, 'eval_f1_relief': 0.0, 'eval_precision_remorse': 0.8095238095238095, 'eval_recall_remorse': 0.4146341463414634, 'eval_f1_remorse': 0.5483870967741935, 'eval_precision_sadness': 0.23008849557522124, 'eval_recall_sadness': 0.30952380952380953, 'eval_f1_sadness': 0.2639593908629442, 'eval_precision_surprise': 0.0, 'eval_recall_surprise': 0.0, 'eval_f1_surprise': 0.0, 'eval_precision_neutral': 0.4245548266166823, 'eval_recall_neutral': 0.9577167019027484, 'eval_f1_neutral': 0.5883116883116883, 'eval_f1_micro_t4': 0.4552049940948203, 'eval_f1_macro_t4': 0.13733788896780735, 'eval_f1_weighted_t4': 0.3322827474050293, 'eval_precision_micro_t4': 0.5658557046979866, 'eval_precision_macro_t4': 0.1733271526110464, 'eval_recall_micro_t4': 0.3807507761783799, 'eval_recall_macro_t4': 0.14025943716510297, 'eval_avg_preds_t4': 0.7946666666666666, 'eval_f1_micro_t5': 0.4156354350815164, 'eval_f1_macro_t5': 0.11837475744000663, 'eval_f1_weighted_t5': 0.31359105629151307, 'eval_precision_micro_t5': 0.6834625322997416, 'eval_precision_macro_t5': 0.14808999660571373, 'eval_recall_micro_t5': 0.2986169912503528, 'eval_recall_macro_t5': 0.11094021757989628, 'eval_avg_preds_t5': 0.516, 'eval_f1_micro_t6': 0.3440387153541575, 'eval_f1_macro_t6': 0.10501322028429323, 'eval_f1_weighted_t6': 0.26955891252027486, 'eval_precision_micro_t6': 0.7796610169491526, 'eval_precision_macro_t6': 0.1428103978486334, 'eval_recall_micro_t6': 0.22071690657634774, 'eval_recall_macro_t6': 0.09147912913742502, 'eval_avg_preds_t6': 0.3343333333333333, 'eval_f1_micro_t7': 0.24878993223620524, 'eval_f1_macro_t7': 0.08849012051435425, 'eval_f1_weighted_t7': 0.19548364673829888, 'eval_precision_micro_t7': 0.8726655348047538, 'eval_precision_macro_t7': 0.1541140549774558, 'eval_recall_micro_t7': 0.1450747953711544, 'eval_recall_macro_t7': 0.07317960842926644, 'eval_avg_preds_t7': 0.19633333333333333, 'eval_f1_micro_t8': 0.12166093626024861, 'eval_f1_macro_t8': 0.05252114980703166, 'eval_f1_weighted_t8': 0.07809244226371809, 'eval_precision_micro_t8': 0.9663865546218487, 'eval_precision_macro_t8': 0.13696359506415373, 'eval_recall_micro_t8': 0.06491673722833757, 'eval_recall_macro_t8': 0.04310408778896174, 'eval_avg_preds_t8': 0.07933333333333334, 'eval_f1_micro_t9': 0.09511015583019881, 'eval_f1_macro_t9': 0.0330100708690787, 'eval_f1_weighted_t9': 0.053218607057346184, 'eval_precision_micro_t9': 0.9888268156424581, 'eval_precision_macro_t9': 0.035315243415802076, 'eval_recall_micro_t9': 0.04995766299745978, 'eval_recall_macro_t9': 0.030987394957983194, 'eval_avg_preds_t9': 0.059666666666666666, 'eval_f1_micro': 0.3342984252524539, 'eval_f1_macro': 0.19840005220146445, 'eval_f1_weighted': 0.35125469425688355, 'eval_precision_micro': 0.22292333772838577, 'eval_precision_macro': 0.156122505057353, 'eval_recall_micro': 0.668077900084674, 'eval_recall_macro': 0.38763531826934183, 'eval_primary_threshold': 0.2, 'eval_f1_micro_default': 0.4156354350815164, 'eval_f1_macro_default': 0.11837475744000663, 'eval_f1_weighted_default': 0.31359105629151307, 'eval_class_imbalance_ratio': 105.11111450195312, 'eval_prediction_entropy': 6.727141380310059, 'eval_runtime': 16.5891, 'eval_samples_per_second': 180.841, 'eval_steps_per_second': 22.605, 'epoch': 1.0}\n",
      "üíæ Disk space: 133.9GB free, 46.2% used\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Asymmetric/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up latest checkpoint checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1300/2500 [12:49<10:16,  1.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2589, 'grad_norm': 0.00030517578125, 'learning_rate': 1.8093364160360037e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1350/2500 [13:15<10:21,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2512, 'grad_norm': 0.00030517581035383046, 'learning_rate': 1.7000940984241102e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1400/2500 [13:42<09:49,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2551, 'grad_norm': 0.00030517578125, 'learning_rate': 1.5897589362335695e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1450/2500 [14:08<09:15,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2555, 'grad_norm': 0.00030517578125, 'learning_rate': 1.4789335418591692e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1500/2500 [14:35<09:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2416, 'grad_norm': 0.00030517575214616954, 'learning_rate': 1.3682232051738853e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1541/2500 [14:57<08:15,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Asymmetric/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up latest checkpoint checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1542/2500 [15:47<4:05:29, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 133.9GB free, 46.2% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1550/2500 [15:51<22:08,  1.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2495, 'grad_norm': 0.00030517578125, 'learning_rate': 1.2582325876454948e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1600/2500 [16:18<07:51,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2517, 'grad_norm': 0.00030517581035383046, 'learning_rate': 1.1495624198853181e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1650/2500 [16:44<07:24,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2378, 'grad_norm': 0.00030517578125, 'learning_rate': 1.0428062206659356e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1700/2500 [17:10<07:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2428, 'grad_norm': 0.00030517578125, 'learning_rate': 9.38547055327468e-06, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1750/2500 [17:37<07:04,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2512, 'grad_norm': 0.00030517581035383046, 'learning_rate': 8.373543512768796e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1800/2500 [18:04<06:06,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.226, 'grad_norm': 0.00030517578125, 'learning_rate': 7.397807879729412e-06, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1850/2500 [18:32<06:18,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2273, 'grad_norm': 0.00030517578125, 'learning_rate': 6.4635927838267965e-06, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1900/2500 [18:59<05:12,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2317, 'grad_norm': 0.00030517578125, 'learning_rate': 5.576000583955539e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1950/2500 [19:26<04:41,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2299, 'grad_norm': 0.00030517578125, 'learning_rate': 4.739879000919582e-06, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2000/2500 [19:52<04:22,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2312, 'grad_norm': 0.00030517581035383046, 'learning_rate': 3.959794640862277e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2050/2500 [20:18<03:45,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2303, 'grad_norm': 0.00030517575214616954, 'learning_rate': 3.240008054047169e-06, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2100/2500 [20:44<03:26,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.231, 'grad_norm': 0.00030517578125, 'learning_rate': 2.584450465209909e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2107/2500 [20:47<03:18,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 133.9GB free, 46.2% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2150/2500 [21:09<02:57,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2365, 'grad_norm': 0.00030517578125, 'learning_rate': 1.996702302571993e-06, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2200/2500 [21:35<02:36,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2267, 'grad_norm': 0.0006103515625, 'learning_rate': 1.4895933152863989e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2250/2500 [22:01<02:10,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2285, 'grad_norm': 0.0006103516207076609, 'learning_rate': 1.0452044449457493e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2300/2500 [22:28<01:46,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2242, 'grad_norm': 0.0006103515625, 'learning_rate': 6.770318288003557e-07, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2350/2500 [22:54<01:15,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2163, 'grad_norm': 0.0006103515625, 'learning_rate': 3.8708629800780713e-07, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2400/2500 [23:19<00:51,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2301, 'grad_norm': 0.0006103515625, 'learning_rate': 1.7695143451242735e-07, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2450/2500 [23:46<00:26,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2216, 'grad_norm': 0.0006103516207076609, 'learning_rate': 4.777492206982426e-08, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [24:13<00:00,  1.86it/s]\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2289, 'grad_norm': 0.0006103515625, 'learning_rate': 2.622779962213606e-10, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 4/375 [00:00<00:11, 31.89it/s]\u001b[A\n",
      "  2%|‚ñè         | 8/375 [00:00<00:13, 26.82it/s]\u001b[A\n",
      "  3%|‚ñé         | 11/375 [00:00<00:14, 25.65it/s]\u001b[A\n",
      "  4%|‚ñé         | 14/375 [00:00<00:14, 24.98it/s]\u001b[A\n",
      "  5%|‚ñç         | 17/375 [00:00<00:14, 24.67it/s]\u001b[A\n",
      "  5%|‚ñå         | 20/375 [00:00<00:14, 24.53it/s]\u001b[A\n",
      "  6%|‚ñå         | 23/375 [00:00<00:14, 24.42it/s]\u001b[A\n",
      "  7%|‚ñã         | 26/375 [00:01<00:14, 24.33it/s]\u001b[A\n",
      "  8%|‚ñä         | 29/375 [00:01<00:14, 24.25it/s]\u001b[A\n",
      "  9%|‚ñä         | 32/375 [00:01<00:14, 24.29it/s]\u001b[A\n",
      "  9%|‚ñâ         | 35/375 [00:01<00:14, 24.25it/s]\u001b[A\n",
      " 10%|‚ñà         | 38/375 [00:01<00:13, 24.26it/s]\u001b[A\n",
      " 11%|‚ñà         | 41/375 [00:01<00:13, 24.24it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 44/375 [00:01<00:13, 24.25it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 47/375 [00:01<00:13, 24.26it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 50/375 [00:02<00:13, 24.22it/s]\u001b[A\n",
      " 14%|‚ñà‚ñç        | 53/375 [00:02<00:13, 24.26it/s]\u001b[A\n",
      " 15%|‚ñà‚ñç        | 56/375 [00:02<00:13, 24.25it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 59/375 [00:02<00:13, 24.19it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 62/375 [00:02<00:12, 24.20it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 65/375 [00:02<00:12, 24.11it/s]\u001b[A\n",
      " 18%|‚ñà‚ñä        | 68/375 [00:02<00:12, 24.11it/s]\u001b[A\n",
      " 19%|‚ñà‚ñâ        | 71/375 [00:02<00:12, 24.05it/s]\u001b[A\n",
      " 20%|‚ñà‚ñâ        | 74/375 [00:03<00:12, 24.09it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà        | 77/375 [00:03<00:12, 24.05it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà‚ñè       | 80/375 [00:03<00:12, 24.07it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 83/375 [00:03<00:12, 24.07it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 86/375 [00:03<00:11, 24.12it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñé       | 89/375 [00:03<00:11, 24.04it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 92/375 [00:03<00:11, 24.07it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 95/375 [00:03<00:11, 24.03it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 98/375 [00:04<00:11, 24.01it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 101/375 [00:04<00:11, 24.07it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 104/375 [00:04<00:11, 24.14it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñä       | 107/375 [00:04<00:11, 24.11it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 110/375 [00:04<00:10, 24.19it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñà       | 113/375 [00:04<00:10, 24.14it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 116/375 [00:04<00:10, 24.16it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 119/375 [00:04<00:10, 24.12it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 122/375 [00:05<00:10, 24.16it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 125/375 [00:05<00:10, 24.15it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 128/375 [00:05<00:10, 24.10it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 131/375 [00:05<00:10, 24.07it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 134/375 [00:05<00:09, 24.13it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 137/375 [00:05<00:09, 24.19it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 140/375 [00:05<00:09, 24.23it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 143/375 [00:05<00:09, 24.24it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 146/375 [00:06<00:09, 24.24it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 149/375 [00:06<00:09, 24.21it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 152/375 [00:06<00:09, 24.22it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 155/375 [00:06<00:09, 24.24it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 158/375 [00:06<00:08, 24.27it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 161/375 [00:06<00:08, 24.21it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 164/375 [00:06<00:08, 24.26it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 167/375 [00:06<00:08, 24.30it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 170/375 [00:06<00:08, 24.28it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 173/375 [00:07<00:08, 24.23it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 176/375 [00:07<00:08, 24.27it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 179/375 [00:07<00:08, 24.29it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 182/375 [00:07<00:07, 24.35it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 185/375 [00:07<00:07, 24.32it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 188/375 [00:07<00:07, 24.09it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 191/375 [00:07<00:07, 23.95it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 194/375 [00:07<00:07, 24.03it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 197/375 [00:08<00:07, 24.14it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 200/375 [00:08<00:07, 24.21it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 203/375 [00:08<00:07, 24.12it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 206/375 [00:08<00:06, 24.20it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 209/375 [00:08<00:06, 24.26it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 212/375 [00:08<00:06, 24.33it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 215/375 [00:08<00:06, 24.37it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 218/375 [00:08<00:06, 24.36it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 221/375 [00:09<00:06, 24.34it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 224/375 [00:09<00:06, 24.32it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 227/375 [00:09<00:06, 24.33it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 230/375 [00:09<00:05, 24.30it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 233/375 [00:09<00:05, 24.36it/s]\u001b[A\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 236/375 [00:09<00:05, 24.36it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 239/375 [00:09<00:05, 24.34it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 242/375 [00:09<00:05, 24.36it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 245/375 [00:10<00:05, 24.36it/s]\u001b[A\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 248/375 [00:10<00:05, 24.38it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 251/375 [00:10<00:05, 24.31it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 254/375 [00:10<00:04, 24.23it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 257/375 [00:10<00:04, 24.22it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 260/375 [00:10<00:04, 24.31it/s]\u001b[A\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 263/375 [00:10<00:04, 24.32it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 266/375 [00:10<00:04, 24.29it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 269/375 [00:11<00:04, 24.26it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 272/375 [00:11<00:04, 24.33it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 275/375 [00:11<00:04, 24.37it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 278/375 [00:11<00:03, 24.40it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 281/375 [00:11<00:03, 24.38it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 284/375 [00:11<00:03, 24.44it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 287/375 [00:11<00:03, 24.47it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 290/375 [00:11<00:03, 24.45it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 293/375 [00:12<00:03, 24.44it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 296/375 [00:12<00:03, 24.43it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 299/375 [00:12<00:03, 24.44it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 302/375 [00:12<00:02, 24.45it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 305/375 [00:12<00:02, 24.34it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 308/375 [00:12<00:02, 24.39it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 311/375 [00:12<00:02, 24.34it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 314/375 [00:12<00:02, 23.84it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 317/375 [00:13<00:02, 23.91it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 320/375 [00:13<00:02, 24.01it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 323/375 [00:13<00:02, 24.11it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 326/375 [00:13<00:02, 24.10it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 329/375 [00:13<00:01, 24.17it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 332/375 [00:13<00:01, 24.22it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 335/375 [00:13<00:01, 24.24it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 338/375 [00:13<00:01, 24.20it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 341/375 [00:14<00:01, 24.11it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 344/375 [00:14<00:01, 24.12it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 347/375 [00:14<00:01, 24.01it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 350/375 [00:14<00:01, 24.03it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 353/375 [00:14<00:00, 24.11it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 356/375 [00:14<00:00, 24.16it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 359/375 [00:14<00:00, 24.07it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 362/375 [00:14<00:00, 23.80it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 365/375 [00:15<00:00, 23.88it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 368/375 [00:15<00:00, 24.00it/s]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 371/375 [00:15<00:00, 24.05it/s]\u001b[A\n",
      "                                                   A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [24:29<00:00,  1.86it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:15<00:00, 24.02it/s]\u001b[A\n",
      "                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.057344719767570496, 'eval_f1_micro_t1': 0.1763114623667321, 'eval_f1_macro_t1': 0.14676476015913953, 'eval_f1_weighted_t1': 0.27913193198218256, 'eval_precision_micro_t1': 0.09729824664110295, 'eval_precision_macro_t1': 0.08601723403693953, 'eval_recall_micro_t1': 0.9381879762912786, 'eval_recall_macro_t1': 0.7908287272657574, 'eval_avg_preds_t1': 11.387666666666666, 'eval_f1_micro_t2': 0.41045070644881204, 'eval_f1_macro_t2': 0.27268782756956866, 'eval_f1_weighted_t2': 0.4322967035902989, 'eval_precision_micro_t2': 0.2849002849002849, 'eval_precision_macro_t2': 0.22563244102801286, 'eval_recall_micro_t2': 0.7338413773638159, 'eval_recall_macro_t2': 0.48861894300594766, 'eval_avg_preds_t2': 3.042, 'eval_f1_micro_t3': 0.5149453219927096, 'eval_f1_macro_t3': 0.29129019483046864, 'eval_f1_weighted_t3': 0.47222490323506655, 'eval_precision_micro_t3': 0.4521015574994666, 'eval_precision_macro_t3': 0.3271755832174135, 'eval_recall_micro_t3': 0.59808072255151, 'eval_recall_macro_t3': 0.34824661291999853, 'eval_avg_preds_t3': 1.5623333333333334, 'eval_precision_admiration': 0.5758354755784062, 'eval_recall_admiration': 0.8205128205128205, 'eval_f1_admiration': 0.676737160120846, 'eval_precision_amusement': 0.6508620689655172, 'eval_recall_amusement': 0.8628571428571429, 'eval_f1_amusement': 0.742014742014742, 'eval_precision_anger': 0.2761904761904762, 'eval_recall_anger': 0.5471698113207547, 'eval_f1_anger': 0.3670886075949367, 'eval_precision_annoyance': 0.2514792899408284, 'eval_recall_annoyance': 0.4941860465116279, 'eval_f1_annoyance': 0.3333333333333333, 'eval_precision_approval': 0.3076923076923077, 'eval_recall_approval': 0.3018867924528302, 'eval_f1_approval': 0.3047619047619048, 'eval_precision_caring': 0.75, 'eval_recall_caring': 0.038461538461538464, 'eval_f1_caring': 0.07317073170731707, 'eval_precision_confusion': 0.20930232558139536, 'eval_recall_confusion': 0.43373493975903615, 'eval_f1_confusion': 0.2823529411764706, 'eval_precision_curiosity': 0.390625, 'eval_recall_curiosity': 0.7407407407407407, 'eval_f1_curiosity': 0.5115089514066496, 'eval_precision_desire': 1.0, 'eval_recall_desire': 0.18604651162790697, 'eval_f1_desire': 0.3137254901960784, 'eval_precision_disappointment': 0.13846153846153847, 'eval_recall_disappointment': 0.1, 'eval_f1_disappointment': 0.11612903225806452, 'eval_precision_disapproval': 0.2986111111111111, 'eval_recall_disapproval': 0.2621951219512195, 'eval_f1_disapproval': 0.2792207792207792, 'eval_precision_disgust': 0.0, 'eval_recall_disgust': 0.0, 'eval_f1_disgust': 0.0, 'eval_precision_embarrassment': 0.0, 'eval_recall_embarrassment': 0.0, 'eval_f1_embarrassment': 0.0, 'eval_precision_excitement': 0.2857142857142857, 'eval_recall_excitement': 0.03773584905660377, 'eval_f1_excitement': 0.06666666666666667, 'eval_precision_fear': 0.0, 'eval_recall_fear': 0.0, 'eval_f1_fear': 0.0, 'eval_precision_gratitude': 0.8034934497816594, 'eval_recall_gratitude': 0.9019607843137255, 'eval_f1_gratitude': 0.8498845265588915, 'eval_precision_grief': 0.0, 'eval_recall_grief': 0.0, 'eval_f1_grief': 0.0, 'eval_precision_joy': 0.4818181818181818, 'eval_recall_joy': 0.4690265486725664, 'eval_f1_joy': 0.47533632286995514, 'eval_precision_love': 0.6114285714285714, 'eval_recall_love': 0.8492063492063492, 'eval_f1_love': 0.7109634551495017, 'eval_precision_nervousness': 0.0, 'eval_recall_nervousness': 0.0, 'eval_f1_nervousness': 0.0, 'eval_precision_optimism': 0.35135135135135137, 'eval_recall_optimism': 0.5118110236220472, 'eval_f1_optimism': 0.4166666666666667, 'eval_precision_pride': 0.0, 'eval_recall_pride': 0.0, 'eval_f1_pride': 0.0, 'eval_precision_realization': 0.0, 'eval_recall_realization': 0.0, 'eval_f1_realization': 0.0, 'eval_precision_relief': 0.0, 'eval_recall_relief': 0.0, 'eval_f1_relief': 0.0, 'eval_precision_remorse': 0.47692307692307695, 'eval_recall_remorse': 0.7560975609756098, 'eval_f1_remorse': 0.5849056603773585, 'eval_precision_sadness': 0.3142857142857143, 'eval_recall_sadness': 0.5238095238095238, 'eval_f1_sadness': 0.39285714285714285, 'eval_precision_surprise': 0.5, 'eval_recall_surprise': 0.013888888888888888, 'eval_f1_surprise': 0.02702702702702703, 'eval_precision_neutral': 0.4868421052631579, 'eval_recall_neutral': 0.8995771670190275, 'eval_f1_neutral': 0.6317743132887899, 'eval_f1_micro_t4': 0.5253329251492423, 'eval_f1_macro_t4': 0.23643805896246703, 'eval_f1_weighted_t4': 0.4310832125421984, 'eval_precision_micro_t4': 0.5739130434782609, 'eval_precision_macro_t4': 0.27128354458099607, 'eval_recall_micro_t4': 0.48433530906011857, 'eval_recall_macro_t4': 0.24622643287727614, 'eval_avg_preds_t4': 0.9966666666666667, 'eval_f1_micro_t5': 0.4965903129917818, 'eval_f1_macro_t5': 0.19438631094828782, 'eval_f1_weighted_t5': 0.39229507929707186, 'eval_precision_micro_t5': 0.6525735294117647, 'eval_precision_macro_t5': 0.25767981817427593, 'eval_recall_micro_t5': 0.4007902907140841, 'eval_recall_macro_t5': 0.18823723457522248, 'eval_avg_preds_t5': 0.7253333333333334, 'eval_f1_micro_t6': 0.44751703992210323, 'eval_f1_macro_t6': 0.13829730436632648, 'eval_f1_weighted_t6': 0.3411605408639008, 'eval_precision_micro_t6': 0.7217336683417085, 'eval_precision_macro_t6': 0.20662101639685476, 'eval_recall_micro_t6': 0.32430143945808637, 'eval_recall_macro_t6': 0.134445878498924, 'eval_avg_preds_t6': 0.5306666666666666, 'eval_f1_micro_t7': 0.40765391014975044, 'eval_f1_macro_t7': 0.12819122916094883, 'eval_f1_weighted_t7': 0.3143980059497664, 'eval_precision_micro_t7': 0.7747035573122529, 'eval_precision_macro_t7': 0.13988663874408427, 'eval_recall_micro_t7': 0.2766017499294383, 'eval_recall_macro_t7': 0.12014109617392789, 'eval_avg_preds_t7': 0.4216666666666667, 'eval_f1_micro_t8': 0.3648351648351648, 'eval_f1_macro_t8': 0.12206364619450234, 'eval_f1_weighted_t8': 0.28623398031050873, 'eval_precision_micro_t8': 0.8242303872889771, 'eval_precision_macro_t8': 0.14610174997766626, 'eval_recall_micro_t8': 0.23426474738921818, 'eval_recall_macro_t8': 0.10836534554191384, 'eval_avg_preds_t8': 0.33566666666666667, 'eval_f1_micro_t9': 0.17030007694280586, 'eval_f1_macro_t9': 0.07335825865122958, 'eval_f1_weighted_t9': 0.1156860278323851, 'eval_precision_micro_t9': 0.9325842696629213, 'eval_precision_macro_t9': 0.1325152592468732, 'eval_recall_micro_t9': 0.09370589895568728, 'eval_recall_macro_t9': 0.05951719149198141, 'eval_avg_preds_t9': 0.11866666666666667, 'eval_f1_micro': 0.41045070644881204, 'eval_f1_macro': 0.27268782756956866, 'eval_f1_weighted': 0.4322967035902989, 'eval_precision_micro': 0.2849002849002849, 'eval_precision_macro': 0.22563244102801286, 'eval_recall_micro': 0.7338413773638159, 'eval_recall_macro': 0.48861894300594766, 'eval_primary_threshold': 0.2, 'eval_f1_micro_default': 0.4965903129917818, 'eval_f1_macro_default': 0.19438631094828782, 'eval_f1_weighted_default': 0.39229507929707186, 'eval_class_imbalance_ratio': 105.11111450195312, 'eval_prediction_entropy': 6.072048187255859, 'eval_runtime': 15.9854, 'eval_samples_per_second': 187.671, 'eval_steps_per_second': 23.459, 'epoch': 2.0}\n",
      "üíæ Disk space: 133.9GB free, 46.2% used\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Asymmetric/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up latest checkpoint checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [29:51<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1791.4741, 'train_samples_per_second': 22.328, 'train_steps_per_second': 1.395, 'train_loss': 0.2975490947723389, 'epoch': 2.0}\n",
      "‚úÖ Saved ensemble models to ./outputs/phase1_Asymmetric_ensemble\n",
      "üìä Final evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:16<00:00, 23.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Performing final backup to Google Drive...\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Asymmetric/\n",
      "‚úÖ Backed up evaluation report to Google Drive\n",
      "‚úÖ Backed up checkpoint-1250 to Google Drive\n",
      "‚úÖ Backed up checkpoint-2500 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n",
      "‚úÖ Training completed!\n",
      "üìà Final F1 Macro: 0.2727\n",
      "üìà Final F1 Micro: 0.4105\n",
      "üìà Final F1 Weighted: 0.4323\n",
      "üìä Class Imbalance Ratio: 105.11\n",
      "üî¨ Scientific log: ./outputs/phase1_Asymmetric/scientific_log_20250910_134625.json\n",
      "üíæ Model saved to: ./outputs/phase1_Asymmetric\n",
      "‚úÖ Asymmetric completed successfully!\n",
      "üöÄ Starting Combined_07 on GPU 0\n",
      "Command: python3 notebooks/scripts/train_deberta_local.py --output_dir ./outputs/phase1_Combined_07 --model_type deberta-v3-large --per_device_train_batch_size 4 --per_device_eval_batch_size 8 --gradient_accumulation_steps 4 --num_train_epochs 2 --learning_rate 3e-5 --lr_scheduler_type cosine --warmup_ratio 0.15 --weight_decay 0.01 --fp16 --max_length 256 --max_train_samples 20000 --max_eval_samples 3000 --augment_prob 0 --use_combined_loss --loss_combination_ratio 0.7\n",
      "üöÄ Executing training command...\n",
      "üíæ Disk space at startup: 132.3GB free, 46.9% used\n",
      "üöÄ GoEmotions DeBERTa Training (SCIENTIFIC VERSION)\n",
      "============================================================\n",
      "üìÅ Output directory: ./outputs/phase1_Combined_07\n",
      "ü§ñ Model: deberta-v3-large (from local cache)\n",
      "üìä Dataset: GoEmotions (from local cache)\n",
      "üî¨ Scientific logging: ENABLED\n",
      "ü§ñ Loading deberta-v3-large...\n",
      "üìÅ Found local cache at models/deberta-v3-large\n",
      "‚úÖ deberta-v3-large tokenizer loaded from local cache\n",
      "‚úÖ deberta-v3-large model loaded from local cache\n",
      "üìä Loading GoEmotions dataset from local cache...\n",
      "‚úÖ GoEmotions dataset loaded from local cache\n",
      "   Training examples: 43410\n",
      "   Validation examples: 5426\n",
      "   Total emotions: 28\n",
      "üîÑ Creating datasets...\n",
      "‚úÖ Created 43410 training examples\n",
      "‚úÖ Created 5426 validation examples\n",
      "üîÑ Limiting training data: 43410 ‚Üí 20000 samples\n",
      "‚úÖ Using 20000 training examples (subset for quick screening)\n",
      "üîÑ Limiting validation data: 5426 ‚Üí 3000 samples\n",
      "‚úÖ Using 3000 validation examples (subset for quick screening)\n",
      "üîß Disabling gradient checkpointing to prevent RuntimeError during backward pass\n",
      "üöÄ Using Combined Loss (ASL + Class Weighting + Focal Loss) for maximum performance\n",
      "üìä Loss combination ratio: 0.7 ASL + 0.30000000000000004 Focal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 14:21:45,215] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-09-10 14:21:46,817] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "üìä Class weights computed: tensor([ 0.3754,  0.6660,  0.9894,  0.6277,  0.5275,  1.4263,  1.1333,  0.7076,\n",
      "         2.4187,  1.2217,  0.7667,  1.9551,  5.1167,  1.8175,  2.6013,  0.5824,\n",
      "        20.1345,  1.0677,  0.7432,  9.4534,  0.9806, 13.9672,  1.3967, 10.1331,\n",
      "         2.8447,  1.1692,  1.4626,  0.1090])\n",
      "üéØ Loss combination: 0.7 ASL + 0.30000000000000004 Focal\n",
      "üìä Rare classes identified: [16, 21, 23, 19, 12, 24, 14, 8, 11, 13, 26, 5, 22, 9] (threshold: 1326 samples)\n",
      "üìà Oversampled class grief: 77 ‚Üí 115\n",
      "üìà Oversampled class pride: 111 ‚Üí 166\n",
      "üìà Oversampled class relief: 153 ‚Üí 229\n",
      "üìà Oversampled class nervousness: 164 ‚Üí 246\n",
      "üìà Oversampled class embarrassment: 303 ‚Üí 454\n",
      "üìà Oversampled class remorse: 545 ‚Üí 817\n",
      "üìà Oversampled class fear: 596 ‚Üí 894\n",
      "üìà Oversampled class desire: 641 ‚Üí 961\n",
      "üìà Oversampled class disgust: 793 ‚Üí 1189\n",
      "üìà Oversampled class excitement: 853 ‚Üí 1279\n",
      "üìà Oversampled class surprise: 1060 ‚Üí 1590\n",
      "üìà Oversampled class caring: 1087 ‚Üí 1630\n",
      "üìà Oversampled class realization: 1110 ‚Üí 1665\n",
      "üìà Oversampled class disappointment: 1269 ‚Üí 1903\n",
      "‚úÖ Stratified oversampling applied: 43410 ‚Üí 47786 samples\n",
      "‚úÖ Oversampling applied for rare classes\n",
      "üîÑ Creating oversampled training dataset...\n",
      "‚úÖ Oversampled training dataset: 47786 examples\n",
      "üöÄ Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5974 [00:00<?, ?it/s]/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "  1%|          | 50/5974 [00:27<51:40,  1.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5382, 'grad_norm': 7.62939453125e-05, 'learning_rate': 1.6387959866220736e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 100/5974 [00:55<51:26,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4016, 'grad_norm': 7.629393803654239e-05, 'learning_rate': 3.311036789297659e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 150/5974 [01:20<49:15,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0895, 'grad_norm': 7.629395258845761e-05, 'learning_rate': 4.983277591973244e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 200/5974 [01:48<51:49,  1.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7757, 'grad_norm': 7.62939453125e-05, 'learning_rate': 6.65551839464883e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 250/5974 [02:14<49:13,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5647, 'grad_norm': 7.629395986441523e-05, 'learning_rate': 8.327759197324414e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 300/5974 [02:43<51:43,  1.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4846, 'grad_norm': 7.629393803654239e-05, 'learning_rate': 9.999999999999999e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 350/5974 [03:09<48:21,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4554, 'grad_norm': 0.000152587890625, 'learning_rate': 1.1638795986622074e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 400/5974 [03:35<49:44,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4659, 'grad_norm': 0.000152587890625, 'learning_rate': 1.331103678929766e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 450/5974 [04:02<49:38,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4562, 'grad_norm': 0.00015258791972883046, 'learning_rate': 1.4983277591973246e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 500/5974 [04:29<47:01,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4519, 'grad_norm': 0.000152587890625, 'learning_rate': 1.6655518394648828e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 550/5974 [04:56<48:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4503, 'grad_norm': 0.00015258787607308477, 'learning_rate': 1.8327759197324415e-05, 'epoch': 0.18}\n",
      "üíæ Disk space: 132.3GB free, 46.9% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 600/5974 [05:23<48:08,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4543, 'grad_norm': 0.00015258791972883046, 'learning_rate': 1.9999999999999998e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 650/5974 [05:50<45:41,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4258, 'grad_norm': 0.000152587890625, 'learning_rate': 2.1672240802675585e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 700/5974 [06:16<46:51,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.424, 'grad_norm': 0.000152587890625, 'learning_rate': 2.334448160535117e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 750/5974 [06:43<45:04,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4402, 'grad_norm': 0.00015258790517691523, 'learning_rate': 2.5016722408026756e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 800/5974 [07:09<45:35,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4278, 'grad_norm': 0.00015258790517691523, 'learning_rate': 2.668896321070234e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 850/5974 [07:35<45:06,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4332, 'grad_norm': 0.0003051757230423391, 'learning_rate': 2.8327759197324414e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 900/5974 [08:02<42:44,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4387, 'grad_norm': 0.00030517575214616954, 'learning_rate': 3e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 950/5974 [08:29<43:46,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.427, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.999282119682315e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 1000/5974 [08:55<44:24,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4097, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.99712916586546e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 1050/5974 [09:22<43:53,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4319, 'grad_norm': 0.00030517578125, 'learning_rate': 2.9935431993003283e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 1100/5974 [09:49<42:26,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4171, 'grad_norm': 0.00030517578125, 'learning_rate': 2.988527652380009e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñä        | 1112/5974 [09:56<47:24,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 132.3GB free, 46.9% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 1150/5974 [10:17<43:42,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4068, 'grad_norm': 0.00030517578125, 'learning_rate': 2.9820873258543923e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 1200/5974 [10:43<40:39,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3915, 'grad_norm': 0.00030517578125, 'learning_rate': 2.9742283842350127e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà        | 1250/5974 [11:09<41:23,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3883, 'grad_norm': 0.00030517578125, 'learning_rate': 2.964958349894546e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 1300/5974 [11:36<42:33,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.377, 'grad_norm': 0.0003051758394576609, 'learning_rate': 2.954286095866589e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 1350/5974 [12:02<42:07,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3701, 'grad_norm': 0.00030517578125, 'learning_rate': 2.942221837352624e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 1400/5974 [12:29<40:31,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3782, 'grad_norm': 0.00030517578125, 'learning_rate': 2.9287771219442972e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 1450/5974 [12:55<39:30,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3829, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.9139648185703665e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 1500/5974 [13:22<40:17,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3641, 'grad_norm': 0.00030517578125, 'learning_rate': 2.8977991051789015e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 1550/5974 [13:49<39:04,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3687, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.8802954551665212e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 1600/5974 [14:15<39:02,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3634, 'grad_norm': 0.00030517578125, 'learning_rate': 2.8614706225676684e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 1650/5974 [14:42<37:35,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3634, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.8413426260180853e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 1678/5974 [14:56<36:53,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 132.3GB free, 46.9% used\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Combined_07/\n",
      "‚úÖ Backed up latest checkpoint checkpoint-4397 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 1700/5974 [15:53<38:41,  1.84it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3629, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.8199307315078478e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñâ       | 1750/5974 [16:19<35:53,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3625, 'grad_norm': 0.00030517578125, 'learning_rate': 2.797255433940467e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 1800/5974 [16:45<36:33,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3415, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.773338437515705e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà       | 1850/5974 [17:12<36:03,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3581, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.7482026349548834e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 1900/5974 [17:38<36:16,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3625, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.7218720855885724e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 1950/5974 [18:04<33:34,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3366, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.6943719923276303e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 2000/5974 [18:30<34:57,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.347, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.6657286775396398e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 2050/5974 [18:57<34:51,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3364, 'grad_norm': 0.00030517578125, 'learning_rate': 2.6359695578538266e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 2100/5974 [19:24<34:56,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3363, 'grad_norm': 0.00030517578125, 'learning_rate': 2.605123117918583e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 2150/5974 [19:50<33:05,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.346, 'grad_norm': 0.00030517578125, 'learning_rate': 2.573218883136709e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 2162/5974 [19:57<32:51,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 132.3GB free, 46.9% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 2200/5974 [20:17<31:59,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3238, 'grad_norm': 0.0003051757230423391, 'learning_rate': 2.5402873914044725e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 2250/5974 [20:42<32:27,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3255, 'grad_norm': 0.00030517578125, 'learning_rate': 2.5063601638815353e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 2300/5974 [21:09<33:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3341, 'grad_norm': 0.00030517578125, 'learning_rate': 2.4714696748197275e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 2350/5974 [21:34<30:47,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3197, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.4356493204795444e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 2400/5974 [22:00<32:29,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3275, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.3989333871641244e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 2450/5974 [22:27<31:33,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3126, 'grad_norm': 0.00030517578125, 'learning_rate': 2.3613570184012973e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2500/5974 [22:55<31:33,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3256, 'grad_norm': 0.00030517578125, 'learning_rate': 2.322956181305123e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2550/5974 [23:22<30:15,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3237, 'grad_norm': 0.00030517575214616954, 'learning_rate': 2.2837676321491143e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2600/5974 [23:48<29:59,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3315, 'grad_norm': 0.00030517578125, 'learning_rate': 2.2438288811840926e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2650/5974 [24:15<29:11,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3258, 'grad_norm': 0.0006103515625, 'learning_rate': 2.2039978979824785e-05, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2700/5974 [24:42<29:35,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4312, 'grad_norm': 0.0006103516207076609, 'learning_rate': 2.162687185583166e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2727/5974 [24:57<30:18,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 132.3GB free, 46.9% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2750/5974 [25:09<31:02,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4711, 'grad_norm': 0.0012207030085846782, 'learning_rate': 2.1215870242730775e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2800/5974 [25:36<28:17,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3605, 'grad_norm': 0.001220703125, 'learning_rate': 2.079059332942079e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2850/5974 [26:03<27:23,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3666, 'grad_norm': 0.001220703125, 'learning_rate': 2.035977381213892e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2900/5974 [26:28<25:59,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3474, 'grad_norm': 0.0012207032414153218, 'learning_rate': 1.9923824060021083e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2950/5974 [26:54<25:51,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3252, 'grad_norm': 0.001220703125, 'learning_rate': 1.9483161352729327e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2987/5974 [27:14<25:45,  1.93it/s]\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 4/375 [00:00<00:12, 30.06it/s]\u001b[A\n",
      "  2%|‚ñè         | 8/375 [00:00<00:14, 24.53it/s]\u001b[A\n",
      "  3%|‚ñé         | 11/375 [00:00<00:15, 23.78it/s]\u001b[A\n",
      "  4%|‚ñé         | 14/375 [00:00<00:15, 23.35it/s]\u001b[A\n",
      "  5%|‚ñç         | 17/375 [00:00<00:15, 23.26it/s]\u001b[A\n",
      "  5%|‚ñå         | 20/375 [00:00<00:15, 23.10it/s]\u001b[A\n",
      "  6%|‚ñå         | 23/375 [00:00<00:15, 23.08it/s]\u001b[A\n",
      "  7%|‚ñã         | 26/375 [00:01<00:15, 23.03it/s]\u001b[A\n",
      "  8%|‚ñä         | 29/375 [00:01<00:15, 22.91it/s]\u001b[A\n",
      "  9%|‚ñä         | 32/375 [00:01<00:14, 23.00it/s]\u001b[A\n",
      "  9%|‚ñâ         | 35/375 [00:01<00:14, 22.99it/s]\u001b[A\n",
      " 10%|‚ñà         | 38/375 [00:01<00:14, 23.04it/s]\u001b[A\n",
      " 11%|‚ñà         | 41/375 [00:01<00:14, 23.11it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 44/375 [00:01<00:14, 23.18it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 47/375 [00:02<00:14, 23.13it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 50/375 [00:02<00:14, 23.04it/s]\u001b[A\n",
      " 14%|‚ñà‚ñç        | 53/375 [00:02<00:13, 23.14it/s]\u001b[A\n",
      " 15%|‚ñà‚ñç        | 56/375 [00:02<00:13, 23.24it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 59/375 [00:02<00:13, 23.23it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 62/375 [00:02<00:13, 23.33it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 65/375 [00:02<00:13, 23.11it/s]\u001b[A\n",
      " 18%|‚ñà‚ñä        | 68/375 [00:02<00:13, 23.27it/s]\u001b[A\n",
      " 19%|‚ñà‚ñâ        | 71/375 [00:03<00:12, 23.46it/s]\u001b[A\n",
      " 20%|‚ñà‚ñâ        | 74/375 [00:03<00:12, 23.51it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà        | 77/375 [00:03<00:12, 23.28it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà‚ñè       | 80/375 [00:03<00:12, 23.29it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 83/375 [00:03<00:12, 23.30it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 86/375 [00:03<00:12, 23.33it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñé       | 89/375 [00:03<00:12, 23.32it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 92/375 [00:03<00:12, 23.31it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 95/375 [00:04<00:11, 23.40it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 98/375 [00:04<00:11, 23.45it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 101/375 [00:04<00:11, 23.51it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 104/375 [00:04<00:11, 23.46it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñä       | 107/375 [00:04<00:11, 23.47it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 110/375 [00:04<00:11, 23.52it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñà       | 113/375 [00:04<00:11, 23.37it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 116/375 [00:04<00:11, 23.39it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 119/375 [00:05<00:10, 23.38it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 122/375 [00:05<00:10, 23.37it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 125/375 [00:05<00:10, 23.29it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 128/375 [00:05<00:10, 23.49it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 131/375 [00:05<00:10, 23.30it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 134/375 [00:05<00:10, 23.56it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 137/375 [00:05<00:10, 23.63it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 140/375 [00:05<00:09, 23.74it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 143/375 [00:06<00:09, 23.82it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 146/375 [00:06<00:09, 23.96it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 149/375 [00:06<00:09, 23.99it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 152/375 [00:06<00:09, 24.03it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 155/375 [00:06<00:09, 24.04it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 158/375 [00:06<00:09, 24.11it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 161/375 [00:06<00:08, 23.93it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 164/375 [00:06<00:08, 23.96it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 167/375 [00:07<00:08, 23.99it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 170/375 [00:07<00:08, 24.01it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 173/375 [00:07<00:08, 24.03it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 176/375 [00:07<00:08, 24.05it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 179/375 [00:07<00:08, 24.05it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 182/375 [00:07<00:07, 24.13it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 185/375 [00:07<00:07, 24.05it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 188/375 [00:07<00:07, 24.12it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 191/375 [00:08<00:07, 24.08it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 194/375 [00:08<00:07, 23.81it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 197/375 [00:08<00:07, 23.74it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 200/375 [00:08<00:07, 23.89it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 203/375 [00:08<00:07, 24.02it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 206/375 [00:08<00:07, 24.10it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 209/375 [00:08<00:06, 24.12it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 212/375 [00:08<00:06, 24.17it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 215/375 [00:09<00:06, 24.05it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 218/375 [00:09<00:06, 24.07it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 221/375 [00:09<00:06, 24.09it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 224/375 [00:09<00:06, 24.09it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 227/375 [00:09<00:06, 24.18it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 230/375 [00:09<00:05, 24.23it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 233/375 [00:09<00:05, 24.26it/s]\u001b[A\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 236/375 [00:09<00:05, 24.19it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 239/375 [00:10<00:05, 24.16it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 242/375 [00:10<00:05, 24.16it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 245/375 [00:10<00:05, 24.19it/s]\u001b[A\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 248/375 [00:10<00:05, 24.20it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 251/375 [00:10<00:05, 24.19it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 254/375 [00:10<00:04, 24.27it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 257/375 [00:10<00:04, 24.25it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 260/375 [00:10<00:04, 23.89it/s]\u001b[A\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 263/375 [00:11<00:04, 23.38it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 266/375 [00:11<00:04, 23.01it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 269/375 [00:11<00:04, 22.93it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 272/375 [00:11<00:04, 23.17it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 275/375 [00:11<00:04, 23.38it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 278/375 [00:11<00:04, 23.62it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 281/375 [00:11<00:04, 23.48it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 284/375 [00:12<00:03, 23.70it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 287/375 [00:12<00:03, 23.86it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 290/375 [00:12<00:03, 23.95it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 293/375 [00:12<00:03, 23.96it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 296/375 [00:12<00:03, 24.03it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 299/375 [00:12<00:03, 24.00it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 302/375 [00:12<00:03, 24.07it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 305/375 [00:12<00:02, 23.71it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 308/375 [00:13<00:02, 23.79it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 311/375 [00:13<00:02, 23.43it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 314/375 [00:13<00:02, 23.47it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 317/375 [00:13<00:02, 23.58it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 320/375 [00:13<00:02, 23.80it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 323/375 [00:13<00:02, 23.81it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 326/375 [00:13<00:02, 23.84it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 329/375 [00:13<00:01, 23.92it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 332/375 [00:14<00:01, 23.85it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 335/375 [00:14<00:01, 23.76it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 338/375 [00:14<00:01, 23.53it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 341/375 [00:14<00:01, 23.62it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 344/375 [00:14<00:01, 23.55it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 347/375 [00:14<00:01, 23.61it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 350/375 [00:14<00:01, 23.74it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 353/375 [00:14<00:00, 23.94it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 356/375 [00:15<00:00, 23.88it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 359/375 [00:15<00:00, 23.74it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 362/375 [00:15<00:00, 23.80it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 365/375 [00:15<00:00, 23.82it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 368/375 [00:15<00:00, 23.78it/s]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 371/375 [00:15<00:00, 23.75it/s]\u001b[A\n",
      "                                                   A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2987/5974 [27:30<25:45,  1.93it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:16<00:00, 23.84it/s]\u001b[A\n",
      "                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08304766565561295, 'eval_f1_micro_t1': 0.3401060597032712, 'eval_f1_macro_t1': 0.28287167342071273, 'eval_f1_weighted_t1': 0.3918740798285522, 'eval_precision_micro_t1': 0.21555891238670694, 'eval_precision_macro_t1': 0.20882960479771198, 'eval_recall_micro_t1': 0.8055320349985887, 'eval_recall_macro_t1': 0.6274171293449997, 'eval_avg_preds_t1': 4.413333333333333, 'eval_f1_micro_t2': 0.46020173774093676, 'eval_f1_macro_t2': 0.3229492375222108, 'eval_f1_weighted_t2': 0.4508778840339011, 'eval_precision_micro_t2': 0.3561051004636785, 'eval_precision_macro_t2': 0.346403378815637, 'eval_recall_micro_t2': 0.6502963590177815, 'eval_recall_macro_t2': 0.4494840019623561, 'eval_avg_preds_t2': 2.1566666666666667, 'eval_f1_micro_t3': 0.5042864346949067, 'eval_f1_macro_t3': 0.3053090636040782, 'eval_f1_weighted_t3': 0.44139148309079446, 'eval_precision_micro_t3': 0.455684666210982, 'eval_precision_macro_t3': 0.3630052911220592, 'eval_recall_micro_t3': 0.5644933672029354, 'eval_recall_macro_t3': 0.351474970317276, 'eval_avg_preds_t3': 1.463, 'eval_precision_admiration': 0.6815068493150684, 'eval_recall_admiration': 0.7289377289377289, 'eval_f1_admiration': 0.7044247787610619, 'eval_precision_amusement': 0.6954314720812182, 'eval_recall_amusement': 0.7828571428571428, 'eval_f1_amusement': 0.7365591397849462, 'eval_precision_anger': 0.21070234113712374, 'eval_recall_anger': 0.5943396226415094, 'eval_f1_anger': 0.3111111111111111, 'eval_precision_annoyance': 0.27459016393442626, 'eval_recall_annoyance': 0.38953488372093026, 'eval_f1_annoyance': 0.32211538461538464, 'eval_precision_approval': 0.4, 'eval_recall_approval': 0.009433962264150943, 'eval_f1_approval': 0.018433179723502304, 'eval_precision_caring': 0.24731182795698925, 'eval_recall_caring': 0.5897435897435898, 'eval_f1_caring': 0.3484848484848485, 'eval_precision_confusion': 0.3076923076923077, 'eval_recall_confusion': 0.14457831325301204, 'eval_f1_confusion': 0.19672131147540983, 'eval_precision_curiosity': 0.45454545454545453, 'eval_recall_curiosity': 0.7407407407407407, 'eval_f1_curiosity': 0.5633802816901409, 'eval_precision_desire': 1.0, 'eval_recall_desire': 0.18604651162790697, 'eval_f1_desire': 0.3137254901960784, 'eval_precision_disappointment': 0.0, 'eval_recall_disappointment': 0.0, 'eval_f1_disappointment': 0.0, 'eval_precision_disapproval': 0.7, 'eval_recall_disapproval': 0.042682926829268296, 'eval_f1_disapproval': 0.08045977011494253, 'eval_precision_disgust': 0.21052631578947367, 'eval_recall_disgust': 0.4666666666666667, 'eval_f1_disgust': 0.29015544041450775, 'eval_precision_embarrassment': 0.3076923076923077, 'eval_recall_embarrassment': 0.23529411764705882, 'eval_f1_embarrassment': 0.26666666666666666, 'eval_precision_excitement': 0.0, 'eval_recall_excitement': 0.0, 'eval_f1_excitement': 0.0, 'eval_precision_fear': 0.75, 'eval_recall_fear': 0.33962264150943394, 'eval_f1_fear': 0.4675324675324675, 'eval_precision_gratitude': 0.84688995215311, 'eval_recall_gratitude': 0.8676470588235294, 'eval_f1_gratitude': 0.8571428571428571, 'eval_precision_grief': 0.0, 'eval_recall_grief': 0.0, 'eval_f1_grief': 0.0, 'eval_precision_joy': 0.0, 'eval_recall_joy': 0.0, 'eval_f1_joy': 0.0, 'eval_precision_love': 0.6369047619047619, 'eval_recall_love': 0.8492063492063492, 'eval_f1_love': 0.7278911564625851, 'eval_precision_nervousness': 0.0, 'eval_recall_nervousness': 0.0, 'eval_f1_nervousness': 0.0, 'eval_precision_optimism': 0.6571428571428571, 'eval_recall_optimism': 0.18110236220472442, 'eval_f1_optimism': 0.2839506172839506, 'eval_precision_pride': 0.0, 'eval_recall_pride': 0.0, 'eval_f1_pride': 0.0, 'eval_precision_realization': 0.0, 'eval_recall_realization': 0.0, 'eval_f1_realization': 0.0, 'eval_precision_relief': 0.0, 'eval_recall_relief': 0.0, 'eval_f1_relief': 0.0, 'eval_precision_remorse': 0.44871794871794873, 'eval_recall_remorse': 0.8536585365853658, 'eval_f1_remorse': 0.5882352941176471, 'eval_precision_sadness': 0.4666666666666667, 'eval_recall_sadness': 0.3333333333333333, 'eval_f1_sadness': 0.3888888888888889, 'eval_precision_surprise': 0.43478260869565216, 'eval_recall_surprise': 0.5555555555555556, 'eval_f1_surprise': 0.4878048780487805, 'eval_precision_neutral': 0.43304431599229287, 'eval_recall_neutral': 0.9503171247357294, 'eval_f1_neutral': 0.5949702183984117, 'eval_f1_micro_t4': 0.5042760247714538, 'eval_f1_macro_t4': 0.2434568576792382, 'eval_f1_weighted_t4': 0.40795929786254814, 'eval_precision_micro_t4': 0.5279407224451992, 'eval_precision_macro_t4': 0.33591717800352333, 'eval_recall_micro_t4': 0.4826418289585097, 'eval_recall_macro_t4': 0.2607384615061441, 'eval_avg_preds_t4': 1.0796666666666668, 'eval_f1_micro_t5': 0.4973770491803279, 'eval_f1_macro_t5': 0.21756266787470163, 'eval_f1_weighted_t5': 0.3917182941188002, 'eval_precision_micro_t5': 0.5932733672272194, 'eval_precision_macro_t5': 0.22339506949005902, 'eval_recall_micro_t5': 0.4281682190234265, 'eval_recall_macro_t5': 0.21974796579861297, 'eval_avg_preds_t5': 0.8523333333333334, 'eval_f1_micro_t6': 0.4702712412430393, 'eval_f1_macro_t6': 0.19786271629557994, 'eval_f1_weighted_t6': 0.37027063464644633, 'eval_precision_micro_t6': 0.6467391304347826, 'eval_precision_macro_t6': 0.23866404337534108, 'eval_recall_micro_t6': 0.3694609088343212, 'eval_recall_macro_t6': 0.18152899421421773, 'eval_avg_preds_t6': 0.6746666666666666, 'eval_f1_micro_t7': 0.4264677007657569, 'eval_f1_macro_t7': 0.15590862418848223, 'eval_f1_weighted_t7': 0.3289973816134908, 'eval_precision_micro_t7': 0.7006451612903226, 'eval_precision_macro_t7': 0.2122628386377356, 'eval_recall_micro_t7': 0.3065198983911939, 'eval_recall_macro_t7': 0.13764861047833396, 'eval_avg_preds_t7': 0.5166666666666667, 'eval_f1_micro_t8': 0.33048561151079137, 'eval_f1_macro_t8': 0.09786179198585199, 'eval_f1_weighted_t8': 0.2629500057996388, 'eval_precision_micro_t8': 0.8121546961325967, 'eval_precision_macro_t8': 0.14933245489221147, 'eval_recall_micro_t8': 0.20745131244707873, 'eval_recall_macro_t8': 0.07955655509886506, 'eval_avg_preds_t8': 0.3016666666666667, 'eval_f1_micro_t9': 0.06442806442806442, 'eval_f1_macro_t9': 0.026014109347442683, 'eval_f1_weighted_t9': 0.04193976646700328, 'eval_precision_micro_t9': 0.9833333333333333, 'eval_precision_macro_t9': 0.03511904761904762, 'eval_recall_micro_t9': 0.03330510866497319, 'eval_recall_macro_t9': 0.020658263305322132, 'eval_avg_preds_t9': 0.04, 'eval_f1_micro': 0.46020173774093676, 'eval_f1_macro': 0.3229492375222108, 'eval_f1_weighted': 0.4508778840339011, 'eval_precision_micro': 0.3561051004636785, 'eval_precision_macro': 0.346403378815637, 'eval_recall_micro': 0.6502963590177815, 'eval_recall_macro': 0.4494840019623561, 'eval_primary_threshold': 0.2, 'eval_f1_micro_default': 0.4973770491803279, 'eval_f1_macro_default': 0.21756266787470163, 'eval_f1_weighted_default': 0.3917182941188002, 'eval_class_imbalance_ratio': 105.11111450195312, 'eval_prediction_entropy': 3.6929380893707275, 'eval_runtime': 16.3585, 'eval_samples_per_second': 183.391, 'eval_steps_per_second': 22.924, 'epoch': 1.0}\n",
      "üíæ Disk space: 127.5GB free, 48.8% used\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Combined_07/\n",
      "‚úÖ Backed up latest checkpoint checkpoint-4397 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3000/5974 [28:26<39:37,  1.25it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3205, 'grad_norm': 0.001220703125, 'learning_rate': 1.9038207481042732e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3050/5974 [28:52<25:21,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3266, 'grad_norm': 0.0012207032414153218, 'learning_rate': 1.8589388343130312e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3100/5974 [29:19<25:33,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3237, 'grad_norm': 0.001220703125, 'learning_rate': 1.8137133536892474e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3150/5974 [29:46<25:04,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3243, 'grad_norm': 0.001220703125, 'learning_rate': 1.768187594876119e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3170/5974 [29:56<24:25,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Combined_07/\n",
      "‚úÖ Backed up latest checkpoint checkpoint-4397 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3171/5974 [30:40<10:30:40, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 127.5GB free, 48.8% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3200/5974 [30:57<27:54,  1.66it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3341, 'grad_norm': 0.001220703125, 'learning_rate': 1.722405133935245e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3250/5974 [31:23<24:35,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3215, 'grad_norm': 0.001220703125, 'learning_rate': 1.676409792636766e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3300/5974 [31:50<23:59,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3256, 'grad_norm': 0.0012207032414153218, 'learning_rate': 1.630245596514312e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3350/5974 [32:18<23:14,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3176, 'grad_norm': 0.001220703125, 'learning_rate': 1.5839567327249207e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3400/5974 [32:45<22:21,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3079, 'grad_norm': 0.0012207030085846782, 'learning_rate': 1.5375875077542493e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3450/5974 [33:13<22:25,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3046, 'grad_norm': 0.001220703125, 'learning_rate': 1.4911823050075674e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3500/5974 [33:39<21:48,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2999, 'grad_norm': 0.001220703125, 'learning_rate': 1.4447855423271294e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3550/5974 [34:06<22:06,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3115, 'grad_norm': 0.001220703125, 'learning_rate': 1.3984416294765775e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3600/5974 [34:33<21:20,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2985, 'grad_norm': 0.0012207030085846782, 'learning_rate': 1.3521949256330853e-05, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3650/5974 [35:01<20:04,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3133, 'grad_norm': 0.001220703125, 'learning_rate': 1.3060896969279164e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3700/5974 [35:27<20:05,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3074, 'grad_norm': 0.001220703125, 'learning_rate': 1.2601700740760431e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3725/5974 [35:40<19:47,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 127.4GB free, 48.8% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3750/5974 [35:53<18:50,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2966, 'grad_norm': 0.001220703125, 'learning_rate': 1.214480010135387e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3800/5974 [36:20<19:11,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3068, 'grad_norm': 0.001220703125, 'learning_rate': 1.1690632384361033e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3850/5974 [36:47<19:50,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3027, 'grad_norm': 0.001220703125, 'learning_rate': 1.1239632307201866e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3900/5974 [37:14<18:44,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2922, 'grad_norm': 0.0012207032414153218, 'learning_rate': 1.0792231555314586e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3950/5974 [37:41<18:02,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2936, 'grad_norm': 0.001220703125, 'learning_rate': 1.0348858368957735e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4000/5974 [38:08<19:03,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3006, 'grad_norm': 0.001220703125, 'learning_rate': 9.909937133309805e-06, 'epoch': 1.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4050/5974 [38:34<16:33,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2931, 'grad_norm': 0.001220703125, 'learning_rate': 9.475887972258913e-06, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4100/5974 [39:01<16:21,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3033, 'grad_norm': 0.001220703125, 'learning_rate': 9.047126346271226e-06, 'epoch': 1.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4150/5974 [39:27<15:36,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2923, 'grad_norm': 0.001220703125, 'learning_rate': 8.624062654723102e-06, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4200/5974 [39:53<15:53,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3057, 'grad_norm': 0.001220703125, 'learning_rate': 8.207101843077618e-06, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4250/5974 [40:20<14:51,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2927, 'grad_norm': 0.0012207030085846782, 'learning_rate': 7.796643015281318e-06, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4289/5974 [40:40<15:01,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 127.4GB free, 48.8% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4300/5974 [40:46<14:51,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.301, 'grad_norm': 0.0012207030085846782, 'learning_rate': 7.393079051752473e-06, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4350/5974 [41:12<13:56,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2923, 'grad_norm': 0.001220703125, 'learning_rate': 6.996796233326207e-06, 'epoch': 1.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4400/5974 [41:39<13:36,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2809, 'grad_norm': 0.0012207032414153218, 'learning_rate': 6.6081738715166396e-06, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4450/5974 [42:05<13:33,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2869, 'grad_norm': 0.001220703125, 'learning_rate': 6.227583945449829e-06, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4500/5974 [42:31<12:24,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2804, 'grad_norm': 0.001220703125, 'learning_rate': 5.8553907458151655e-06, 'epoch': 1.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4550/5974 [42:57<12:12,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2828, 'grad_norm': 0.0012207032414153218, 'learning_rate': 5.491950526175844e-06, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4600/5974 [43:23<12:02,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2841, 'grad_norm': 0.001220703125, 'learning_rate': 5.1376111619723e-06, 'epoch': 1.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4650/5974 [43:50<11:42,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2903, 'grad_norm': 0.0012207030085846782, 'learning_rate': 4.792711817544993e-06, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4700/5974 [44:16<11:05,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2849, 'grad_norm': 0.0012207030085846782, 'learning_rate': 4.457582621495187e-06, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4750/5974 [44:42<11:05,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2825, 'grad_norm': 0.0006103515042923391, 'learning_rate': 4.132544350694518e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4776/5974 [44:56<10:42,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Combined_07/\n",
      "‚úÖ Backed up latest checkpoint checkpoint-4397 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4783/5974 [45:40<39:45,  2.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 127.4GB free, 48.8% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4800/5974 [45:50<10:50,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2718, 'grad_norm': 0.0006103515625, 'learning_rate': 3.817908123245786e-06, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4850/5974 [46:17<09:58,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2878, 'grad_norm': 0.0006103515625, 'learning_rate': 3.5139751006888813e-06, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4900/5974 [46:43<09:22,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2894, 'grad_norm': 0.0006103515042923391, 'learning_rate': 3.2210361997368597e-06, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4950/5974 [47:10<09:12,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2886, 'grad_norm': 0.0006103515625, 'learning_rate': 2.939371813818077e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5000/5974 [47:37<08:18,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2995, 'grad_norm': 0.0006103515625, 'learning_rate': 2.669251544691006e-06, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5050/5974 [48:02<08:21,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2802, 'grad_norm': 0.0006103516207076609, 'learning_rate': 2.4109339443884637e-06, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5100/5974 [48:29<07:53,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2784, 'grad_norm': 0.0006103515625, 'learning_rate': 2.164666267738402e-06, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5150/5974 [48:56<07:10,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2839, 'grad_norm': 0.0006103516207076609, 'learning_rate': 1.93068423569809e-06, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5200/5974 [49:22<06:47,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2798, 'grad_norm': 0.0006103515625, 'learning_rate': 1.709211809728185e-06, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5250/5974 [49:49<06:38,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2725, 'grad_norm': 0.0006103514460846782, 'learning_rate': 1.5004609774227085e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5300/5974 [50:16<06:15,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2928, 'grad_norm': 0.0006103515625, 'learning_rate': 1.3046315496000743e-06, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5346/5974 [50:41<05:41,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 127.4GB free, 48.8% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5350/5974 [50:43<05:32,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2737, 'grad_norm': 0.0006103516207076609, 'learning_rate': 1.1219109690494262e-06, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5400/5974 [51:10<05:05,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2749, 'grad_norm': 0.0006103515625, 'learning_rate': 9.52474131115319e-07, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5450/5974 [51:36<04:35,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.285, 'grad_norm': 0.0006103515625, 'learning_rate': 7.964832162924718e-07, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5500/5974 [52:03<04:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2733, 'grad_norm': 0.0006103515625, 'learning_rate': 6.540875349908704e-07, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5550/5974 [52:28<03:34,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2862, 'grad_norm': 0.0006103515625, 'learning_rate': 5.254233846197603e-07, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5600/5974 [52:55<03:16,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2899, 'grad_norm': 0.0006103515625, 'learning_rate': 4.106139191273262e-07, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5650/5974 [53:21<02:57,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2863, 'grad_norm': 0.0006103515625, 'learning_rate': 3.09769031120985e-07, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5700/5974 [53:48<02:30,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2757, 'grad_norm': 0.0006103515625, 'learning_rate': 2.229852466810589e-07, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5750/5974 [54:15<02:02,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2824, 'grad_norm': 0.0006103516207076609, 'learning_rate': 1.5034563296853099e-07, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5800/5974 [54:42<01:35,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2787, 'grad_norm': 0.0006103515625, 'learning_rate': 9.191971871536808e-08, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5850/5974 [55:09<01:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2743, 'grad_norm': 0.0006103515625, 'learning_rate': 4.776342767341124e-08, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5900/5974 [55:35<00:40,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.292, 'grad_norm': 0.0006103515625, 'learning_rate': 1.7919025085650907e-08, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5911/5974 [55:41<00:33,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 127.4GB free, 48.8% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5950/5974 [56:02<00:12,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2836, 'grad_norm': 0.0006103515042923391, 'learning_rate': 2.4150772310344015e-09, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5974/5974 [56:15<00:00,  1.96it/s]\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 4/375 [00:00<00:12, 30.76it/s]\u001b[A\n",
      "  2%|‚ñè         | 8/375 [00:00<00:14, 25.67it/s]\u001b[A\n",
      "  3%|‚ñé         | 11/375 [00:00<00:14, 24.40it/s]\u001b[A\n",
      "  4%|‚ñé         | 14/375 [00:00<00:15, 24.02it/s]\u001b[A\n",
      "  5%|‚ñç         | 17/375 [00:00<00:15, 23.57it/s]\u001b[A\n",
      "  5%|‚ñå         | 20/375 [00:00<00:15, 23.29it/s]\u001b[A\n",
      "  6%|‚ñå         | 23/375 [00:00<00:15, 23.05it/s]\u001b[A\n",
      "  7%|‚ñã         | 26/375 [00:01<00:15, 23.04it/s]\u001b[A\n",
      "  8%|‚ñä         | 29/375 [00:01<00:15, 22.94it/s]\u001b[A\n",
      "  9%|‚ñä         | 32/375 [00:01<00:14, 22.93it/s]\u001b[A\n",
      "  9%|‚ñâ         | 35/375 [00:01<00:14, 22.87it/s]\u001b[A\n",
      " 10%|‚ñà         | 38/375 [00:01<00:14, 23.19it/s]\u001b[A\n",
      " 11%|‚ñà         | 41/375 [00:01<00:14, 23.37it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 44/375 [00:01<00:15, 21.47it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 47/375 [00:02<00:15, 21.10it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 50/375 [00:02<00:15, 20.43it/s]\u001b[A\n",
      " 14%|‚ñà‚ñç        | 53/375 [00:02<00:15, 20.78it/s]\u001b[A\n",
      " 15%|‚ñà‚ñç        | 56/375 [00:02<00:15, 20.24it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 59/375 [00:02<00:15, 20.54it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 62/375 [00:02<00:15, 20.20it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 65/375 [00:02<00:15, 20.43it/s]\u001b[A\n",
      " 18%|‚ñà‚ñä        | 68/375 [00:03<00:14, 20.62it/s]\u001b[A\n",
      " 19%|‚ñà‚ñâ        | 71/375 [00:03<00:14, 21.41it/s]\u001b[A\n",
      " 20%|‚ñà‚ñâ        | 74/375 [00:03<00:13, 21.72it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà        | 77/375 [00:03<00:13, 22.15it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà‚ñè       | 80/375 [00:03<00:13, 22.35it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 83/375 [00:03<00:12, 22.67it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 86/375 [00:03<00:12, 22.73it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñé       | 89/375 [00:03<00:12, 23.07it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 92/375 [00:04<00:12, 23.23it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 95/375 [00:04<00:11, 23.49it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 98/375 [00:04<00:11, 23.54it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 101/375 [00:04<00:11, 23.68it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 104/375 [00:04<00:11, 23.67it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñä       | 107/375 [00:04<00:11, 23.52it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 110/375 [00:04<00:11, 23.54it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñà       | 113/375 [00:05<00:11, 23.38it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 116/375 [00:05<00:11, 23.41it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 119/375 [00:05<00:10, 23.54it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 122/375 [00:05<00:10, 23.54it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 125/375 [00:05<00:10, 23.45it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 128/375 [00:05<00:10, 23.08it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 131/375 [00:05<00:10, 23.39it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 134/375 [00:05<00:11, 20.60it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 137/375 [00:06<00:11, 20.14it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 140/375 [00:06<00:11, 21.04it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 143/375 [00:06<00:10, 21.39it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 146/375 [00:06<00:10, 21.88it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 149/375 [00:06<00:10, 22.47it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 152/375 [00:06<00:09, 22.88it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 155/375 [00:06<00:09, 23.15it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 158/375 [00:07<00:09, 23.25it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 161/375 [00:07<00:09, 23.42it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 164/375 [00:07<00:08, 23.54it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 167/375 [00:07<00:08, 23.67it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 170/375 [00:07<00:08, 23.61it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 173/375 [00:07<00:08, 23.59it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 176/375 [00:07<00:08, 23.30it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 179/375 [00:07<00:08, 23.22it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 182/375 [00:08<00:08, 23.40it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 185/375 [00:08<00:08, 23.47it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 188/375 [00:08<00:07, 23.74it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 191/375 [00:08<00:07, 23.90it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 194/375 [00:08<00:07, 23.84it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 197/375 [00:08<00:07, 23.44it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 200/375 [00:08<00:07, 23.27it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 203/375 [00:08<00:07, 23.01it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 206/375 [00:09<00:07, 22.87it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 209/375 [00:09<00:07, 22.96it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 212/375 [00:09<00:07, 22.49it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 215/375 [00:09<00:07, 22.43it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 218/375 [00:09<00:07, 22.41it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 221/375 [00:09<00:06, 22.54it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 224/375 [00:09<00:06, 22.59it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 227/375 [00:09<00:06, 22.94it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 230/375 [00:10<00:06, 23.24it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 233/375 [00:10<00:06, 23.39it/s]\u001b[A\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 236/375 [00:10<00:05, 23.56it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 239/375 [00:10<00:05, 23.16it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 242/375 [00:10<00:05, 23.37it/s]\u001b[A\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 245/375 [00:10<00:05, 23.51it/s]\u001b[A\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 248/375 [00:10<00:05, 23.61it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 251/375 [00:11<00:05, 23.66it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 254/375 [00:11<00:05, 23.73it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 257/375 [00:11<00:04, 23.76it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 260/375 [00:11<00:04, 23.82it/s]\u001b[A\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 263/375 [00:11<00:04, 23.69it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 266/375 [00:11<00:04, 23.67it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 269/375 [00:11<00:04, 23.74it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 272/375 [00:11<00:04, 23.75it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 275/375 [00:12<00:04, 23.81it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 278/375 [00:12<00:04, 23.84it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 281/375 [00:12<00:03, 23.74it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 284/375 [00:12<00:03, 23.35it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 287/375 [00:12<00:03, 23.10it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 290/375 [00:12<00:03, 22.96it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 293/375 [00:12<00:03, 23.07it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 296/375 [00:12<00:03, 23.38it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 299/375 [00:13<00:03, 23.54it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 302/375 [00:13<00:03, 23.04it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 305/375 [00:13<00:03, 23.15it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 308/375 [00:13<00:03, 22.33it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 311/375 [00:13<00:02, 21.81it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 314/375 [00:13<00:02, 21.62it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 317/375 [00:13<00:02, 21.75it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 320/375 [00:14<00:02, 22.17it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 323/375 [00:14<00:02, 22.29it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 326/375 [00:14<00:02, 22.68it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 329/375 [00:14<00:02, 22.63it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 332/375 [00:14<00:01, 23.06it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 335/375 [00:14<00:01, 23.35it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 338/375 [00:14<00:01, 23.54it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 341/375 [00:14<00:01, 23.64it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 344/375 [00:15<00:01, 23.76it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 347/375 [00:15<00:01, 23.77it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 350/375 [00:15<00:01, 23.82it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 353/375 [00:15<00:00, 23.90it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 356/375 [00:15<00:00, 23.97it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 359/375 [00:15<00:00, 23.97it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 362/375 [00:15<00:00, 23.98it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 365/375 [00:15<00:00, 23.95it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 368/375 [00:16<00:00, 23.99it/s]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 371/375 [00:16<00:00, 23.99it/s]\u001b[A\n",
      "                                                   A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5974/5974 [56:32<00:00,  1.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:16<00:00, 24.01it/s]\u001b[A\n",
      "                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06764795631170273, 'eval_f1_micro_t1': 0.3533725969552172, 'eval_f1_macro_t1': 0.3132469705767133, 'eval_f1_weighted_t1': 0.41794002559359933, 'eval_precision_micro_t1': 0.21999308197855413, 'eval_precision_macro_t1': 0.20609651617236116, 'eval_recall_micro_t1': 0.8975444538526672, 'eval_recall_macro_t1': 0.7929986863897789, 'eval_avg_preds_t1': 4.818333333333333, 'eval_f1_micro_t2': 0.5042620008972634, 'eval_f1_macro_t2': 0.42703999016238126, 'eval_f1_weighted_t2': 0.5298496717537751, 'eval_precision_micro_t2': 0.3696395685345962, 'eval_precision_macro_t2': 0.3420374067862844, 'eval_recall_micro_t2': 0.7931131809201242, 'eval_recall_macro_t2': 0.654737732657253, 'eval_avg_preds_t2': 2.534, 'eval_f1_micro_t3': 0.5764910248986682, 'eval_f1_macro_t3': 0.4747980278118723, 'eval_f1_weighted_t3': 0.5787679931418254, 'eval_precision_micro_t3': 0.48880597014925375, 'eval_precision_macro_t3': 0.41836976568439477, 'eval_recall_micro_t3': 0.7025119954840531, 'eval_recall_macro_t3': 0.5673717791204035, 'eval_avg_preds_t3': 1.6973333333333334, 'eval_precision_admiration': 0.6170798898071626, 'eval_recall_admiration': 0.8205128205128205, 'eval_f1_admiration': 0.7044025157232704, 'eval_precision_amusement': 0.6681818181818182, 'eval_recall_amusement': 0.84, 'eval_f1_amusement': 0.7443037974683544, 'eval_precision_anger': 0.34615384615384615, 'eval_recall_anger': 0.5943396226415094, 'eval_f1_anger': 0.4375, 'eval_precision_annoyance': 0.296551724137931, 'eval_recall_annoyance': 0.5, 'eval_f1_annoyance': 0.3722943722943723, 'eval_precision_approval': 0.3744075829383886, 'eval_recall_approval': 0.37264150943396224, 'eval_f1_approval': 0.3735224586288416, 'eval_precision_caring': 0.32222222222222224, 'eval_recall_caring': 0.7435897435897436, 'eval_f1_caring': 0.4496124031007752, 'eval_precision_confusion': 0.35, 'eval_recall_confusion': 0.5903614457831325, 'eval_f1_confusion': 0.43946188340807174, 'eval_precision_curiosity': 0.42213114754098363, 'eval_recall_curiosity': 0.762962962962963, 'eval_f1_curiosity': 0.5435356200527705, 'eval_precision_desire': 0.48333333333333334, 'eval_recall_desire': 0.6744186046511628, 'eval_f1_desire': 0.5631067961165048, 'eval_precision_disappointment': 0.20930232558139536, 'eval_recall_disappointment': 0.4, 'eval_f1_disappointment': 0.2748091603053435, 'eval_precision_disapproval': 0.43575418994413406, 'eval_recall_disapproval': 0.47560975609756095, 'eval_f1_disapproval': 0.45481049562682213, 'eval_precision_disgust': 0.3516483516483517, 'eval_recall_disgust': 0.5333333333333333, 'eval_f1_disgust': 0.423841059602649, 'eval_precision_embarrassment': 0.6923076923076923, 'eval_recall_embarrassment': 0.5294117647058824, 'eval_f1_embarrassment': 0.6, 'eval_precision_excitement': 0.34177215189873417, 'eval_recall_excitement': 0.5094339622641509, 'eval_f1_excitement': 0.4090909090909091, 'eval_precision_fear': 0.6206896551724138, 'eval_recall_fear': 0.6792452830188679, 'eval_f1_fear': 0.6486486486486487, 'eval_precision_gratitude': 0.915, 'eval_recall_gratitude': 0.8970588235294118, 'eval_f1_gratitude': 0.905940594059406, 'eval_precision_grief': 0.0, 'eval_recall_grief': 0.0, 'eval_f1_grief': 0.0, 'eval_precision_joy': 0.49645390070921985, 'eval_recall_joy': 0.6194690265486725, 'eval_f1_joy': 0.5511811023622047, 'eval_precision_love': 0.6457142857142857, 'eval_recall_love': 0.8968253968253969, 'eval_f1_love': 0.7508305647840532, 'eval_precision_nervousness': 0.3333333333333333, 'eval_recall_nervousness': 0.4166666666666667, 'eval_f1_nervousness': 0.37037037037037035, 'eval_precision_optimism': 0.5895522388059702, 'eval_recall_optimism': 0.6220472440944882, 'eval_f1_optimism': 0.6053639846743295, 'eval_precision_pride': 0.0, 'eval_recall_pride': 0.0, 'eval_f1_pride': 0.0, 'eval_precision_realization': 0.2037037037037037, 'eval_recall_realization': 0.3055555555555556, 'eval_f1_realization': 0.24444444444444444, 'eval_precision_relief': 0.0, 'eval_recall_relief': 0.0, 'eval_f1_relief': 0.0, 'eval_precision_remorse': 0.5901639344262295, 'eval_recall_remorse': 0.8780487804878049, 'eval_f1_remorse': 0.7058823529411765, 'eval_precision_sadness': 0.3825503355704698, 'eval_recall_sadness': 0.6785714285714286, 'eval_f1_sadness': 0.4892703862660944, 'eval_precision_surprise': 0.49, 'eval_recall_surprise': 0.6805555555555556, 'eval_f1_surprise': 0.5697674418604651, 'eval_precision_neutral': 0.5363457760314342, 'eval_recall_neutral': 0.8657505285412262, 'eval_f1_neutral': 0.6623534169025476, 'eval_f1_micro_t4': 0.5941571800850364, 'eval_f1_macro_t4': 0.46576233552667656, 'eval_f1_weighted_t4': 0.5781707683785114, 'eval_precision_micro_t4': 0.5779082177161152, 'eval_precision_macro_t4': 0.5057253717884304, 'eval_recall_micro_t4': 0.611346316680779, 'eval_recall_macro_t4': 0.47207278840769734, 'eval_avg_preds_t4': 1.2493333333333334, 'eval_f1_micro_t5': 0.5774445685117243, 'eval_f1_macro_t5': 0.4274092035760928, 'eval_f1_weighted_t5': 0.5419207010421013, 'eval_precision_micro_t5': 0.6639765223771094, 'eval_precision_macro_t5': 0.5357255505938078, 'eval_recall_micro_t5': 0.5108664973186565, 'eval_recall_macro_t5': 0.390119470995354, 'eval_avg_preds_t5': 0.9086666666666666, 'eval_f1_micro_t6': 0.5325122260460061, 'eval_f1_macro_t6': 0.36916038388522304, 'eval_f1_weighted_t6': 0.4841267227050037, 'eval_precision_micro_t6': 0.7431749241658241, 'eval_precision_macro_t6': 0.5803049219127624, 'eval_recall_micro_t6': 0.41490262489415747, 'eval_recall_macro_t6': 0.3098681511907791, 'eval_avg_preds_t6': 0.6593333333333333, 'eval_f1_micro_t7': 0.4574898785425101, 'eval_f1_macro_t7': 0.2834825746715241, 'eval_f1_weighted_t7': 0.39963003901322375, 'eval_precision_micro_t7': 0.8088761632068718, 'eval_precision_macro_t7': 0.5759150076641302, 'eval_recall_micro_t7': 0.31893875246965847, 'eval_recall_macro_t7': 0.22673115578099742, 'eval_avg_preds_t7': 0.4656666666666667, 'eval_f1_micro_t8': 0.3396825396825397, 'eval_f1_macro_t8': 0.1714982686784552, 'eval_f1_weighted_t8': 0.2820128748197891, 'eval_precision_micro_t8': 0.8638985005767013, 'eval_precision_macro_t8': 0.41003420252477485, 'eval_recall_micro_t8': 0.2114027660174993, 'eval_recall_macro_t8': 0.1309160021820272, 'eval_avg_preds_t8': 0.289, 'eval_f1_micro_t9': 0.16576576576576577, 'eval_f1_macro_t9': 0.07554884013483297, 'eval_f1_weighted_t9': 0.11838461778437401, 'eval_precision_micro_t9': 0.9415204678362573, 'eval_precision_macro_t9': 0.16567401005429636, 'eval_recall_micro_t9': 0.09088343211967259, 'eval_recall_macro_t9': 0.058364881324134796, 'eval_avg_preds_t9': 0.114, 'eval_f1_micro': 0.5042620008972634, 'eval_f1_macro': 0.42703999016238126, 'eval_f1_weighted': 0.5298496717537751, 'eval_precision_micro': 0.3696395685345962, 'eval_precision_macro': 0.3420374067862844, 'eval_recall_micro': 0.7931131809201242, 'eval_recall_macro': 0.654737732657253, 'eval_primary_threshold': 0.2, 'eval_f1_micro_default': 0.5774445685117243, 'eval_f1_macro_default': 0.4274092035760928, 'eval_f1_weighted_default': 0.5419207010421013, 'eval_class_imbalance_ratio': 105.11111450195312, 'eval_prediction_entropy': 3.54439640045166, 'eval_runtime': 16.8552, 'eval_samples_per_second': 177.987, 'eval_steps_per_second': 22.248, 'epoch': 2.0}\n",
      "üíæ Disk space: 122.6GB free, 50.8% used\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Combined_07/\n",
      "‚úÖ Backed up latest checkpoint checkpoint-5974 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5974/5974 [1:00:16<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3616.7125, 'train_samples_per_second': 26.425, 'train_steps_per_second': 1.652, 'train_loss': 0.3670233117324834, 'epoch': 2.0}\n",
      "‚úÖ Saved ensemble models to ./outputs/phase1_Combined_07_ensemble\n",
      "üìä Final evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:16<00:00, 22.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Performing final backup to Google Drive...\n",
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Combined_07/\n",
      "‚úÖ Backed up checkpoint-4397 to Google Drive\n",
      "‚úÖ Backed up checkpoint-2987 to Google Drive\n",
      "‚úÖ Backed up checkpoint-5974 to Google Drive\n",
      "‚úÖ Backup to Google Drive completed\n",
      "‚úÖ Training completed!\n",
      "üìà Final F1 Macro: 0.4270\n",
      "üìà Final F1 Micro: 0.5043\n",
      "üìà Final F1 Weighted: 0.5298\n",
      "üìä Class Imbalance Ratio: 105.11\n",
      "üî¨ Scientific log: ./outputs/phase1_Combined_07/scientific_log_20250910_142143.json\n",
      "üíæ Model saved to: ./outputs/phase1_Combined_07\n",
      "‚úÖ Combined_07 completed successfully!\n",
      "üöÄ Starting Combined_05 on GPU 0\n",
      "Command: python3 notebooks/scripts/train_deberta_local.py --output_dir ./outputs/phase1_Combined_05 --model_type deberta-v3-large --per_device_train_batch_size 4 --per_device_eval_batch_size 8 --gradient_accumulation_steps 4 --num_train_epochs 2 --learning_rate 3e-5 --lr_scheduler_type cosine --warmup_ratio 0.15 --weight_decay 0.01 --fp16 --max_length 256 --max_train_samples 20000 --max_eval_samples 3000 --augment_prob 0 --use_combined_loss --loss_combination_ratio 0.5\n",
      "üöÄ Executing training command...\n",
      "üíæ Disk space at startup: 103.1GB free, 58.6% used\n",
      "üöÄ GoEmotions DeBERTa Training (SCIENTIFIC VERSION)\n",
      "============================================================\n",
      "üìÅ Output directory: ./outputs/phase1_Combined_05\n",
      "ü§ñ Model: deberta-v3-large (from local cache)\n",
      "üìä Dataset: GoEmotions (from local cache)\n",
      "üî¨ Scientific logging: ENABLED\n",
      "ü§ñ Loading deberta-v3-large...\n",
      "üìÅ Found local cache at models/deberta-v3-large\n",
      "‚úÖ deberta-v3-large tokenizer loaded from local cache\n",
      "‚úÖ deberta-v3-large model loaded from local cache\n",
      "üìä Loading GoEmotions dataset from local cache...\n",
      "‚úÖ GoEmotions dataset loaded from local cache\n",
      "   Training examples: 43410\n",
      "   Validation examples: 5426\n",
      "   Total emotions: 28\n",
      "üîÑ Creating datasets...\n",
      "‚úÖ Created 43410 training examples\n",
      "‚úÖ Created 5426 validation examples\n",
      "üîÑ Limiting training data: 43410 ‚Üí 20000 samples\n",
      "‚úÖ Using 20000 training examples (subset for quick screening)\n",
      "üîÑ Limiting validation data: 5426 ‚Üí 3000 samples\n",
      "‚úÖ Using 3000 validation examples (subset for quick screening)\n",
      "üîß Disabling gradient checkpointing to prevent RuntimeError during backward pass\n",
      "üöÄ Using Combined Loss (ASL + Class Weighting + Focal Loss) for maximum performance\n",
      "üìä Loss combination ratio: 0.5 ASL + 0.5 Focal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-10 15:27:04,087] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-09-10 15:27:05,719] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "üìä Class weights computed: tensor([ 0.3754,  0.6660,  0.9894,  0.6277,  0.5275,  1.4263,  1.1333,  0.7076,\n",
      "         2.4187,  1.2217,  0.7667,  1.9551,  5.1167,  1.8175,  2.6013,  0.5824,\n",
      "        20.1345,  1.0677,  0.7432,  9.4534,  0.9806, 13.9672,  1.3967, 10.1331,\n",
      "         2.8447,  1.1692,  1.4626,  0.1090])\n",
      "üéØ Loss combination: 0.5 ASL + 0.5 Focal\n",
      "üìä Rare classes identified: [16, 21, 23, 19, 12, 24, 14, 8, 11, 13, 26, 5, 22, 9] (threshold: 1326 samples)\n",
      "üìà Oversampled class grief: 77 ‚Üí 115\n",
      "üìà Oversampled class pride: 111 ‚Üí 166\n",
      "üìà Oversampled class relief: 153 ‚Üí 229\n",
      "üìà Oversampled class nervousness: 164 ‚Üí 246\n",
      "üìà Oversampled class embarrassment: 303 ‚Üí 454\n",
      "üìà Oversampled class remorse: 545 ‚Üí 817\n",
      "üìà Oversampled class fear: 596 ‚Üí 894\n",
      "üìà Oversampled class desire: 641 ‚Üí 961\n",
      "üìà Oversampled class disgust: 793 ‚Üí 1189\n",
      "üìà Oversampled class excitement: 853 ‚Üí 1279\n",
      "üìà Oversampled class surprise: 1060 ‚Üí 1590\n",
      "üìà Oversampled class caring: 1087 ‚Üí 1630\n",
      "üìà Oversampled class realization: 1110 ‚Üí 1665\n",
      "üìà Oversampled class disappointment: 1269 ‚Üí 1903\n",
      "‚úÖ Stratified oversampling applied: 43410 ‚Üí 47786 samples\n",
      "‚úÖ Oversampling applied for rare classes\n",
      "üîÑ Creating oversampled training dataset...\n",
      "‚úÖ Oversampled training dataset: 47786 examples\n",
      "üöÄ Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5974 [00:00<?, ?it/s]/venv/deberta-v3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2752: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "  1%|          | 50/5974 [00:28<52:54,  1.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4155, 'grad_norm': 7.62939453125e-05, 'learning_rate': 1.6387959866220736e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 100/5974 [00:54<50:56,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2869, 'grad_norm': 7.62939453125e-05, 'learning_rate': 3.311036789297659e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 150/5974 [01:21<50:36,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9953, 'grad_norm': 7.62939453125e-05, 'learning_rate': 4.983277591973244e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 200/5974 [01:48<51:59,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7078, 'grad_norm': 7.62939453125e-05, 'learning_rate': 6.65551839464883e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 250/5974 [02:15<50:57,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5196, 'grad_norm': 7.62939453125e-05, 'learning_rate': 8.327759197324414e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 300/5974 [02:42<48:52,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4494, 'grad_norm': 7.62939453125e-05, 'learning_rate': 9.999999999999999e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 350/5974 [03:09<47:28,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4232, 'grad_norm': 0.00015258790517691523, 'learning_rate': 1.1638795986622074e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 400/5974 [03:35<49:42,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4326, 'grad_norm': 0.00015258790517691523, 'learning_rate': 1.331103678929766e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 450/5974 [04:04<50:20,  1.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4233, 'grad_norm': 0.000152587890625, 'learning_rate': 1.4983277591973246e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 500/5974 [04:32<51:33,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4191, 'grad_norm': 0.000152587890625, 'learning_rate': 1.6655518394648828e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 542/5974 [04:56<52:13,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 103.1GB free, 58.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 550/5974 [05:00<49:32,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4173, 'grad_norm': 0.00015258787607308477, 'learning_rate': 1.8327759197324415e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 600/5974 [05:29<48:21,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4221, 'grad_norm': 0.00015258787607308477, 'learning_rate': 1.9999999999999998e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 650/5974 [05:56<47:46,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3946, 'grad_norm': 0.000152587890625, 'learning_rate': 2.1672240802675585e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 700/5974 [06:22<46:46,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3934, 'grad_norm': 0.00015258787607308477, 'learning_rate': 2.334448160535117e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 750/5974 [06:49<44:11,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4087, 'grad_norm': 0.00015258790517691523, 'learning_rate': 2.5016722408026756e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 800/5974 [07:16<48:07,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3926, 'grad_norm': 0.000152587890625, 'learning_rate': 2.668896321070234e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 850/5974 [07:45<51:57,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3997, 'grad_norm': 0.00015258790517691523, 'learning_rate': 2.8361204013377926e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 900/5974 [08:12<45:24,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3944, 'grad_norm': 0.000152587890625, 'learning_rate': 2.9999997128249746e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 950/5974 [08:39<44:56,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3809, 'grad_norm': 0.000152587890625, 'learning_rate': 2.999253119724526e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 1000/5974 [09:06<44:16,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3706, 'grad_norm': 0.00015258786152116954, 'learning_rate': 2.9970714808829057e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 1050/5974 [09:33<42:43,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3909, 'grad_norm': 0.000152587890625, 'learning_rate': 2.9934568845075605e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 1091/5974 [09:56<46:40,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 103.1GB free, 58.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 1100/5974 [10:01<44:43,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3762, 'grad_norm': 0.00015258791972883046, 'learning_rate': 2.988412790395283e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 1150/5974 [10:29<44:16,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3705, 'grad_norm': 0.000152587890625, 'learning_rate': 2.981944026620584e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 1200/5974 [10:58<44:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3563, 'grad_norm': 0.00015258787607308477, 'learning_rate': 2.974056784914389e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà        | 1250/5974 [11:25<43:41,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3507, 'grad_norm': 0.00015258790517691523, 'learning_rate': 2.964758614737473e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 1300/5974 [11:52<42:04,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3486, 'grad_norm': 0.000152587890625, 'learning_rate': 2.9540584160543175e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 1350/5974 [12:19<40:14,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3425, 'grad_norm': 0.000152587890625, 'learning_rate': 2.941966430814295e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 1400/5974 [12:45<41:15,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.351, 'grad_norm': 0.000152587890625, 'learning_rate': 2.9284942331483467e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 1450/5974 [13:12<41:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3524, 'grad_norm': 0.00015258787607308477, 'learning_rate': 2.9136547182905262e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 1500/5974 [13:40<43:51,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3351, 'grad_norm': 0.00015258790517691523, 'learning_rate': 2.897462090235021e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 1550/5974 [14:08<41:14,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3408, 'grad_norm': 0.000152587890625, 'learning_rate': 2.879931848140461e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 1600/5974 [14:35<38:57,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3374, 'grad_norm': 0.000152587890625, 'learning_rate': 2.8610807714945315e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 1640/5974 [14:56<39:13,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Backing up training outputs to Google Drive: 'drive:00_Projects/üéØ TechLabs-2025/Final_Project/TRAINING/GoEmotions-DeBERTa-Backup/'phase1_Combined_05/\n",
      "‚úÖ Backup to Google Drive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 1641/5974 [15:43<17:27:07, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Disk space: 103.1GB free, 58.6% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 1650/5974 [15:48<1:20:02,  1.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3345, 'grad_norm': 0.000152587890625, 'learning_rate': 2.8409269040530877e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 1700/5974 [16:15<38:39,  1.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3323, 'grad_norm': 0.000152587890625, 'learning_rate': 2.8194895365691448e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñâ       | 1750/5974 [16:41<36:04,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3352, 'grad_norm': 0.00030517581035383046, 'learning_rate': 2.797255433940467e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 1800/5974 [17:08<36:33,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3469, 'grad_norm': 0.0006103515625, 'learning_rate': 2.7738287999619898e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà       | 1850/5974 [17:34<36:17,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3621, 'grad_norm': 0.0006103515625, 'learning_rate': 2.748717141592346e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 1900/5974 [18:01<37:34,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.372, 'grad_norm': 0.0006103515042923391, 'learning_rate': 2.722410243944962e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 1950/5974 [18:28<36:31,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3437, 'grad_norm': 0.0006103515042923391, 'learning_rate': 2.694933287291891e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 2000/5974 [18:56<35:45,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3412, 'grad_norm': 0.0006103515042923391, 'learning_rate': 2.666312571854962e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 2050/5974 [19:22<35:34,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3387, 'grad_norm': 0.0006103516207076609, 'learning_rate': 2.6365754926318946e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 2100/5974 [19:49<33:34,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3381, 'grad_norm': 0.0006103514460846782, 'learning_rate': 2.6057505131745288e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 2150/5974 [20:15<33:32,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3417, 'grad_norm': 0.0006103516207076609, 'learning_rate': 2.5738671383442585e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 2185/5974 [20:34<35:07,  1.80it/s]Traceback (most recent call last):\n",
      "  File \"/home/user/goemotions-deberta/notebooks/scripts/train_deberta_local.py\", line 1273, in <module>\n",
      "    main()\n",
      "  File \"/home/user/goemotions-deberta/notebooks/scripts/train_deberta_local.py\", line 1195, in main\n",
      "    trainer.train()\n",
      "  File \"/venv/deberta-v3/lib/python3.10/site-packages/transformers/trainer.py\", line 2328, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/venv/deberta-v3/lib/python3.10/site-packages/transformers/trainer.py\", line 2672, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "  File \"/home/user/goemotions-deberta/notebooks/scripts/train_deberta_local.py\", line 612, in training_step\n",
      "    self.accelerator.backward(loss)\n",
      "  File \"/venv/deberta-v3/lib/python3.10/site-packages/accelerate/accelerator.py\", line 2730, in backward\n",
      "    self.scaler.scale(loss).backward(**kwargs)\n",
      "  File \"/venv/deberta-v3/lib/python3.10/site-packages/torch/_tensor.py\", line 648, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/venv/deberta-v3/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 353, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/venv/deberta-v3/lib/python3.10/site-packages/torch/autograd/graph.py\", line 824, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 61\u001b[0m\n\u001b[1;32m     52\u001b[0m configs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     53\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBCE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     54\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsymmetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombined_03\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m     58\u001b[0m ]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, asym, ratio \u001b[38;5;129;01min\u001b[39;00m configs:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mrun_config_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masym\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müéâ PHASE 1 SEQUENTIAL COMPLETE!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä Outputs: ./outputs/phase1_BCE/, ./outputs/phase1_Asymmetric/, etc.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m, in \u001b[0;36mrun_config_seq\u001b[0;34m(config_name, use_asym, ratio)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ Executing training command...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/venv/deberta-v3/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/venv/deberta-v3/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/venv/deberta-v3/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/venv/deberta-v3/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/venv/deberta-v3/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PHASE 1: Sequential Training Implementation\n",
    "import subprocess, time\n",
    "import os\n",
    "\n",
    "print(\"üöÄ PHASE 1: Sequential Single-GPU Training - 5 Configs\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def run_config_seq(config_name, use_asym=False, ratio=None):\n",
    "    \"\"\"Run training on GPU 0 sequentially\"\"\"\n",
    "    print(f\"üöÄ Starting {config_name} on GPU 0\")\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    env['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    \n",
    "    cmd = [\n",
    "        'python3', 'notebooks/scripts/train_deberta_local.py',\n",
    "        '--output_dir', f'./outputs/phase1_{config_name}',\n",
    "        '--model_type', 'deberta-v3-large',\n",
    "        '--per_device_train_batch_size', '4',\n",
    "        '--per_device_eval_batch_size', '8',\n",
    "        '--gradient_accumulation_steps', '4',\n",
    "        '--num_train_epochs', '2',\n",
    "        '--learning_rate', '3e-5',\n",
    "        '--lr_scheduler_type', 'cosine',\n",
    "        '--warmup_ratio', '0.15',\n",
    "        '--weight_decay', '0.01',\n",
    "        '--fp16',\n",
    "        '--max_length', '256',\n",
    "        '--max_train_samples', '20000',\n",
    "        '--max_eval_samples', '3000',\n",
    "        '--augment_prob', '0'\n",
    "    ]\n",
    "    \n",
    "    if use_asym: \n",
    "        cmd += ['--use_asymmetric_loss']\n",
    "    if ratio is not None: \n",
    "        cmd += ['--use_combined_loss', '--loss_combination_ratio', str(ratio)]\n",
    "    \n",
    "    print(f\"Command: {' '.join(cmd)}\")\n",
    "    \n",
    "    print(f\"üöÄ Executing training command...\")\n",
    "    result = subprocess.run(cmd, env=env)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ {config_name} completed successfully!\")\n",
    "    else:\n",
    "        print(f\"‚ùå {config_name} failed with return code: {result.returncode}\")\n",
    "    \n",
    "    return result.returncode\n",
    "\n",
    "# Run all 5 configs sequentially\n",
    "configs = [\n",
    "    ('BCE', False, None),\n",
    "    ('Asymmetric', True, None),\n",
    "    ('Combined_07', False, 0.7),\n",
    "    ('Combined_05', False, 0.5),\n",
    "    ('Combined_03', False, 0.3)\n",
    "]\n",
    "\n",
    "for name, asym, ratio in configs:\n",
    "    run_config_seq(name, asym, ratio)\n",
    "\n",
    "print(\"\\nüéâ PHASE 1 SEQUENTIAL COMPLETE!\")\n",
    "print(\"üìä Outputs: ./outputs/phase1_BCE/, ./outputs/phase1_Asymmetric/, etc.\")\n",
    "print(\"üîç Run analysis cell for F1@0.2 comparison vs baseline 42.18% (target >50%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca589e2c",
   "metadata": {},
   "source": [
    "## PHASE 2: Analysis and Results\n",
    "\n",
    "**Load eval_report.json from all configs, extract f1_macro_t2, compare to baseline 42.18%.**\n",
    "\n",
    "- Success if >50%\n",
    "- Diagnose if below (check loss curve, class F1)\n",
    "- HF multi-label best practices: threshold sweep, per-class weights effective on rare emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05826ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 2: RESULTS ANALYSIS (Threshold=0.2)\n",
    "import json, os\n",
    "\n",
    "BASELINE_F1 = 0.4218  # Original notebook line 1405\n",
    "\n",
    "def load_results(dirs):\n",
    "    results = {}\n",
    "    for d in dirs:\n",
    "        path = os.path.join(d, 'eval_report.json')\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            name = d.split('/')[-1]\n",
    "            f1_t2 = data.get('f1_macro_t2', data.get('f1_macro', 0.0))\n",
    "            results[name] = {'f1_macro_t2': f1_t2, 'success': f1_t2 > 0.50, 'improvement': ((f1_t2 - BASELINE_F1) / BASELINE_F1) * 100}\n",
    "            print(f\"‚úÖ {name}: F1@0.2 = {f1_t2:.4f} ({'SUCCESS >50%' if results[name]['success'] else 'NEEDS IMPROVEMENT'})\")\n",
    "        else:\n",
    "            print(f\"‚è≥ {d.split('/')[-1]}: Not completed\")\n",
    "    return results\n",
    "\n",
    "# Load Phase 1 results\n",
    "dirs = ['./outputs/phase1_BCE', './outputs/phase1_Asymmetric', \n",
    "        './outputs/phase1_Combined_07', './outputs/phase1_Combined_05', \n",
    "        './outputs/phase1_Combined_03']\n",
    "\n",
    "results = load_results(dirs)\n",
    "\n",
    "# Handle empty results case\n",
    "if not results:\n",
    "    best_f1 = 0.0\n",
    "else:\n",
    "    best_f1 = max([r['f1_macro_t2'] for r in results.values()])\n",
    "\n",
    "print(f\"\\nüèÜ BEST F1@0.2: {best_f1:.4f} ({'SUCCESS' if best_f1 > 0.50 else 'BELOW TARGET (42.18% baseline)'}\")\n",
    "\n",
    "if best_f1 > 0.50:\n",
    "    print(\"‚úÖ PHASE 3 READY: Add cell for top configs with extended training\")\n",
    "else:\n",
    "    print(\"üîç DIAGNOSE: Check loss curve, class-wise F1 for rare emotions\")\n",
    "\n",
    "print(\"\\nüìÅ All outputs: ./outputs/phase1_*/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d073e",
   "metadata": {},
   "source": [
    "## PHASE 3: Extended Training (Top Configs)\n",
    "\n",
    "**If Phase 1 achieved >50% F1, train top 2 configs with 3 epochs, 30k samples.**\n",
    "\n",
    "- Extended training for better convergence\n",
    "- Same fixes: pos_weight, oversampling, threshold=0.2\n",
    "- Target: 55-65% F1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2376c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 3: EXTENDED TRAINING (if Phase 1 success)\n",
    "if best_f1 > 0.50 and results:\n",
    "    print(\"üöÄ PHASE 3: Extended Training for Top Configs\")\n",
    "    \n",
    "    top_configs = sorted(results.items(), key=lambda x: x[1]['f1_macro_t2'], reverse=True)[:2]\n",
    "    print(f\"Top configs: {top_configs[0][0]} + {top_configs[1][0]}\")\n",
    "    \n",
    "    for name, result in top_configs:\n",
    "        asym = 'Asymmetric' in name\n",
    "        ratio = None\n",
    "        if 'Combined' in name:\n",
    "            ratio = float(name.split('_')[-1]) / 100 if name.split('_')[-1].isdigit() and len(name.split('_')[-1]) == 2 else float('0.' + name.split('_')[-1])\n",
    "        \n",
    "        # Extended params\n",
    "        cmd = [\n",
    "            'python3', 'notebooks/scripts/train_deberta_local.py',\n",
    "            '--output_dir', f'./outputs/phase3_{name}',\n",
    "            '--model_type', 'deberta-v3-large',\n",
    "            '--per_device_train_batch_size', '4',\n",
    "            '--per_device_eval_batch_size', '8',\n",
    "            '--gradient_accumulation_steps', '4',\n",
    "            '--num_train_epochs', '3',\n",
    "            '--learning_rate', '3e-5',\n",
    "            '--lr_scheduler_type', 'cosine',\n",
    "            '--warmup_ratio', '0.15',\n",
    "            '--weight_decay', '0.01',\n",
    "            '--fp16',\n",
    "            '--max_length', '256',\n",
    "            '--max_train_samples', '30000',\n",
    "            '--max_eval_samples', '3000',\n",
    "            '--augment_prob', '0'\n",
    "        ]\n",
    "        \n",
    "        if asym: cmd += ['--use_asymmetric_loss']\n",
    "        if ratio is not None: cmd += ['--use_combined_loss', '--loss_combination_ratio', str(ratio)]\n",
    "        \n",
    "        env = os.environ.copy()\n",
    "        env['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        \n",
    "        print(f\"Running extended {name}...\")\n",
    "        print(f\"üöÄ Executing extended training command...\")\n",
    "        result = subprocess.run(cmd, env=env)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ Extended {name} completed successfully!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Extended {name} failed with return code: {result.returncode}\")\n",
    "        \n",
    "    print(\"\\nüéâ PHASE 3 EXTENDED TRAINING COMPLETE!\")\n",
    "else:\n",
    "    print(\"‚è≥ PHASE 3 SKIPPED: Phase 1 F1 below 50% threshold\")\n",
    "    print(\"üîß Consider debugging or adjusting hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d14056",
   "metadata": {},
   "source": [
    "## PHASE 4: Final Evaluation and Model Selection\n",
    "\n",
    "**Compare all results, select best model, validate on full validation set.**\n",
    "\n",
    "- Load all eval_report.json files\n",
    "- Select model with highest F1@0.2\n",
    "- Run final full evaluation\n",
    "- Save best model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b456e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 4: FINAL EVALUATION AND MODEL SELECTION\n",
    "print(\"üöÄ PHASE 4: Final Evaluation and Model Selection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load all results (Phase 1 + Phase 3)\n",
    "all_dirs = [\n",
    "    './outputs/phase1_BCE', './outputs/phase1_Asymmetric', \n",
    "    './outputs/phase1_Combined_07', './outputs/phase1_Combined_05', \n",
    "    './outputs/phase1_Combined_03'\n",
    "]\n",
    "\n",
    "if best_f1 > 0.50 and results:\n",
    "    top_configs = sorted(results.items(), key=lambda x: x[1]['f1_macro_t2'], reverse=True)[:2]\n",
    "    all_dirs.extend([f'./outputs/phase3_{name}' for name, _ in top_configs])\n",
    "\n",
    "all_results = load_results(all_dirs)\n",
    "\n",
    "# Handle empty results case\n",
    "if not all_results:\n",
    "    best_f1_final = 0.0\n",
    "    best_name = \"None\"\n",
    "    best_data = {'f1_macro_t2': 0.0, 'improvement': 0.0}\n",
    "else:\n",
    "    # Find absolute best\n",
    "    best_model = max(all_results.items(), key=lambda x: x[1]['f1_macro_t2'])\n",
    "    best_name, best_data = best_model\n",
    "    best_f1_final = best_data['f1_macro_t2']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_name}\")\n",
    "print(f\"üìä Final F1@0.2: {best_f1_final:.4f}\")\n",
    "print(f\"‚úÖ Success: {'YES' if best_f1_final > 0.50 else 'NO'} (target >50% vs baseline 42.18%)\")\n",
    "print(f\"ÔøΩÔøΩ Improvement: {best_data['improvement']:.1f}% over baseline\")\n",
    "\n",
    "# Copy best model to final location\n",
    "if all_results:\n",
    "    best_dir = [d for d in all_dirs if best_name in d][0]\n",
    "    final_dir = './outputs/best_deberta_model'\n",
    "    \n",
    "    if os.path.exists(best_dir):\n",
    "        import shutil\n",
    "        shutil.copytree(best_dir, final_dir, dirs_exist_ok=True)\n",
    "        print(f\"üíæ Best model copied to: {final_dir}\")\n",
    "\n",
    "# Final validation (full dataset)\n",
    "print(\"\\nüîç Running final full validation...\")\n",
    "final_cmd = [\n",
    "    'python3', 'notebooks/scripts/train_deberta_local.py',\n",
    "    '--output_dir', './outputs/best_deberta_model',\n",
    "    '--model_type', 'deberta-v3-large',\n",
    "    '--do_eval',\n",
    "    '--max_eval_samples', '6000',\n",
    "    '--per_device_eval_batch_size', '8',\n",
    "    '--evaluation_strategy', 'no',\n",
    "    '--load_best_model_at_end', 'False'\n",
    "]\n",
    "\n",
    "env = os.environ.copy()\n",
    "env['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "print(f\"üöÄ Executing final validation...\")\n",
    "result = subprocess.run(final_cmd, env=env)\n",
    "print(\"‚úÖ Final validation complete!\")\n",
    "\n",
    "print(\"\\nüéâ PHASE 4 COMPLETE - Training pipeline finished!\")\n",
    "print(\"\\nüìÅ Final model: ./outputs/best_deberta_model/\")\n",
    "print(\"üéØ Achievement: \" + (\"SUCCESS >50% F1!\" if best_f1_final > 0.50 else \"Needs improvement\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIVE MONITORING UTILITIES\n",
    "import subprocess, glob, os, json\n",
    "\n",
    "def monitor_processes():\n",
    "    result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)\n",
    "    processes = [line for line in result.stdout.split('\\n') if 'train_deberta_local' in line]\n",
    "    if processes:\n",
    "        print(\"üîÑ Active processes:\")\n",
    "        for p in processes: print(f\"  {p}\")\n",
    "    else:\n",
    "        print(\"‚è∏Ô∏è No active training\")\n",
    "    print(\"\\nüñ•Ô∏è GPU status:\")\n",
    "    !nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used --format=csv\n",
    "\n",
    "def check_all_results():\n",
    "    \"\"\"Check results from all training phases\"\"\"\n",
    "    print(\"üìä COMPLETE RESULTS DASHBOARD\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    configs = ['BCE', 'Asymmetric', 'Combined_07', 'Combined_05', 'Combined_03']\n",
    "    all_f1_scores = []\n",
    "    \n",
    "    for config in configs:\n",
    "        eval_file = f'./outputs/phase1_{config}/eval_report.json'\n",
    "        if os.path.exists(eval_file):\n",
    "            try:\n",
    "                with open(eval_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                f1_score = data.get('f1_macro_t2', 0.0)\n",
    "                all_f1_scores.append(f1_score)\n",
    "                \n",
    "                if f1_score > 0.50:\n",
    "                    status = \"üéâ TARGET ACHIEVED\"\n",
    "                elif f1_score > 0.4218:\n",
    "                    status = \"üìà BEATS BASELINE\"\n",
    "                else:\n",
    "                    status = \"üìâ BELOW BASELINE\"\n",
    "                \n",
    "                print(f\"{config:15}: F1={f1_score:.4f} {status}\")\n",
    "            except:\n",
    "                print(f\"{config:15}: ‚ùå Error reading results\")\n",
    "        else:\n",
    "            print(f\"{config:15}: ‚è≥ Not completed\")\n",
    "    \n",
    "    if all_f1_scores:\n",
    "        best_f1 = max(all_f1_scores)\n",
    "        above_baseline = sum(1 for f1 in all_f1_scores if f1 > 0.4218)\n",
    "        \n",
    "        print(f\"\\nüèÜ SUMMARY:\")\n",
    "        print(f\"Best F1: {best_f1:.4f}\")\n",
    "        print(f\"Configs above baseline: {above_baseline}/{len(all_f1_scores)}\")\n",
    "        \n",
    "        if above_baseline >= 3:\n",
    "            print(\"üéâ EXCELLENT! Multiple configs working!\")\n",
    "        elif above_baseline >= 1:\n",
    "            print(\"‚úÖ SUCCESS! At least one config beats baseline!\")\n",
    "\n",
    "def tail_logs(pattern='*.log'):\n",
    "    logs = glob.glob(pattern)\n",
    "    for log in logs[-2:]:\n",
    "        print(f\"\\nüìä {log}:\")\n",
    "        !tail -5 {log}\n",
    "\n",
    "# Execute monitoring\n",
    "monitor_processes()\n",
    "check_all_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5d88a",
   "metadata": {},
   "source": [
    "## PHASE 5: Deployment Preparation\n",
    "\n",
    "**Prepare best model for deployment.**\n",
    "\n",
    "- Convert to deployment format\n",
    "- Create inference pipeline\n",
    "- Test on sample data\n",
    "- Package for production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
