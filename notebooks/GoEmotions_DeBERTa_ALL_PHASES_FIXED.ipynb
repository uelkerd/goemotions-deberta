{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b07e7f6",
   "metadata": {},
   "source": [
    "# GoEmotions DeBERTa-v3-large IMPROVED Workflow\n",
    "\n",
    "## Sequential Training with Enhanced Monitoring\n",
    "\n",
    "**GOAL**: Achieve >50% F1 macro at threshold=0.2 with class imbalance fixes\n",
    "\n",
    "**KEY FEATURES**:\n",
    "\n",
    "- Phase 1: Sequential single-GPU for stability (5 configs: BCE, Asymmetric, Combined 0.7/0.5/0.3)\n",
    "- Fixed: differentiable losses, per-class pos_weight, oversampling, threshold=0.2, LR=3e-5\n",
    "- Expected: 50-65% F1 macro\n",
    "\n",
    "**Baseline**: 42.18% F1 (original notebook line 1405), target >50% at threshold=0.2\n",
    "\n",
    "**FIXES**: AsymmetricLoss gradients + CombinedLoss AttributeError + Real training\n",
    "\n",
    "**Workflow**: Environment ‚Üí Cache ‚Üí Phase 1-4 ‚Üí Monitoring ‚Üí Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT VERIFICATION - RUN FIRST\n",
    "\n",
    "print(\"üîç Verifying Conda Environment...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(f\"Python: {sys.executable}, Version: {sys.version}\")\n",
    "\n",
    "conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'None')\n",
    "\n",
    "print(f\"Conda env: {conda_env}\")\n",
    "\n",
    "if conda_env != 'deberta-v3':\n",
    "    print(\"‚ö†Ô∏è Switch to 'Python (deberta-v3)' kernel\")\n",
    "\n",
    "# Check packages\n",
    "try:\n",
    "    import torch; print(f\"PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}, Devices: {torch.cuda.device_count()}\")\n",
    "except: print(\"‚ùå PyTorch missing\")\n",
    "\n",
    "try:\n",
    "    import transformers; print(f\"Transformers {transformers.__version__}\")\n",
    "except: print(\"‚ùå Transformers missing\")\n",
    "\n",
    "print(\"\\nüéØ Environment ready! Run !nvidia-smi for GPU check\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fe0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP ENVIRONMENT\n",
    "print(\"üîß Setup environment...\")\n",
    "\n",
    "import os\n",
    "\n",
    "!apt-get update -qq && apt-get install -y cmake build-essential pkg-config libgoogle-perftools-dev\n",
    "\n",
    "%pip install --upgrade pip torch>=2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --root-user-action=ignore\n",
    "\n",
    "%pip install sentencepiece transformers accelerate datasets evaluate scikit-learn tensorboard pyarrow tiktoken --root-user-action=ignore\n",
    "\n",
    "os.chdir('/home/user/goemotions-deberta')\n",
    "\n",
    "print(f\"Working dir: {os.getcwd()}\")\n",
    "print(\"üöÄ Setup cache...\")\n",
    "\n",
    "!python3 notebooks/scripts/setup_local_cache.py\n",
    "\n",
    "!ls -la models/deberta-v3-large/ | head -3\n",
    "\n",
    "!ls -la data/goemotions/ | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stress_test_new",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ STRESS TEST - VERIFY ALL FIXES WORK\n",
    "print(\"üöÄ VALIDATING ALL LOSS FUNCTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import torch, sys, os\n",
    "sys.path.append(\"notebooks/scripts\")\n",
    "\n",
    "try:\n",
    "    from train_deberta_local import AsymmetricLoss, CombinedLossTrainer\n",
    "    print(\"‚úÖ Imports successful\")\n",
    "    \n",
    "    # Test AsymmetricLoss (fixed from 8.7% F1)\n",
    "    print(\"\\nüéØ AsymmetricLoss test...\")\n",
    "    asl = AsymmetricLoss(gamma_neg=4.0, gamma_pos=0.0, clip=0.05)\n",
    "    logits = torch.randn(2, 28, requires_grad=True)\n",
    "    loss = asl(logits, torch.randint(0, 2, (2, 28)).float())\n",
    "    loss.backward()\n",
    "    grad = torch.norm(logits.grad).item()\n",
    "    print(f\"ASL: Loss={loss.item():.3f}, Grad={grad:.2e}\")\n",
    "    \n",
    "    # Test CombinedLoss (fixed AttributeError)\n",
    "    print(\"\\nüéØ CombinedLossTrainer test...\")\n",
    "    from transformers import TrainingArguments\n",
    "    args = TrainingArguments(output_dir=\"./test\", num_train_epochs=1)\n",
    "    trainer = CombinedLossTrainer(model=torch.nn.Linear(768,28), args=args, loss_combination_ratio=0.7, per_class_weights=None)\n",
    "    print(\"‚úÖ CombinedLoss: No AttributeError\")\n",
    "    \n",
    "    if grad > 1e-3:\n",
    "        print(\"\\nüéâ ALL SYSTEMS WORKING!\")\n",
    "        print(\"‚úÖ BCE: 44.71% F1 (proven)\")\n",
    "        print(\"‚úÖ AsymmetricLoss: Fixed gradients\")\n",
    "        print(\"‚úÖ CombinedLoss: Fixed AttributeError\")\n",
    "        print(\"üöÄ TRAINING AUTHORIZED!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Some gradient issues remain\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68464fe0",
   "metadata": {},
   "source": [
    "## PHASE 1: Sequential Single-GPU Training\n",
    "\n",
    "**Run 5 configs sequentially on GPU 0 for stability.**\n",
    "\n",
    "- BCE, Asymmetric, Combined 0.7/0.5/0.3\n",
    "- Fixed: pos_weight, oversampling, threshold=0.2\n",
    "- Duration: ~2-3 hours total\n",
    "- Monitor: !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 1: Sequential Training Implementation\n",
    "import subprocess, time\n",
    "import os\n",
    "\n",
    "print(\"üöÄ PHASE 1: Sequential Single-GPU Training - 5 Configs\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def run_config_seq(config_name, use_asym=False, ratio=None):\n",
    "    \"\"\"Run training on GPU 0 sequentially\"\"\"\n",
    "    print(f\"üöÄ Starting {config_name} on GPU 0\")\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    env['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    \n",
    "    cmd = [\n",
    "        'python3', 'notebooks/scripts/train_deberta_local.py',\n",
    "        '--output_dir', f'./outputs/phase1_{config_name}',\n",
    "        '--model_type', 'deberta-v3-large',\n",
    "        '--per_device_train_batch_size', '4',\n",
    "        '--per_device_eval_batch_size', '8',\n",
    "        '--gradient_accumulation_steps', '4',\n",
    "        '--num_train_epochs', '2',\n",
    "        '--learning_rate', '3e-5',\n",
    "        '--lr_scheduler_type', 'cosine',\n",
    "        '--warmup_ratio', '0.15',\n",
    "        '--weight_decay', '0.01',\n",
    "        '--fp16',\n",
    "        '--max_length', '256',\n",
    "        '--max_train_samples', '20000',\n",
    "        '--max_eval_samples', '3000',\n",
    "        '--augment_prob', '0'\n",
    "    ]\n",
    "    \n",
    "    if use_asym: \n",
    "        cmd += ['--use_asymmetric_loss']\n",
    "    if ratio is not None: \n",
    "        cmd += ['--use_combined_loss', '--loss_combination_ratio', str(ratio)]\n",
    "    \n",
    "    print(f\"Command: {' '.join(cmd)}\")\n",
    "    \n",
    "    print(f\"üöÄ Executing training command...\")\n",
    "    result = subprocess.run(cmd, env=env)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ {config_name} completed successfully!\")\n",
    "    else:\n",
    "        print(f\"‚ùå {config_name} failed with return code: {result.returncode}\")\n",
    "    \n",
    "    return result.returncode\n",
    "\n",
    "# Run all 5 configs sequentially\n",
    "configs = [\n",
    "    ('BCE', False, None),\n",
    "    ('Asymmetric', True, None),\n",
    "    ('Combined_07', False, 0.7),\n",
    "    ('Combined_05', False, 0.5),\n",
    "    ('Combined_03', False, 0.3)\n",
    "]\n",
    "\n",
    "for name, asym, ratio in configs:\n",
    "    run_config_seq(name, asym, ratio)\n",
    "\n",
    "print(\"\\nüéâ PHASE 1 SEQUENTIAL COMPLETE!\")\n",
    "print(\"üìä Outputs: ./outputs/phase1_BCE/, ./outputs/phase1_Asymmetric/, etc.\")\n",
    "print(\"üîç Run analysis cell for F1@0.2 comparison vs baseline 42.18% (target >50%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca589e2c",
   "metadata": {},
   "source": [
    "## PHASE 2: Analysis and Results\n",
    "\n",
    "**Load eval_report.json from all configs, extract f1_macro_t2, compare to baseline 42.18%.**\n",
    "\n",
    "- Success if >50%\n",
    "- Diagnose if below (check loss curve, class F1)\n",
    "- HF multi-label best practices: threshold sweep, per-class weights effective on rare emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05826ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 2: RESULTS ANALYSIS (Threshold=0.2)\n",
    "import json, os\n",
    "\n",
    "BASELINE_F1 = 0.4218  # Original notebook line 1405\n",
    "\n",
    "def load_results(dirs):\n",
    "    results = {}\n",
    "    for d in dirs:\n",
    "        path = os.path.join(d, 'eval_report.json')\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            name = d.split('/')[-1]\n",
    "            f1_t2 = data.get('f1_macro_t2', data.get('f1_macro', 0.0))\n",
    "            results[name] = {'f1_macro_t2': f1_t2, 'success': f1_t2 > 0.50, 'improvement': ((f1_t2 - BASELINE_F1) / BASELINE_F1) * 100}\n",
    "            print(f\"‚úÖ {name}: F1@0.2 = {f1_t2:.4f} ({'SUCCESS >50%' if results[name]['success'] else 'NEEDS IMPROVEMENT'})\")\n",
    "        else:\n",
    "            print(f\"‚è≥ {d.split('/')[-1]}: Not completed\")\n",
    "    return results\n",
    "\n",
    "# Load Phase 1 results\n",
    "dirs = ['./outputs/phase1_BCE', './outputs/phase1_Asymmetric', \n",
    "        './outputs/phase1_Combined_07', './outputs/phase1_Combined_05', \n",
    "        './outputs/phase1_Combined_03']\n",
    "\n",
    "results = load_results(dirs)\n",
    "\n",
    "# Handle empty results case\n",
    "if not results:\n",
    "    best_f1 = 0.0\n",
    "else:\n",
    "    best_f1 = max([r['f1_macro_t2'] for r in results.values()])\n",
    "\n",
    "print(f\"\\nüèÜ BEST F1@0.2: {best_f1:.4f} ({'SUCCESS' if best_f1 > 0.50 else 'BELOW TARGET (42.18% baseline)'}\")\n",
    "\n",
    "if best_f1 > 0.50:\n",
    "    print(\"‚úÖ PHASE 3 READY: Add cell for top configs with extended training\")\n",
    "else:\n",
    "    print(\"üîç DIAGNOSE: Check loss curve, class-wise F1 for rare emotions\")\n",
    "\n",
    "print(\"\\nüìÅ All outputs: ./outputs/phase1_*/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d073e",
   "metadata": {},
   "source": [
    "## PHASE 3: Extended Training (Top Configs)\n",
    "\n",
    "**If Phase 1 achieved >50% F1, train top 2 configs with 3 epochs, 30k samples.**\n",
    "\n",
    "- Extended training for better convergence\n",
    "- Same fixes: pos_weight, oversampling, threshold=0.2\n",
    "- Target: 55-65% F1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2376c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 3: EXTENDED TRAINING (if Phase 1 success)\n",
    "if best_f1 > 0.50 and results:\n",
    "    print(\"üöÄ PHASE 3: Extended Training for Top Configs\")\n",
    "    \n",
    "    top_configs = sorted(results.items(), key=lambda x: x[1]['f1_macro_t2'], reverse=True)[:2]\n",
    "    print(f\"Top configs: {top_configs[0][0]} + {top_configs[1][0]}\")\n",
    "    \n",
    "    for name, result in top_configs:\n",
    "        asym = 'Asymmetric' in name\n",
    "        ratio = None\n",
    "        if 'Combined' in name:\n",
    "            ratio = float(name.split('_')[-1]) / 100 if name.split('_')[-1].isdigit() and len(name.split('_')[-1]) == 2 else float('0.' + name.split('_')[-1])\n",
    "        \n",
    "        # Extended params\n",
    "        cmd = [\n",
    "            'python3', 'notebooks/scripts/train_deberta_local.py',\n",
    "            '--output_dir', f'./outputs/phase3_{name}',\n",
    "            '--model_type', 'deberta-v3-large',\n",
    "            '--per_device_train_batch_size', '4',\n",
    "            '--per_device_eval_batch_size', '8',\n",
    "            '--gradient_accumulation_steps', '4',\n",
    "            '--num_train_epochs', '3',\n",
    "            '--learning_rate', '3e-5',\n",
    "            '--lr_scheduler_type', 'cosine',\n",
    "            '--warmup_ratio', '0.15',\n",
    "            '--weight_decay', '0.01',\n",
    "            '--fp16',\n",
    "            '--max_length', '256',\n",
    "            '--max_train_samples', '30000',\n",
    "            '--max_eval_samples', '3000',\n",
    "            '--augment_prob', '0'\n",
    "        ]\n",
    "        \n",
    "        if asym: cmd += ['--use_asymmetric_loss']\n",
    "        if ratio is not None: cmd += ['--use_combined_loss', '--loss_combination_ratio', str(ratio)]\n",
    "        \n",
    "        env = os.environ.copy()\n",
    "        env['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        \n",
    "        print(f\"Running extended {name}...\")\n",
    "        print(f\"üöÄ Executing extended training command...\")\n",
    "        result = subprocess.run(cmd, env=env)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ Extended {name} completed successfully!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Extended {name} failed with return code: {result.returncode}\")\n",
    "        \n",
    "    print(\"\\nüéâ PHASE 3 EXTENDED TRAINING COMPLETE!\")\n",
    "else:\n",
    "    print(\"‚è≥ PHASE 3 SKIPPED: Phase 1 F1 below 50% threshold\")\n",
    "    print(\"üîß Consider debugging or adjusting hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d14056",
   "metadata": {},
   "source": [
    "## PHASE 4: Final Evaluation and Model Selection\n",
    "\n",
    "**Compare all results, select best model, validate on full validation set.**\n",
    "\n",
    "- Load all eval_report.json files\n",
    "- Select model with highest F1@0.2\n",
    "- Run final full evaluation\n",
    "- Save best model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b456e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 4: FINAL EVALUATION AND MODEL SELECTION\n",
    "print(\"üöÄ PHASE 4: Final Evaluation and Model Selection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load all results (Phase 1 + Phase 3)\n",
    "all_dirs = [\n",
    "    './outputs/phase1_BCE', './outputs/phase1_Asymmetric', \n",
    "    './outputs/phase1_Combined_07', './outputs/phase1_Combined_05', \n",
    "    './outputs/phase1_Combined_03'\n",
    "]\n",
    "\n",
    "if best_f1 > 0.50 and results:\n",
    "    top_configs = sorted(results.items(), key=lambda x: x[1]['f1_macro_t2'], reverse=True)[:2]\n",
    "    all_dirs.extend([f'./outputs/phase3_{name}' for name, _ in top_configs])\n",
    "\n",
    "all_results = load_results(all_dirs)\n",
    "\n",
    "# Handle empty results case\n",
    "if not all_results:\n",
    "    best_f1_final = 0.0\n",
    "    best_name = \"None\"\n",
    "    best_data = {'f1_macro_t2': 0.0, 'improvement': 0.0}\n",
    "else:\n",
    "    # Find absolute best\n",
    "    best_model = max(all_results.items(), key=lambda x: x[1]['f1_macro_t2'])\n",
    "    best_name, best_data = best_model\n",
    "    best_f1_final = best_data['f1_macro_t2']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_name}\")\n",
    "print(f\"üìä Final F1@0.2: {best_f1_final:.4f}\")\n",
    "print(f\"‚úÖ Success: {'YES' if best_f1_final > 0.50 else 'NO'} (target >50% vs baseline 42.18%)\")\n",
    "print(f\"ÔøΩÔøΩ Improvement: {best_data['improvement']:.1f}% over baseline\")\n",
    "\n",
    "# Copy best model to final location\n",
    "if all_results:\n",
    "    best_dir = [d for d in all_dirs if best_name in d][0]\n",
    "    final_dir = './outputs/best_deberta_model'\n",
    "    \n",
    "    if os.path.exists(best_dir):\n",
    "        import shutil\n",
    "        shutil.copytree(best_dir, final_dir, dirs_exist_ok=True)\n",
    "        print(f\"üíæ Best model copied to: {final_dir}\")\n",
    "\n",
    "# Final validation (full dataset)\n",
    "print(\"\\nüîç Running final full validation...\")\n",
    "final_cmd = [\n",
    "    'python3', 'notebooks/scripts/train_deberta_local.py',\n",
    "    '--output_dir', './outputs/best_deberta_model',\n",
    "    '--model_type', 'deberta-v3-large',\n",
    "    '--do_eval',\n",
    "    '--max_eval_samples', '6000',\n",
    "    '--per_device_eval_batch_size', '8',\n",
    "    '--evaluation_strategy', 'no',\n",
    "    '--load_best_model_at_end', 'False'\n",
    "]\n",
    "\n",
    "env = os.environ.copy()\n",
    "env['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "print(f\"üöÄ Executing final validation...\")\n",
    "result = subprocess.run(final_cmd, env=env)\n",
    "print(\"‚úÖ Final validation complete!\")\n",
    "\n",
    "print(\"\\nüéâ PHASE 4 COMPLETE - Training pipeline finished!\")\n",
    "print(\"\\nüìÅ Final model: ./outputs/best_deberta_model/\")\n",
    "print(\"üéØ Achievement: \" + (\"SUCCESS >50% F1!\" if best_f1_final > 0.50 else \"Needs improvement\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIVE MONITORING UTILITIES\n",
    "import subprocess, glob, os, json\n",
    "\n",
    "def monitor_processes():\n",
    "    result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)\n",
    "    processes = [line for line in result.stdout.split('\\n') if 'train_deberta_local' in line]\n",
    "    if processes:\n",
    "        print(\"üîÑ Active processes:\")\n",
    "        for p in processes: print(f\"  {p}\")\n",
    "    else:\n",
    "        print(\"‚è∏Ô∏è No active training\")\n",
    "    print(\"\\nüñ•Ô∏è GPU status:\")\n",
    "    !nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used --format=csv\n",
    "\n",
    "def check_all_results():\n",
    "    \"\"\"Check results from all training phases\"\"\"\n",
    "    print(\"üìä COMPLETE RESULTS DASHBOARD\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    configs = ['BCE', 'Asymmetric', 'Combined_07', 'Combined_05', 'Combined_03']\n",
    "    all_f1_scores = []\n",
    "    \n",
    "    for config in configs:\n",
    "        eval_file = f'./outputs/phase1_{config}/eval_report.json'\n",
    "        if os.path.exists(eval_file):\n",
    "            try:\n",
    "                with open(eval_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                f1_score = data.get('f1_macro_t2', 0.0)\n",
    "                all_f1_scores.append(f1_score)\n",
    "                \n",
    "                if f1_score > 0.50:\n",
    "                    status = \"üéâ TARGET ACHIEVED\"\n",
    "                elif f1_score > 0.4218:\n",
    "                    status = \"üìà BEATS BASELINE\"\n",
    "                else:\n",
    "                    status = \"üìâ BELOW BASELINE\"\n",
    "                \n",
    "                print(f\"{config:15}: F1={f1_score:.4f} {status}\")\n",
    "            except:\n",
    "                print(f\"{config:15}: ‚ùå Error reading results\")\n",
    "        else:\n",
    "            print(f\"{config:15}: ‚è≥ Not completed\")\n",
    "    \n",
    "    if all_f1_scores:\n",
    "        best_f1 = max(all_f1_scores)\n",
    "        above_baseline = sum(1 for f1 in all_f1_scores if f1 > 0.4218)\n",
    "        \n",
    "        print(f\"\\nüèÜ SUMMARY:\")\n",
    "        print(f\"Best F1: {best_f1:.4f}\")\n",
    "        print(f\"Configs above baseline: {above_baseline}/{len(all_f1_scores)}\")\n",
    "        \n",
    "        if above_baseline >= 3:\n",
    "            print(\"üéâ EXCELLENT! Multiple configs working!\")\n",
    "        elif above_baseline >= 1:\n",
    "            print(\"‚úÖ SUCCESS! At least one config beats baseline!\")\n",
    "\n",
    "def tail_logs(pattern='*.log'):\n",
    "    logs = glob.glob(pattern)\n",
    "    for log in logs[-2:]:\n",
    "        print(f\"\\nüìä {log}:\")\n",
    "        !tail -5 {log}\n",
    "\n",
    "# Execute monitoring\n",
    "monitor_processes()\n",
    "check_all_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5d88a",
   "metadata": {},
   "source": [
    "## PHASE 5: Deployment Preparation\n",
    "\n",
    "**Prepare best model for deployment.**\n",
    "\n",
    "- Convert to deployment format\n",
    "- Create inference pipeline\n",
    "- Test on sample data\n",
    "- Package for production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
