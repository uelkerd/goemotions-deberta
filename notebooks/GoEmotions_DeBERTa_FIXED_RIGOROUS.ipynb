{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GoEmotions DeBERTa FIXED - The Configuration That ACTUALLY WORKS!\n",
        "\n",
        "## \u26a0\ufe0f STOP USING THE BROKEN CONFIG!\n",
        "\n",
        "### What's BROKEN (gives 6.7% F1):\n",
        "- **5,000 samples** \u2192 Can't learn 28 classes\n",
        "- **2e-5 learning rate** \u2192 Too low\n",
        "- **1 epoch** \u2192 Not enough\n",
        "\n",
        "### What WORKS (gives 50-65% F1):\n",
        "- **20,000 samples** \u2705\n",
        "- **3e-5 learning rate** \u2705\n",
        "- **2-3 epochs** \u2705\n",
        "- **Eval every 250 steps** \u2705"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/home/user/goemotions-deberta')\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## THE WORKING CONFIGURATION - RUN THIS!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# THIS IS THE CONFIG THAT WORKS!\n",
        "print('\ud83d\udd25 RUNNING THE FIXED CONFIGURATION')\n",
        "print('Expected F1: 50-65% (not 6.7%!)')\n",
        "print()\n",
        "\n",
        "!python3 notebooks/scripts/train_deberta_local.py \\\n",
        "  --output_dir './outputs/FIXED_RUN' \\\n",
        "  --model_type 'deberta-v3-large' \\\n",
        "  --per_device_train_batch_size 4 \\\n",
        "  --per_device_eval_batch_size 8 \\\n",
        "  --gradient_accumulation_steps 4 \\\n",
        "  --num_train_epochs 3 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --warmup_ratio 0.2 \\\n",
        "  --weight_decay 0.01 \\\n",
        "  --lr_scheduler_type cosine \\\n",
        "  --fp16 \\\n",
        "  --max_length 256 \\\n",
        "  --max_train_samples 20000 \\\n",
        "  --max_eval_samples 3000 \\\n",
        "  --evaluation_strategy steps \\\n",
        "  --eval_steps 250 \\\n",
        "  --save_strategy steps \\\n",
        "  --save_steps 250 \\\n",
        "  --logging_steps 50 \\\n",
        "  --metric_for_best_model f1_macro \\\n",
        "  --load_best_model_at_end \\\n",
        "  --save_total_limit 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For Even Better Results: Asymmetric Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asymmetric Loss - Better for extreme imbalance\n",
        "print('\u26a1 ASYMMETRIC LOSS CONFIG')\n",
        "print('Expected F1: 55-60%')\n",
        "\n",
        "!python3 notebooks/scripts/train_deberta_local.py \\\n",
        "  --output_dir './outputs/FIXED_ASL' \\\n",
        "  --model_type 'deberta-v3-large' \\\n",
        "  --per_device_train_batch_size 4 \\\n",
        "  --per_device_eval_batch_size 8 \\\n",
        "  --gradient_accumulation_steps 4 \\\n",
        "  --num_train_epochs 3 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --warmup_ratio 0.2 \\\n",
        "  --weight_decay 0.01 \\\n",
        "  --lr_scheduler_type cosine \\\n",
        "  --fp16 \\\n",
        "  --max_length 256 \\\n",
        "  --max_train_samples 20000 \\\n",
        "  --max_eval_samples 3000 \\\n",
        "  --evaluation_strategy steps \\\n",
        "  --eval_steps 250 \\\n",
        "  --save_strategy steps \\\n",
        "  --save_steps 250 \\\n",
        "  --logging_steps 50 \\\n",
        "  --metric_for_best_model f1_macro \\\n",
        "  --load_best_model_at_end \\\n",
        "  --save_total_limit 2 \\\n",
        "  --use_asymmetric_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BEST: Combined Loss (70% ASL + 30% Focal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BEST CONFIGURATION - Combined Loss\n",
        "print('\ud83c\udfc6 COMBINED LOSS - THE BEST CONFIG')\n",
        "print('Expected F1: 60-65%')\n",
        "\n",
        "!python3 notebooks/scripts/train_deberta_local.py \\\n",
        "  --output_dir './outputs/FIXED_COMBINED' \\\n",
        "  --model_type 'deberta-v3-large' \\\n",
        "  --per_device_train_batch_size 4 \\\n",
        "  --per_device_eval_batch_size 8 \\\n",
        "  --gradient_accumulation_steps 4 \\\n",
        "  --num_train_epochs 3 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --warmup_ratio 0.2 \\\n",
        "  --weight_decay 0.01 \\\n",
        "  --lr_scheduler_type cosine \\\n",
        "  --fp16 \\\n",
        "  --max_length 256 \\\n",
        "  --max_train_samples 20000 \\\n",
        "  --max_eval_samples 3000 \\\n",
        "  --evaluation_strategy steps \\\n",
        "  --eval_steps 250 \\\n",
        "  --save_strategy steps \\\n",
        "  --save_steps 250 \\\n",
        "  --logging_steps 50 \\\n",
        "  --metric_for_best_model f1_macro \\\n",
        "  --load_best_model_at_end \\\n",
        "  --save_total_limit 2 \\\n",
        "  --use_combined_loss \\\n",
        "  --loss_combination_ratio 0.7"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}