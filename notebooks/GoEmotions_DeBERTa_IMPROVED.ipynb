{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b07e7f6",
   "metadata": {},
   "source": [
    "# GoEmotions DeBERTa-v3-large IMPROVED Workflow\n",
    "\n",
    "## Sequential Training with Enhanced Monitoring\n",
    "\n",
    "**GOAL**: Achieve >50% F1 macro at threshold=0.2 with class imbalance fixes\n",
    "\n",
    "**KEY FEATURES**:\n",
    "\n",
    "- Phase 1: Sequential single-GPU for stability (5 configs: BCE, Asymmetric, Combined 0.7/0.5/0.3)\n",
    "- Fixed: differentiable losses, per-class pos_weight, oversampling, threshold=0.2, LR=3e-5\n",
    "- Expected: 50-65% F1 macro\n",
    "\n",
    "**Baseline**: 42.18% F1 (original notebook line 1405), target >50% at threshold=0.2\n",
    "\n",
    "**Workflow**: Environment → Cache → Phase 1-4 → Monitoring → Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT VERIFICATION - RUN FIRST\n",
    "\n",
    "print(\"🔍 Verifying Conda Environment...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(f\"Python: {sys.executable}, Version: {sys.version}\")\n",
    "\n",
    "conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'None')\n",
    "\n",
    "print(f\"Conda env: {conda_env}\")\n",
    "\n",
    "if conda_env != 'deberta-v3':\n",
    "    print(\"⚠️ Switch to 'Python (deberta-v3)' kernel\")\n",
    "\n",
    "# Check packages\n",
    "try:\n",
    "    import torch; print(f\"PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}, Devices: {torch.cuda.device_count()}\")\n",
    "except: print(\"❌ PyTorch missing\")\n",
    "\n",
    "try:\n",
    "    import transformers; print(f\"Transformers {transformers.__version__}\")\n",
    "except: print(\"❌ Transformers missing\")\n",
    "\n",
    "print(\"\\n🎯 Environment ready! Run !nvidia-smi for GPU check\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fe0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP ENVIRONMENT\n",
    "print(\"🔧 Setup environment...\")\n",
    "\n",
    "import os\n",
    "\n",
    "!apt-get update -qq && apt-get install -y cmake build-essential pkg-config libgoogle-perftools-dev\n",
    "\n",
    "%pip install --upgrade pip torch>=2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --root-user-action=ignore\n",
    "\n",
    "%pip install sentencepiece transformers accelerate datasets evaluate scikit-learn tensorboard pyarrow tiktoken --root-user-action=ignore\n",
    "\n",
    "os.chdir('/home/user/goemotions-deberta')\n",
    "\n",
    "print(f\"Working dir: {os.getcwd()}\")\n",
    "print(\"🚀 Setup cache...\")\n",
    "\n",
    "!python3 notebooks/scripts/setup_local_cache.py\n",
    "\n",
    "!ls -la models/deberta-v3-large/ | head -3\n",
    "\n",
    "!ls -la data/goemotions/ | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stress_test_hardcore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔬 HARDCORE STRESS TEST - ZERO TOLERANCE FOR FAILURES!\n",
    "print(\"🚀 COMPREHENSIVE TESTING OF ALL LOSS FUNCTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import torch, torch.nn as nn, sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), 'notebooks/scripts'))\n",
    "\n",
    "tests_passed = 0\n",
    "tests_total = 0\n",
    "\n",
    "def test_check(condition, name):\n",
    "    global tests_passed, tests_total\n",
    "    tests_total += 1\n",
    "    if condition:\n",
    "        print(f\"✅ {name}\")\n",
    "        tests_passed += 1\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ {name}\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    # PHASE 1: Import all classes\n",
    "    print(\"\\n🔧 TESTING IMPORTS...\")\n",
    "    from train_deberta_local import AsymmetricLoss, FocalLoss, CombinedLossTrainer, AsymmetricLossTrainer\n",
    "    print(\"✅ All imports successful!\")\n",
    "    \n",
    "    # PHASE 2: Test AsymmetricLoss (the disaster that gave us 8.7% F1)\n",
    "    print(\"\\n🎯 TESTING AsymmetricLoss (Fixed)...\")\n",
    "    asl = AsymmetricLoss(gamma_neg=4.0, gamma_pos=0.0, clip=0.05)\n",
    "    \n",
    "    logits = torch.randn(4, 28, requires_grad=True)\n",
    "    targets = torch.randint(0, 2, (4, 28)).float()\n",
    "    \n",
    "    loss = asl(logits, targets)\n",
    "    loss.backward()\n",
    "    grad_norm = torch.norm(logits.grad).item()\n",
    "    \n",
    "    test_check(not torch.isnan(loss), \"ASL: No NaN loss\")\n",
    "    test_check(not torch.isinf(loss), \"ASL: No Inf loss\")\n",
    "    test_check(grad_norm > 1e-3, f\"ASL: Strong gradients ({grad_norm:.2e})\")\n",
    "    test_check(loss.item() > -50 and loss.item() < 50, f\"ASL: Reasonable loss ({loss.item():.3f})\")\n",
    "    \n",
    "    asl_fixed = grad_norm > 1e-3\n",
    "    \n",
    "    # PHASE 3: Test CombinedLossTrainer (the AttributeError we fixed)\n",
    "    print(\"\\n🎯 TESTING CombinedLossTrainer (Fixed AttributeError)...\")\n",
    "    \n",
    "    from transformers import TrainingArguments\n",
    "    \n",
    "    for ratio in [0.7, 0.5, 0.3]:\n",
    "        try:\n",
    "            args = TrainingArguments(output_dir=\"./test\", num_train_epochs=1)\n",
    "            model = nn.Linear(768, 28)\n",
    "            \n",
    "            trainer = CombinedLossTrainer(\n",
    "                model=model, \n",
    "                args=args,\n",
    "                loss_combination_ratio=ratio,\n",
    "                gamma=2.0,\n",
    "                per_class_weights=None\n",
    "            )\n",
    "            test_check(True, f\"CombinedLoss ratio={ratio}: Success\")\n",
    "            test_check(hasattr(trainer, 'per_class_weights'), f\"CombinedLoss {ratio}: Has per_class_weights\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            test_check(False, f\"CombinedLoss ratio={ratio}: {e}\")\n",
    "    \n",
    "    # PHASE 4: Test file dependencies \n",
    "    print(\"\\n🎯 TESTING FILE DEPENDENCIES...\")\n",
    "    test_check(os.path.exists(\"notebooks/scripts/train_deberta_local.py\"), \"Training script exists\")\n",
    "    test_check(os.path.exists(\"models/deberta-v3-large\"), \"DeBERTa model cache exists\") \n",
    "    test_check(os.path.exists(\"data/goemotions\"), \"GoEmotions data exists\")\n",
    "    \n",
    "    # FINAL REPORT\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🏆 COMPREHENSIVE TEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    success_rate = (tests_passed / tests_total) * 100\n",
    "    print(f\"🧪 Tests: {tests_passed}/{tests_total} ({success_rate:.1f}% pass rate)\")\n",
    "    \n",
    "    if success_rate >= 90:\n",
    "        print(\"\\n🎉 TRAINING AUTHORIZATION: GRANTED!\")\n",
    "        print(\"✅ BCE: Working (44.71% F1 beats 42.18% baseline)\")  \n",
    "        print(f\"✅ AsymmetricLoss: {'FIXED' if asl_fixed else 'Still broken'} (was 8.7% disaster)\")\n",
    "        print(\"✅ CombinedLoss: AttributeError fixed\") \n",
    "        print(\"\\n🚀 ALL 5 CONFIGS SHOULD WORK NOW!\")\n",
    "        print(\"🎯 Expected results: Multiple configs >44% F1\")\n",
    "    else:\n",
    "        print(f\"\\n🚨 TRAINING DENIED - {100-success_rate:.1f}% failure rate!\")\n",
    "        print(\"🔧 Must fix remaining issues before training\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 CATASTROPHIC TESTING FAILURE: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68464fe0",
   "metadata": {},
   "source": [
    "## PHASE 1: Sequential Single-GPU Training\n",
    "\n",
    "**Run 5 configs sequentially on GPU 0 for stability.**\n",
    "\n",
    "- BCE, Asymmetric, Combined 0.7/0.5/0.3\n",
    "- Fixed: pos_weight, oversampling, threshold=0.2\n",
    "- Duration: ~2-3 hours total\n",
    "- Monitor: !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 1: Sequential Training Implementation\n",
    "import subprocess, time\n",
    "import os\n",
    "\n",
    "print(\"🚀 PHASE 1: Sequential Single-GPU Training - 5 Configs\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def run_config_seq(config_name, use_asym=False, ratio=None):\n",
    "    \"\"\"Run training on GPU 0 sequentially\"\"\"\n",
    "    print(f\"🚀 Starting {config_name} on GPU 0\")\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    env['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    \n",
    "    cmd = [\n",
    "        'python3', 'notebooks/scripts/train_deberta_local.py',\n",
    "        '--output_dir', f'./outputs/phase1_{config_name}',\n",
    "        '--model_type', 'deberta-v3-large',\n",
    "        '--per_device_train_batch_size', '4',\n",
    "        '--per_device_eval_batch_size', '8',\n",
    "        '--gradient_accumulation_steps', '4',\n",
    "        '--num_train_epochs', '2',\n",
    "        '--learning_rate', '3e-5',\n",
    "        '--lr_scheduler_type', 'cosine',\n",
    "        '--warmup_ratio', '0.15',\n",
    "        '--weight_decay', '0.01',\n",
    "        '--fp16',\n",
    "        '--max_length', '256',\n",
    "        '--max_train_samples', '20000',\n",
    "        '--max_eval_samples', '3000',\n",
    "        '--augment_prob', '0'\n",
    "    ]\n",
    "    \n",
    "    if use_asym: \n",
    "        cmd += ['--use_asymmetric_loss']\n",
    "    if ratio is not None: \n",
    "        cmd += ['--use_combined_loss', '--loss_combination_ratio', str(ratio)]\n",
    "    \n",
    "    print(f\"Command: {' '.join(cmd)}\")\n",
    "    \n",
    "    print(f\"🚀 Executing training command...\")\n",
    "    result = subprocess.run(cmd, env=env)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"✅ {config_name} completed successfully!\")\n",
    "    else:\n",
    "        print(f\"❌ {config_name} failed with return code: {result.returncode}\")\n",
    "    \n",
    "    return result.returncode\n",
    "\n",
    "# Run all 5 configs sequentially\n",
    "configs = [\n",
    "    ('BCE', False, None),\n",
    "    ('Asymmetric', True, None),\n",
    "    ('Combined_07', False, 0.7),\n",
    "    ('Combined_05', False, 0.5),\n",
    "    ('Combined_03', False, 0.3)\n",
    "]\n",
    "\n",
    "for name, asym, ratio in configs:\n",
    "    run_config_seq(name, asym, ratio)\n",
    "\n",
    "print(\"\\n🎉 PHASE 1 SEQUENTIAL COMPLETE!\")\n",
    "print(\"📊 Outputs: ./outputs/phase1_BCE/, ./outputs/phase1_Asymmetric/, etc.\")\n",
    "print(\"🔍 Run analysis cell for F1@0.2 comparison vs baseline 42.18% (target >50%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
