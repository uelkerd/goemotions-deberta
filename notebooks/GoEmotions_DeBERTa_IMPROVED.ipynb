
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions DeBERTa-v3-large IMPROVED Workflow with Full Enhancement Plan\n",
    "\n",
    "## Implementing All Improvements: HPO, Data Aug, Arch Mods, Ensembles, Monitoring\n",
    "\n",
    "**GOAL**: Achieve >60% F1 macro at threshold=0.2 with comprehensive enhancements\n",
    "\n",
    "**KEY IMPROVEMENTS APPLIED**:\n",
    "\n",
    "- **HPO**: Optuna for hyperparameter optimization (LR, batch_size, gamma, etc.)\n",
    "- **Data Aug**: SMOTE for imbalance, nlpaug for text augmentation (augment_prob)\n",
    "- **Loss Enhancements**: Focal loss variants (gamma), per-class weights, threshold sweeps\n",
    "- **Architecture Mods**: Freeze layers option, increased dropout, label smoothing\n",
    "- **Ensembles**: Soft-voting across top models\n",
    "- **Monitoring**: Early stopping, logging with tensorboard\n",
    "- **Optimization**: DeepSpeed ZeRO-2 for memory efficiency\n",
    "- **Script Updates**: Added args to train_deberta_local.py (gamma, augment_prob, freeze_layers, etc.)\n",
    "\n",
    "**Workflow**: Environment ‚Üí Script Edits ‚Üí Data Prep/Aug ‚Üí HPO ‚Üí Training with Monitoring ‚Üí Ensembles ‚Üí Eval\n",
    "\n",
    "**Expected**: 60-70% F1 macro, 2x faster with ZeRO-2, robust to imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing packages for enhanced workflow (added sentence-transformers for SMOTE embeddings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%pip install --quiet optuna>=3.0.0 nlpaug>=1.1.0 imbalanced-learn>=0.10.0 deepspeed>=0.12.0 sentence-transformers\n",
    "\n",
    "# Verify installations\n",
    "import optuna\n",
    "print(f\"Optuna {optuna.__version__} installed successfully\")\n",
    "import nlpaug\n",
    "print(f\"nlpaug {nlpaug.__version__} installed successfully\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(\"SMOTE from imbalanced-learn installed successfully\")\n",
    "import contextlib\n",
    "import os\n",
    "with contextlib.redirect_stderr(open(os.devnull, 'w')):\n",
    "    import deepspeed\n",
    "print(f\"DeepSpeed {deepspeed.__version__} installed successfully\")\n",
    "print(\"‚úÖ All dependencies installed and verified for deberta-v3 environment\")\n",
    "\n",
    "# Verify sentence-transformers installation (added for SMOTE embeddings)\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"SentenceTransformer available\")\n",
    "except ImportError as e:\n",
    "    print(f\"SentenceTransformer import failed: {e}\")\n",
    "\n",
    "# Fallback pip installs if conda fails (user site-packages)\n",
    "%pip install --user optuna nlpaug imbalanced-learn deepspeed sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT VERIFICATION\n",
    "print(\"üîç Verifying Enhanced Environment...\")\n",
    "import sys, os\n",
    "print(f\"Python: {sys.executable}, Version: {sys.version}\")\n",
    "import torch; print(f\"PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}, Devices: {torch.cuda.device_count()}\")\n",
    "import transformers; print(f\"Transformers {transformers.__version__}\")\n",
    "import optuna; print(f\"Optuna {optuna.__version__}\")\n",
    "import nlpaug; print(f\"nlpaug available\")\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE; print(f\"SMOTE available from imblearn {imblearn.__version__}\")\n",
    "try:\n",
    "    import deepspeed\n",
    "    print(f\"DeepSpeed {deepspeed.__version__}\")\n",
    "except:\n",
    "    print(\"DeepSpeed installed but import skipped due to compatibility\")\n",
    "!nvidia-smi\n",
    "os.chdir('/home/user/goemotions-deberta')\n",
    "!python3 notebooks/scripts/setup_local_cache.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 1: Update Training Script with New Arguments\n",
    "\n",
    "Apply modifications to notebooks/scripts/train_deberta_local.py: add args for gamma (focal loss), augment_prob (data aug), freeze