{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Sep  3 11:24:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:C1:00.0 Off |                  N/A |\n",
            "| 30%   26C    P8             38W /  350W |       2MiB /  24576MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   1  NVIDIA GeForce RTX 3090        On  |   00000000:C2:00.0 Off |                  N/A |\n",
            "| 30%   26C    P8             40W /  350W |       2MiB /  24576MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Cannot install accelerate==0.24.0, datasets==2.20.0, datasets==2.21.0, datasets==3.0.0, datasets==3.0.1, datasets==3.0.2, datasets==3.1.0, datasets==3.2.0, datasets==3.3.0, datasets==3.3.1, datasets==3.3.2, datasets==3.4.0, datasets==3.4.1, datasets==3.5.0, datasets==3.5.1, datasets==3.6.0, datasets==4.0.0, transformers and transformers==4.35.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0müìÅ Current directory: /home/user/goemotions-deberta\n",
            "üöÄ Setting up local cache...\n",
            "/bin/bash: line 1: python: command not found\n"
          ]
        }
      ],
      "source": [
        "# GoEmotions DeBERTa-v3-large Multi-Label Classification\n",
        "# Using local caching for fast, offline training\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "# Install packages with conflict resolution\n",
        "!pip install --upgrade pip --root-user-action=ignore\n",
        "!pip install torch==2.3.1+cu118 torchvision==0.18.1+cu118 torchaudio==2.3.1+cu118 --index-url https://download.pytorch.org/whl/cu118 --root-user-action=ignore\n",
        "!pip install transformers accelerate datasets evaluate scikit-learn tensorboard pyarrow tiktoken --root-user-action=ignore\n",
        "\n",
        "# Change to the project root directory\n",
        "import os\n",
        "os.chdir('/home/user/goemotions-deberta')\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Setup local caching (run this first time only)\n",
        "print(\"üöÄ Setting up local cache...\")\n",
        "!python3 scripts/setup_local_cache.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: can't open file '/home/user/goemotions-deberta/scripts/train_deberta_local.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/home/user/goemotions-deberta/scripts/train_deberta_local.py': [Errno 2] No such file or directory\n",
            "E0903 11:24:58.677000 140358872911872 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 2) local_rank: 0 (pid: 141103) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 7, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1226, in launch_command\n",
            "    multi_gpu_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 853, in multi_gpu_launcher\n",
            "    distrib_run.run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 870, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 263, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "scripts/train_deberta_local.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "[1]:\n",
            "  time      : 2025-09-03_11:24:58\n",
            "  host      : 2fd62b2353f7\n",
            "  rank      : 1 (local_rank: 1)\n",
            "  exitcode  : 2 (pid: 141104)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2025-09-03_11:24:58\n",
            "  host      : 2fd62b2353f7\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 2 (pid: 141103)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Training with DeBERTa-v3-large using local cache\n",
        "!accelerate launch --num_processes=2 --mixed_precision=fp16 \\\n",
        "scripts/train_deberta_local.py \\\n",
        "--output_dir \"./outputs/deberta\" \\\n",
        "--model_type \"deberta-v3-large\" \\\n",
        "--per_device_train_batch_size 8 --per_device_eval_batch_size 16 \\\n",
        "--gradient_accumulation_steps 4 \\\n",
        "--num_train_epochs 3 \\\n",
        "--learning_rate 1e-5 --lr_scheduler_type cosine --warmup_ratio 0.1 \\\n",
        "--weight_decay 0.01 --fp16 --tf32 --gradient_checkpointing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Current directory: /home/user/goemotions-deberta\n",
            "‚ùå DeBERTa training not completed yet\n"
          ]
        }
      ],
      "source": [
        "# Check results\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Ensure we're in the right directory\n",
        "os.chdir('/home/user/goemotions-deberta')\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Check DeBERTa results\n",
        "deberta_report = \"./outputs/deberta/eval_report.json\"\n",
        "if os.path.exists(deberta_report):\n",
        "    print(\"üéâ DeBERTa-v3-large training completed!\")\n",
        "    with open(deberta_report, \"r\") as f:\n",
        "        rep = json.load(f)\n",
        "    print(\"Model:\", rep[\"model\"])\n",
        "    print(\"F1_micro:\", rep[\"f1_micro\"], \" F1_macro:\", rep[\"f1_macro\"])\n",
        "    print(\"F1_micro (t=0.3):\", rep.get(\"f1_micro_t3\", \"N/A\"), \" F1_macro (t=0.3):\", rep.get(\"f1_macro_t3\", \"N/A\"))\n",
        "    print(\"F1_micro (t=0.5):\", rep.get(\"f1_micro_t5\", \"N/A\"), \" F1_macro (t=0.5):\", rep.get(\"f1_macro_t5\", \"N/A\"))\n",
        "else:\n",
        "    print(\"‚ùå DeBERTa training not completed yet\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python3 (System)",
      "language": "python",
      "name": "system-python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
