{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccee1535-112b-4dcb-9736-13537c2b9554",
   "metadata": {},
   "source": [
    "=====================================\n",
    "SAMO GoEmotions - DeBERTa-v3-large \n",
    "====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802023ab-5e38-415a-9857-831c470a1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_mistralai\n",
    "import langchain_openai\n",
    "import langchain_aws\n",
    "import langchain_cohere\n",
    "import langchain_google_vertexai\n",
    "import langchain_ollama\n",
    "print(\"All required langchain integrations imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53daffce-352e-44ca-a1dd-788a0cdae260",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Vast.ai 2x3090 bootstrap: force 1 GPU + fast caches (fixed) ---\n",
    "import os\n",
    "\n",
    "# Hide the 2nd GPU before touching torch/cuda\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Keep HF/Datasets caches on fast NVMe (Vast) or fall back if not present\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/.cache/huggingface\" if os.path.isdir(\"/workspace\") else \"/kaggle/working/hf\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.environ[\"HF_HOME\"]\n",
    "os.environ[\"DATASETS_CACHE\"] = os.environ[\"HF_HOME\"]\n",
    "\n",
    "# CUDA allocator options (colon syntax). Keep broadly compatible.\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Visible GPUs:\", torch.cuda.device_count())\n",
    "    print(\"GPU 0:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No CUDA device visible ‚Äî check the Vast template/image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a0d90-366d-4692-8743-f2b51677468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 1. ENVIRONMENT SETUP WITH GPU MEMORY MANAGEMENT (Vast/Kaggle SAFE)\n",
    "# ===================================================================================\n",
    "import os, sys, subprocess, warnings, gc, json, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"üöÄ [1/8] Setting up the environment...\")\n",
    "\n",
    "# -------- Paths & caches (Vast first, Kaggle fallback) --------\n",
    "cache_root = \"/workspace/.cache/huggingface\" if os.path.isdir(\"/workspace\") else \"/kaggle/working/hf\"\n",
    "os.makedirs(cache_root, exist_ok=True)\n",
    "os.environ[\"HF_HOME\"] = cache_root\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = cache_root\n",
    "os.environ[\"DATASETS_CACHE\"] = cache_root\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# CUDA allocator: use correct colon syntax; keep it simple & compatible\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "# -------- GPU memory hygiene --------\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        # Not all drivers support this; ignore if it errors\n",
    "        torch.cuda.set_per_process_memory_fraction(0.95)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-input\"] + pkgs)\n",
    "\n",
    "# -------- Core libs (do NOT reinstall torch unless we must) --------\n",
    "try:\n",
    "    pip_install([\n",
    "        \"transformers==4.41.2\",\n",
    "        \"datasets==2.19.0\",\n",
    "        \"accelerate==0.31.0\",\n",
    "        \"peft==0.10.0\",\n",
    "        \"evaluate==0.4.2\",\n",
    "        \"scikit-learn==1.5.0\",\n",
    "        \"pandas>=2.0.0\",\n",
    "        \"sentencepiece>=0.1.99\",\n",
    "    ])\n",
    "    print(\"   ‚úÖ Dependencies installed.\")\n",
    "except Exception as e:\n",
    "    print(\"   ‚ùå Dependency install error:\", e)\n",
    "    raise\n",
    "\n",
    "# Optional: if Torch is CPU-only, install a CUDA wheel automatically\n",
    "def ensure_cuda_torch():\n",
    "    import importlib\n",
    "    needs_cuda = (not torch.cuda.is_available()) or (\"+cpu\" in torch.__version__)\n",
    "    if not needs_cuda:\n",
    "        return\n",
    "    print(\"   ‚ö†Ô∏è Detected CPU-only PyTorch; installing CUDA build...\")\n",
    "    for cu_tag in (\"cu121\", \"cu118\"):  # try CUDA 12.1, then 11.8\n",
    "        try:\n",
    "            pip_install([\n",
    "                f\"--index-url=https://download.pytorch.org/whl/{cu_tag}\",\n",
    "                \"torch\", \"torchvision\", \"torchaudio\",\n",
    "            ])\n",
    "            importlib.reload(torch)\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"   ‚úÖ Installed CUDA PyTorch ({cu_tag}).\")\n",
    "                return\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(\"   ‚ö†Ô∏è Still no CUDA-enabled torch. Check base image / drivers.\")\n",
    "\n",
    "ensure_cuda_torch()\n",
    "\n",
    "# -------- Print versions & GPU info --------\n",
    "import transformers, datasets, accelerate, peft, pandas as pd  # noqa: E402\n",
    "\n",
    "print(\"\\n--- Library Versions ---\")\n",
    "print(f\"   - Transformers: {transformers.__version__}, Datasets: {datasets.__version__}\")\n",
    "print(f\"   - Accelerate:   {accelerate.__version__}, PEFT: {peft.__version__}\")\n",
    "print(f\"   - PyTorch:      {torch.__version__}\")\n",
    "print(\"------------------------\")\n",
    "print(f\"   - CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(f\"   - GPU Device:     {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   - GPU Memory:     {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"-\" * 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e0229-979c-408b-8acd-e80ec29c61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAFE CONFIG DEFAULTS + REPRO SEED (Vast 3090 tuned) ---\n",
    "import os, random, numpy as np, torch\n",
    "\n",
    "# Reset CONFIG to these defaults (avoid stale values overriding)\n",
    "DEFAULTS = {\n",
    "    \"seed\": 42,\n",
    "    \"output_dir\": \"/workspace/out/fast_vast3090\" if os.path.isdir(\"/workspace\") else \"./out/fast_vast3090\",\n",
    "\n",
    "    # DATA\n",
    "    \"dataset_config\": \"raw\",\n",
    "    \"use_subset\": True,\n",
    "    \"subset_ratio\": 0.60,\n",
    "\n",
    "    # PRECISION / MEMORY\n",
    "    \"bf16\": False,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_checkpointing\": False,\n",
    "\n",
    "    # MODEL / LORA\n",
    "    \"model_name_or_path\": \"microsoft/deberta-v3-large\",\n",
    "    \"use_lora\": True,\n",
    "    \"lora_r\": 32,\n",
    "    \"lora_alpha\": 64,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"lora_target_modules\": [\"query_proj\",\"key_proj\",\"value_proj\"],\n",
    "\n",
    "    # TRAINING CORE\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"per_device_train_batch_size\": 20,   # 24GB-friendly at max_length 96\n",
    "    \"per_device_eval_batch_size\": 64,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"max_length\": 96,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_ratio\": 0.02,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "\n",
    "    # DATALOADER\n",
    "    \"dataloader_num_workers\": 0,\n",
    "\n",
    "    # LOGGING/CHECKPOINTS\n",
    "    \"logging_steps\": 200,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"save_total_limit\": 1,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"f1_macro\",\n",
    "    \"greater_is_better\": True,\n",
    "\n",
    "    # ASL (tuned)\n",
    "    \"asl_gamma_neg\": 3.0,\n",
    "    \"asl_gamma_pos\": 1.0,\n",
    "    \"asl_clip\": 0.05,\n",
    "    \"asl_pos_alpha\": 2.0,\n",
    "\n",
    "    # MISC\n",
    "    \"fp16_full_eval\": True,\n",
    "    \"report_to\": \"none\",\n",
    "}\n",
    "CONFIG = DEFAULTS.copy()\n",
    "\n",
    "def set_seed_all(seed: int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed_all(CONFIG[\"seed\"])\n",
    "print(\"‚úÖ Config ok. Seed:\", CONFIG[\"seed\"])\n",
    "print(\"   Output dir:\", CONFIG[\"output_dir\"])\n",
    "print(\"   fp16:\", CONFIG[\"fp16\"], \"| grad ckpt:\", CONFIG[\"gradient_checkpointing\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdbf16-6678-40bf-9bf8-96e78638f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.5 Tokenizer prerequisites (must run before Cell 3) ---\n",
    "import sys, subprocess, importlib\n",
    "\n",
    "def _pip_install(pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-input\"] + pkgs)\n",
    "\n",
    "# Install/upgrade sentencepiece and tokenizers\n",
    "_pip_install([\"sentencepiece>=0.1.99\", \"tokenizers>=0.15.2\"])\n",
    "\n",
    "import sentencepiece, tokenizers\n",
    "print(\"sentencepiece:\", sentencepiece.__version__, \"| tokenizers:\", tokenizers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea0726-b229-4697-a293-1c76ffedbad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 3. DATA LOADING WITH SMART SAMPLING FOR SPEED  (ROBUST: raw vs simplified)\n",
    "# ===================================================================================\n",
    "print(\"\\nüíæ [3/8] Loading and preparing GoEmotions dataset...\")\n",
    "\n",
    "import gc, sys, subprocess, importlib, importlib.util\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, disable_progress_bar, Sequence, Value\n",
    "\n",
    "disable_progress_bar()\n",
    "\n",
    "# --------- GPU cache hygiene ---------\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# --------- Helper: ensure sentencepiece + hard refresh transformers ---------\n",
    "def ensure_sp_and_refresh_tf():\n",
    "    # 1) Install sentencepiece if missing\n",
    "    if importlib.util.find_spec(\"sentencepiece\") is None:\n",
    "        print(\"   - Installing sentencepiece (required for DeBERTa-v3 SPM)...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-input\", \"sentencepiece>=0.1.99\"])\n",
    "    import sentencepiece  # noqa: F401\n",
    "    # 2) Hard refresh transformers so optional backend checks re-run with SP present\n",
    "    to_drop = [m for m in list(sys.modules) if m == \"transformers\" or m.startswith(\"transformers.\")]\n",
    "    for m in to_drop:\n",
    "        sys.modules.pop(m, None)\n",
    "    import transformers as tf  # fresh import\n",
    "    return tf\n",
    "\n",
    "transformers = ensure_sp_and_refresh_tf()\n",
    "\n",
    "# --------- Load dataset (raw vs simplified) ---------\n",
    "CFG_NAME = CONFIG.get(\"dataset_config\", \"raw\")   # \"raw\" ‚Üí per-emotion 0/1 columns, \"simplified\" ‚Üí list[int]\n",
    "ds_raw = load_dataset(\"go_emotions\", CFG_NAME)\n",
    "\n",
    "print(\"   - Creating 90/10 train/validation split...\")\n",
    "train_validation_split = ds_raw[\"train\"].train_test_split(test_size=0.1, seed=CONFIG[\"seed\"])\n",
    "ds = DatasetDict({\n",
    "    \"train\": train_validation_split[\"train\"],\n",
    "    \"validation\": train_validation_split[\"test\"],\n",
    "})\n",
    "\n",
    "# --------- Optional subsampling ---------\n",
    "if CONFIG.get(\"use_subset\", False):\n",
    "    subset_ratio = float(CONFIG.get(\"subset_ratio\", 0.3))\n",
    "    original_train_size = len(ds[\"train\"])\n",
    "    original_val_size   = len(ds[\"validation\"])\n",
    "    train_subset_size = max(1, int(original_train_size * subset_ratio))\n",
    "    val_subset_size   = max(1, int(original_val_size * subset_ratio))\n",
    "    ds[\"train\"] = ds[\"train\"].shuffle(seed=CONFIG[\"seed\"]).select(range(train_subset_size))\n",
    "    ds[\"validation\"] = ds[\"validation\"].shuffle(seed=CONFIG[\"seed\"]).select(range(val_subset_size))\n",
    "    print(f\"   - Using {subset_ratio*100:.0f}% subset for faster training:\")\n",
    "    print(f\"     ‚Ä¢ Train: {original_train_size:,} ‚Üí {len(ds['train']):,} samples\")\n",
    "    print(f\"     ‚Ä¢ Valid: {original_val_size:,} ‚Üí {len(ds['validation']):,} samples\")\n",
    "else:\n",
    "    print(f\"   - Full dataset: {len(ds['train']):,} train, {len(ds['validation']):,} validation samples.\")\n",
    "\n",
    "# --------- Detect label schema & build label list ---------\n",
    "features = ds_raw[\"train\"].features\n",
    "EXPECTED = [\n",
    "    'admiration','amusement','anger','annoyance','approval','caring','confusion','curiosity','desire',\n",
    "    'disappointment','disapproval','disgust','embarrassment','excitement','fear','gratitude','grief','joy',\n",
    "    'love','nervousness','optimism','pride','realization','relief','remorse','sadness','surprise','neutral'\n",
    "]\n",
    "\n",
    "if \"labels\" in features:  # simplified schema\n",
    "    LABEL_NAMES = list(features[\"labels\"].feature.names)\n",
    "    SCHEMA = \"simplified\"\n",
    "else:                     # raw schema: per-emotion columns\n",
    "    LABEL_NAMES = [name for name in EXPECTED if name in features]\n",
    "    SCHEMA = \"raw\"\n",
    "\n",
    "ID2LABEL = {i: n for i, n in enumerate(LABEL_NAMES)}\n",
    "LABEL2ID = {n: i for i, n in enumerate(LABEL_NAMES)}\n",
    "NUM_LABELS = len(LABEL_NAMES)\n",
    "print(f\"   - Detected schema: {SCHEMA}. Using {NUM_LABELS} emotion labels.\")\n",
    "\n",
    "# --------- Tokenizer (reliable slow path; SP ensured; TF reloaded) ---------\n",
    "from transformers import DebertaV2Tokenizer\n",
    "tok_name = (CONFIG.get(\"model_name\") or\n",
    "            CONFIG.get(\"model_name_or_path\") or\n",
    "            \"microsoft/deberta-v3-large\")\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(tok_name, use_fast=False)\n",
    "print(\"   - Using slow DebertaV2Tokenizer (SentencePiece).\")\n",
    "\n",
    "# --------- Preprocess functions ---------\n",
    "def preprocess_simplified(examples):\n",
    "    enc = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=int(CONFIG.get(\"max_length\", 128)),\n",
    "        padding=False,\n",
    "    )\n",
    "    # list[list[int]] -> multi-hot\n",
    "    batch_size = len(examples[\"text\"])\n",
    "    multi_hot = np.zeros((batch_size, NUM_LABELS), dtype=np.float32)\n",
    "    for i, label_ids in enumerate(examples[\"labels\"]):\n",
    "        for lid in label_ids:\n",
    "            if 0 <= lid < NUM_LABELS:\n",
    "                multi_hot[i, lid] = 1.0\n",
    "    enc[\"labels\"] = multi_hot.tolist()\n",
    "    return enc\n",
    "\n",
    "def preprocess_raw(examples):\n",
    "    enc = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=int(CONFIG.get(\"max_length\", 128)),\n",
    "        padding=False,\n",
    "    )\n",
    "    cols = [np.asarray(examples[name], dtype=np.float32) for name in LABEL_NAMES]\n",
    "    multi_hot = np.stack(cols, axis=1)  # [B, NUM_LABELS]\n",
    "    enc[\"labels\"] = multi_hot.tolist()\n",
    "    return enc\n",
    "\n",
    "preprocess_fn = preprocess_simplified if SCHEMA == \"simplified\" else preprocess_raw\n",
    "\n",
    "# --------- Map & format (NumPy 2.0 safe) ---------\n",
    "print(\"   - Tokenizing and encoding dataset...\")\n",
    "# Remove ALL original columns; keep only what preprocess returns\n",
    "all_cols = ds[\"train\"].column_names\n",
    "encoded_ds = ds.map(preprocess_fn, batched=True, remove_columns=all_cols)\n",
    "\n",
    "# Safety: if anything extra survived, drop it\n",
    "needed = {\"input_ids\", \"attention_mask\", \"labels\"}\n",
    "extra  = [c for c in encoded_ds[\"train\"].column_names if c not in needed]\n",
    "if extra:\n",
    "    encoded_ds = encoded_ds.remove_columns(extra)\n",
    "\n",
    "# Fix labels to fixed-width list so metrics ops stay clean\n",
    "encoded_ds = encoded_ds.cast_column(\"labels\", Sequence(Value(\"float32\"), length=NUM_LABELS))\n",
    "\n",
    "# üö´ Do NOT use torch formatter (NumPy 2.0 + ragged lists => object arrays)\n",
    "# Keep python format and let DataCollatorWithPadding tensorize/pad at batch time.\n",
    "encoded_ds = encoded_ds.with_format(\"python\")\n",
    "\n",
    "print(\"   ‚úÖ Dataset successfully processed (python format; collator will pad/tensorize).\")\n",
    "\n",
    "# --------- Expose for downstream cells ---------\n",
    "DATASETS = encoded_ds\n",
    "LABEL_META = {\"names\": LABEL_NAMES, \"id2label\": ID2LABEL, \"label2id\": LABEL2ID, \"num_labels\": NUM_LABELS}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee6533-052f-48dc-b3b5-151bc72f5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 4A. MODEL SETUP WITH MEMORY OPTIMIZATION (robust + LoRA autodetect)\n",
    "# ===================================================================================\n",
    "print(\"\\nü§ñ [4/8] Building DeBERTa-v3 model with memory-optimized LoRA...\")\n",
    "\n",
    "import os, gc, torch, torch.nn as nn, transformers\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "model_name = (CONFIG.get(\"model_name\") or CONFIG.get(\"model_name_or_path\") or \"microsoft/deberta-v3-large\")\n",
    "CONFIG[\"model_name\"] = model_name\n",
    "\n",
    "# Use LABEL_META if present (from Cell 3)\n",
    "num_labels = LABEL_META[\"num_labels\"] if \"LABEL_META\" in globals() else NUM_LABELS\n",
    "id2label  = LABEL_META[\"id2label\"]  if \"LABEL_META\" in globals() else ID2LABEL\n",
    "label2id  = LABEL_META[\"label2id\"]  if \"LABEL_META\" in globals() else LABEL2ID\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "if hasattr(model.config, \"use_cache\"):\n",
    "    model.config.use_cache = False\n",
    "\n",
    "if CONFIG.get(\"gradient_checkpointing\", True):\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"   - Gradient checkpointing enabled for memory efficiency.\")\n",
    "\n",
    "if CONFIG.get(\"use_lora\", True):\n",
    "    from peft import LoraConfig, get_peft_model, TaskType\n",
    "    requested = CONFIG.get(\"lora_target_modules\") or [\"query_proj\",\"key_proj\",\"value_proj\",\"dense\"]\n",
    "    linear_names = [n for n, m in model.named_modules() if isinstance(m, nn.Linear)]\n",
    "    active = [t for t in requested if any(t in n for n in linear_names)]\n",
    "    if not active:\n",
    "        active = [t for t in [\"query_proj\",\"key_proj\",\"value_proj\"] if any(t in n for n in linear_names)]\n",
    "    if not active:\n",
    "        raise RuntimeError(\"LoRA target detection failed. Provide CONFIG['lora_target_modules'].\")\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=int(CONFIG.get(\"lora_r\", 16)),\n",
    "        lora_alpha=int(CONFIG.get(\"lora_alpha\", 32)),\n",
    "        lora_dropout=float(CONFIG.get(\"lora_dropout\", 0.05)),\n",
    "        target_modules=sorted(set(active)),\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "    os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "    model.config.save_pretrained(CONFIG[\"output_dir\"])\n",
    "    print(f\"   - LoRA applied: {sorted(set(active))}\")\n",
    "\n",
    "print(\"   ‚úÖ Model built successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855df70-b886-43e9-9168-0b35ee9dc3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4B. GENTLER BIAS INIT (fixes over-conservative predictions) ===\n",
    "import numpy as np, torch, torch.nn as nn\n",
    "\n",
    "print(\"üîß Setting gentler classifier bias...\")\n",
    "\n",
    "# 1) Get label prevalence\n",
    "train_py = DATASETS[\"train\"].with_format(\"python\")\n",
    "labels_list = [row[\"labels\"] for row in train_py]\n",
    "Y = np.asarray(labels_list, dtype=np.float32)\n",
    "del labels_list, train_py\n",
    "\n",
    "# 2) Compute per-class prior but CLIP to prevent extreme biases\n",
    "p = Y.mean(axis=0).clip(0.01, 0.5)  # ‚Üê CLIPPED to [1%, 50%] range\n",
    "prior_logits = np.log(p / (1.0 - p)).astype(np.float32)\n",
    "\n",
    "# CRITICAL: Scale down the biases to be less extreme\n",
    "prior_logits = prior_logits * 0.5  # ‚Üê Reduce strength by 50%\n",
    "\n",
    "# 3) Find the classification head\n",
    "head, head_name = None, None\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear) and getattr(module, \"out_features\", None) == Y.shape[1]:\n",
    "        head, head_name = module, name\n",
    "        break\n",
    "\n",
    "assert head is not None, \"Could not locate classification head\"\n",
    "\n",
    "# 4) Set the bias\n",
    "with torch.no_grad():\n",
    "    device = next(model.parameters()).device\n",
    "    b = torch.from_numpy(prior_logits).to(device=device, dtype=head.weight.dtype)\n",
    "    if head.bias is None:\n",
    "        head.bias = torch.nn.Parameter(torch.zeros_like(b))\n",
    "    head.bias.copy_(b)\n",
    "\n",
    "print(f\"‚úÖ Gentler bias set on '{head_name}'\")\n",
    "print(f\"   Bias range: [{prior_logits.min():.2f}, {prior_logits.max():.2f}]\")\n",
    "print(f\"   Bias mean: {prior_logits.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc04232-1f92-4068-858b-ee67a89da3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 5. TRAINER WITH MEMORY-EFFICIENT SETTINGS (FIXED for proper evaluation)\n",
    "# ===================================================================================\n",
    "print(\"\\nüìà [5/8] Configuring memory-efficient Trainer...\")\n",
    "\n",
    "import os, numpy as np, torch, torch.nn as nn\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ---------- Collator with safety checks ----------\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    pad_to_multiple_of=8,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Prune any non-tensor keys before collation\n",
    "TOKEN_KEYS = {\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"}\n",
    "def safe_collate(features):\n",
    "    pruned = [{k: v for k, v in f.items() if k in TOKEN_KEYS} for f in features]\n",
    "    return data_collator(pruned)\n",
    "\n",
    "# Check if we need the safe collator\n",
    "needed_cols = {\"input_ids\", \"attention_mask\", \"labels\"}\n",
    "train_cols = set(DATASETS[\"train\"].column_names)\n",
    "use_safe = not train_cols.issubset(needed_cols)\n",
    "trainer_collate = safe_collate if use_safe else data_collator\n",
    "\n",
    "# ---------- Metrics with SANE thresholds ----------\n",
    "# Use 0.50 for model selection (matches your ~1.2 positives/sample distribution)\n",
    "# Also log 0.30 for visibility but DON'T select on it\n",
    "THRESH_SELECT = 0.50  # For model selection - matches your data distribution\n",
    "THRESH_LOG = 0.30     # For logging only - more sensitive\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    if isinstance(eval_pred, (tuple, list)):\n",
    "        logits, labels = eval_pred\n",
    "    else:\n",
    "        logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    \n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    \n",
    "    # Primary metrics for model selection (0.50)\n",
    "    preds_50 = (probs >= THRESH_SELECT).astype(int)\n",
    "    # Secondary metrics for visibility (0.30)\n",
    "    preds_30 = (probs >= THRESH_LOG).astype(int)\n",
    "    \n",
    "    return {\n",
    "        # PRIMARY - for model selection\n",
    "        \"f1_micro\": f1_score(labels, preds_50, average=\"micro\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(labels, preds_50, average=\"macro\", zero_division=0),\n",
    "        \n",
    "        # SECONDARY - just for monitoring\n",
    "        \"f1_micro_t30\": f1_score(labels, preds_30, average=\"micro\", zero_division=0),\n",
    "        \"f1_macro_t30\": f1_score(labels, preds_30, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "# ---------- Asymmetric Loss ----------\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_neg=3.0, gamma_pos=1.0, clip=0.05, eps=1e-8, pos_alpha=2.0):\n",
    "        super().__init__()\n",
    "        self.gamma_neg = float(gamma_neg)\n",
    "        self.gamma_pos = float(gamma_pos)\n",
    "        self.clip = float(clip)\n",
    "        self.eps = float(eps)\n",
    "        self.pos_alpha = float(pos_alpha)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_sigmoid = torch.sigmoid(x)\n",
    "        xs_pos = x_sigmoid\n",
    "        xs_neg = 1 - x_sigmoid\n",
    "        if self.clip and self.clip > 0:\n",
    "            xs_neg = (xs_neg + self.clip).clamp(max=1)\n",
    "        los_pos = self.pos_alpha * y * torch.log(xs_pos.clamp(min=self.eps))\n",
    "        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n",
    "        loss = los_pos + los_neg\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            pt = xs_pos * y + xs_neg * (1 - y)\n",
    "            gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)\n",
    "            loss = loss * torch.pow(1 - pt, gamma)\n",
    "        return -loss.mean()\n",
    "\n",
    "class AsymmetricLossTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = AsymmetricLoss(\n",
    "            gamma_neg=CONFIG.get(\"asl_gamma_neg\", 3.0),\n",
    "            gamma_pos=CONFIG.get(\"asl_gamma_pos\", 1.0),\n",
    "            clip=CONFIG.get(\"asl_clip\", 0.05),\n",
    "            pos_alpha=CONFIG.get(\"asl_pos_alpha\", 2.0),\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        loss = self.loss_fct(outputs.logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# ---------- Training Arguments (FIXED) ----------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=CONFIG[\"output_dir\"],\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # Training duration\n",
    "    num_train_epochs=5,  # Full 5 epochs\n",
    "    per_device_train_batch_size=20,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=2,\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.02,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    \n",
    "    # CRITICAL FIX: Evaluate by EPOCH, not steps!\n",
    "    # This prevents premature stopping mid-epoch\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # CRITICAL FIX: Select on f1_macro at 0.50 threshold!\n",
    "    metric_for_best_model=\"f1_macro\",  # ‚Üê Uses 0.50 threshold now\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    # Memory optimization\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=False,  # As per your CONFIG\n",
    "    max_grad_norm=1.0,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    "    \n",
    "    # DataLoader\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_drop_last=True,\n",
    "    remove_unused_columns=True,\n",
    ")\n",
    "\n",
    "# ---------- Build Trainer ----------\n",
    "train_ds = DATASETS[\"train\"]\n",
    "val_ds = DATASETS[\"validation\"]\n",
    "\n",
    "# Early stopping with PATIENCE PER EPOCH (not per 500 steps!)\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "\n",
    "trainer = AsymmetricLossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=trainer_collate,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"   ‚úÖ Trainer configured correctly:\")\n",
    "print(f\"   - Evaluation: Every EPOCH (not every 500 steps)\")\n",
    "print(f\"   - Selection metric: f1_macro @ 0.50 threshold\")\n",
    "print(f\"   - Early stopping: 2 epochs patience\")\n",
    "print(f\"   - Effective batch size: {20 * 2} = 40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e98cb9-0dc4-4eb6-8e0d-f38aafe61836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5.5 Rare-label boosted sampler (optional, recommended) ===\n",
    "import numpy as np, torch\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "train_py = DATASETS[\"train\"].with_format(\"python\")\n",
    "L = LABEL_META[\"num_labels\"]\n",
    "names = LABEL_META[\"names\"]\n",
    "label2id = LABEL_META[\"label2id\"]\n",
    "neutral_idx = label2id.get(\"neutral\", None)\n",
    "\n",
    "# per-label prevalence\n",
    "sums = np.zeros(L, dtype=np.float64)\n",
    "for row in train_py:\n",
    "    sums += np.asarray(row[\"labels\"], dtype=np.float64)\n",
    "p = sums / len(train_py)\n",
    "\n",
    "# inverse frequency emphasis (don‚Äôt over-boost 'neutral')\n",
    "inv = 1.0 / np.clip(p, 1e-6, 1.0)\n",
    "if neutral_idx is not None:\n",
    "    inv[neutral_idx] = 1.0\n",
    "\n",
    "# per-sample weight = sum inv for positive labels (min 1.0), then normalize\n",
    "weights = []\n",
    "for row in train_py:\n",
    "    y = np.asarray(row[\"labels\"], dtype=np.float32)\n",
    "    w = float((y * inv).sum())\n",
    "    if w <= 0.0:\n",
    "        w = 1.0\n",
    "    weights.append(w)\n",
    "weights = np.asarray(weights, dtype=np.float64)\n",
    "weights /= weights.mean()\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    torch.as_tensor(weights, dtype=torch.double),\n",
    "    num_samples=len(weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# Patch trainer to use our sampler (python-format dataset + your collator)\n",
    "def _get_train_dataloader(self):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        DATASETS[\"train\"],\n",
    "        batch_size=int(CONFIG.get(\"per_device_train_batch_size\", 16)),\n",
    "        sampler=sampler,\n",
    "        collate_fn=data_collator,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "trainer.get_train_dataloader = _get_train_dataloader.__get__(trainer, type(trainer))\n",
    "print(\"‚úÖ Using WeightedRandomSampler (rare-label boosted).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b912cde-7075-45a7-b12e-c09fe6d7b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# DIAGNOSTIC CELL - Run this AFTER Cell 5.5 and BEFORE Cell 6\n",
    "# This will verify everything is configured correctly\n",
    "# ===================================================================================\n",
    "print(\"\\nüîç Running Pre-Training Diagnostics...\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1. Check data distribution\n",
    "val_ds = DATASETS[\"validation\"]\n",
    "train_ds = DATASETS[\"train\"]\n",
    "\n",
    "# Get label arrays safely\n",
    "Yt = np.stack([row[\"labels\"] for row in train_ds.with_format(\"python\")])\n",
    "Yv = np.stack([row[\"labels\"] for row in val_ds.with_format(\"python\")])\n",
    "\n",
    "print(\"\\nüìä Data Distribution Check:\")\n",
    "print(f\"   Train samples: {len(Yt):,}\")\n",
    "print(f\"   Val samples: {len(Yv):,}\")\n",
    "print(f\"   Positives/sample (train): {Yt.sum(axis=1).mean():.3f}\")\n",
    "print(f\"   Positives/sample (val): {Yv.sum(axis=1).mean():.3f}\")\n",
    "\n",
    "# Per-class prevalence\n",
    "prevalence = Yv.mean(axis=0)\n",
    "print(f\"\\n   Class prevalence (val):\")\n",
    "print(f\"   - Min: {prevalence.min():.4f}\")\n",
    "print(f\"   - Median: {np.median(prevalence):.4f}\")\n",
    "print(f\"   - Max: {prevalence.max():.4f}\")\n",
    "\n",
    "# 2. Check trainer configuration\n",
    "print(\"\\n‚öôÔ∏è Trainer Configuration Check:\")\n",
    "print(f\"   Evaluation strategy: {trainer.args.evaluation_strategy}\")\n",
    "print(f\"   Save strategy: {trainer.args.save_strategy}\")\n",
    "print(f\"   Metric for best model: {trainer.args.metric_for_best_model}\")\n",
    "print(f\"   Load best model at end: {trainer.args.load_best_model_at_end}\")\n",
    "print(f\"   Early stopping: Configured with patience=2\")\n",
    "\n",
    "# 3. Verify metrics configuration\n",
    "print(\"\\nüìà Metrics Configuration:\")\n",
    "# Check if these variables exist from Cell 5\n",
    "if 'THRESH_SELECT' in globals():\n",
    "    print(f\"   Selection threshold: {THRESH_SELECT}\")\n",
    "else:\n",
    "    print(f\"   Selection threshold: 0.50 (default)\")\n",
    "    \n",
    "if 'THRESH_LOG' in globals():\n",
    "    print(f\"   Logging threshold: {THRESH_LOG}\")\n",
    "else:\n",
    "    print(f\"   Logging threshold: 0.30 (default)\")\n",
    "\n",
    "# 4. Check model parameters\n",
    "try:\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nü§ñ Model Configuration:\")\n",
    "    print(f\"   Trainable params: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
    "    print(f\"   Total params: {total_params:,}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nü§ñ Model Configuration: Error - {e}\")\n",
    "\n",
    "# 5. Test a single forward pass\n",
    "print(\"\\nüß™ Testing Forward Pass:\")\n",
    "try:\n",
    "    # Create a small test batch manually\n",
    "    test_texts = [\"This is a test sentence.\"]\n",
    "    test_inputs = tokenizer(\n",
    "        test_texts, \n",
    "        truncation=True, \n",
    "        max_length=96, \n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    device = next(model.parameters()).device\n",
    "    test_inputs = {k: v.to(device) for k, v in test_inputs.items()}\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**test_inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.sigmoid(logits)\n",
    "    \n",
    "    print(f\"   ‚úì Forward pass successful\")\n",
    "    print(f\"   - Output shape: {logits.shape}\")\n",
    "    print(f\"   - Logits range: [{logits.min():.2f}, {logits.max():.2f}]\")\n",
    "    print(f\"   - Probs mean: {probs.mean():.3f}\")\n",
    "    print(f\"   - Predictions at 0.5: {(probs > 0.5).float().sum():.0f} labels\")\n",
    "    print(f\"   - Predictions at 0.3: {(probs > 0.3).float().sum():.0f} labels\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Forward pass failed: {e}\")\n",
    "\n",
    "# 6. Verify loss function\n",
    "print(\"\\nüí∞ Loss Function Check:\")\n",
    "try:\n",
    "    # Check if trainer has the custom loss\n",
    "    if hasattr(trainer, 'loss_fct'):\n",
    "        # Create dummy data\n",
    "        dummy_logits = torch.randn(4, 28).to(device)\n",
    "        dummy_labels = torch.zeros(4, 28).to(device)\n",
    "        dummy_labels[0, [0, 5, 10]] = 1  # Some positive labels\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = trainer.loss_fct(dummy_logits, dummy_labels)\n",
    "        print(f\"   ‚úì AsymmetricLoss working: {loss.item():.4f}\")\n",
    "        \n",
    "        # Check loss parameters\n",
    "        print(f\"   - gamma_neg: {trainer.loss_fct.gamma_neg}\")\n",
    "        print(f\"   - gamma_pos: {trainer.loss_fct.gamma_pos}\")\n",
    "        print(f\"   - clip: {trainer.loss_fct.clip}\")\n",
    "        print(f\"   - pos_alpha: {trainer.loss_fct.pos_alpha}\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è No custom loss function found - using default\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Loss function test failed: {e}\")\n",
    "\n",
    "# 7. Memory check\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nüíæ GPU Memory Status:\")\n",
    "    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    reserved = torch.cuda.memory_reserved() / 1e9\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"   Allocated: {allocated:.2f}GB / {total:.2f}GB ({100*allocated/total:.1f}%)\")\n",
    "    print(f\"   Reserved: {reserved:.2f}GB\")\n",
    "    print(f\"   Free: {(total - allocated):.2f}GB\")\n",
    "\n",
    "# Final readiness check\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "issues = []\n",
    "\n",
    "# Check critical settings\n",
    "if hasattr(trainer, 'args'):\n",
    "    if trainer.args.metric_for_best_model not in [\"f1_macro\", \"f1_macro_t05\"]:\n",
    "        issues.append(f\"‚ùå Metric for selection is '{trainer.args.metric_for_best_model}' (should be 'f1_macro')\")\n",
    "    if trainer.args.evaluation_strategy != \"epoch\":\n",
    "        issues.append(\"‚ùå Evaluation strategy is not 'epoch'\")\n",
    "        \n",
    "# Check data distribution\n",
    "if Yt.sum(axis=1).mean() > 2.0:\n",
    "    issues.append(\"‚ö†Ô∏è Unusual data distribution (>2 labels per sample)\")\n",
    "    \n",
    "# Check memory\n",
    "if torch.cuda.is_available() and allocated/total > 0.9:\n",
    "    issues.append(\"‚ö†Ô∏è GPU memory usage >90% before training\")\n",
    "\n",
    "if issues:\n",
    "    print(\"‚ö†Ô∏è ISSUES FOUND:\")\n",
    "    for issue in issues:\n",
    "        print(f\"   {issue}\")\n",
    "    print(\"\\n   Fix these issues before training!\")\n",
    "else:\n",
    "    print(\"‚úÖ ALL CHECKS PASSED - Ready to train!\")\n",
    "    print(\"\\n   Expected behavior:\")\n",
    "    print(\"   ‚Ä¢ Training will run for 5 epochs\")\n",
    "    print(\"   ‚Ä¢ Each epoch will take ~10-12 minutes\")\n",
    "    print(\"   ‚Ä¢ Evaluation after each epoch\")\n",
    "    print(\"   ‚Ä¢ Early stopping if no improvement for 2 epochs\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751079d-fa15-4272-a8e8-ab2502894967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 6. TRAINING (with safety checks and proper cleanup)\n",
    "# ===================================================================================\n",
    "print(\"\\nüèãÔ∏è [6/8] Starting FAST model training...\")\n",
    "\n",
    "import os, math, gc, torch\n",
    "\n",
    "# CRITICAL: Clean up any old threshold files that could contaminate metrics\n",
    "print(\"   - Cleaning up old threshold files...\")\n",
    "for filename in [\"val_thresholds.npy\", \"val_thresholds.json\", \"optimal_thresholds.json\"]:\n",
    "    filepath = os.path.join(CONFIG[\"output_dir\"], filename)\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            os.remove(filepath)\n",
    "            print(f\"     ‚úì Removed old {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"     ‚ö†Ô∏è Could not remove {filename}: {e}\")\n",
    "\n",
    "# Also check best_model directory\n",
    "best_model_dir = os.path.join(CONFIG[\"output_dir\"], \"best_model\")\n",
    "if os.path.exists(best_model_dir):\n",
    "    threshold_file = os.path.join(best_model_dir, \"optimal_thresholds.json\")\n",
    "    if os.path.exists(threshold_file):\n",
    "        try:\n",
    "            os.remove(threshold_file)\n",
    "            print(f\"     ‚úì Removed old best_model/optimal_thresholds.json\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "train_ds = DATASETS[\"train\"]\n",
    "\n",
    "# Calculate training statistics\n",
    "num_epochs = 5  # Full 5 epochs as configured\n",
    "train_bs = 20    # Per device batch size\n",
    "grad_accum = 2   # Gradient accumulation steps\n",
    "\n",
    "steps_per_epoch = max(1, math.ceil(len(train_ds) / train_bs / grad_accum))\n",
    "total_steps_est = int(steps_per_epoch * num_epochs)\n",
    "\n",
    "print(f\"\\n   üìä Training Statistics:\")\n",
    "print(f\"   - Dataset size: {len(train_ds):,} samples\")\n",
    "print(f\"   - Batch size: {train_bs} √ó {grad_accum} = {train_bs * grad_accum} effective\")\n",
    "print(f\"   - Steps/epoch: {steps_per_epoch:,}\")\n",
    "print(f\"   - Total steps: {total_steps_est:,} ({num_epochs} epochs)\")\n",
    "print(f\"   - Evaluation: After each epoch (not every 500 steps!)\")\n",
    "\n",
    "# Memory cleanup before training\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    # Show GPU memory status\n",
    "    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    reserved = torch.cuda.memory_reserved() / 1e9\n",
    "    print(f\"\\n   üéÆ GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved\")\n",
    "\n",
    "# Start training (NO resume from checkpoint - fresh start)\n",
    "print(f\"\\n   üöÄ Starting training from scratch...\")\n",
    "print(f\"   ‚è∞ Estimated time: ~50-60 minutes for 5 epochs\")\n",
    "\n",
    "train_result = trainer.train(resume_from_checkpoint=False)\n",
    "\n",
    "print(\"\\n   üéâ Training finished successfully!\")\n",
    "print(\"   - Final Metrics:\", train_result.metrics)\n",
    "\n",
    "# Save the best model\n",
    "best_model_path = os.path.join(CONFIG[\"output_dir\"], \"best_model\")\n",
    "os.makedirs(best_model_path, exist_ok=True)\n",
    "model.save_pretrained(best_model_path)\n",
    "tokenizer.save_pretrained(best_model_path)\n",
    "print(f\"   - Best model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7419af-3010-45fa-b178-210fdab56dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8f486-086f-4e4c-b395-9a737d1277e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ANYTIME after DATASETS/encoded_ds exist\n",
    "import numpy as np\n",
    "val_ds = DATASETS[\"validation\"] if \"DATASETS\" in globals() else encoded_ds[\"validation\"]\n",
    "train_ds = DATASETS[\"train\"] if \"DATASETS\" in globals() else encoded_ds[\"train\"]\n",
    "\n",
    "Yt = np.stack(train_ds[\"labels\"])\n",
    "Yv = np.stack(val_ds[\"labels\"])\n",
    "print(\"Positives per sample -> train:\", Yt.mean(axis=1).mean().round(3), \" | val:\", Yv.mean(axis=1).mean().round(3))\n",
    "print(\"Per-class prevalence (val) min/median/max:\",\n",
    "      float(Yv.mean(axis=0).min()), float(np.median(Yv.mean(axis=0))), float(Yv.mean(axis=0).max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dfb1c-8ffc-4e91-8c34-7a42c7a5aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6.1 VAL DIAGNOSTICS ===\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "val_ds = DATASETS[\"validation\"] if \"DATASETS\" in globals() else encoded_ds[\"validation\"]\n",
    "pred = trainer.predict(val_ds)\n",
    "logits = pred.predictions\n",
    "labels = pred.label_ids.astype(int)\n",
    "probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "true_pps = labels.sum() / labels.shape[0]   # avg positives per sample (truth)\n",
    "pred_pps_05 = (probs >= 0.5).sum() / labels.shape[0]  # avg positives/sample @0.5\n",
    "\n",
    "print(f\"Avg true positives/sample: {true_pps:.3f}\")\n",
    "print(f\"Avg preds/sample @0.5:     {pred_pps_05:.3f}\")\n",
    "\n",
    "# Per-class F1 @ 0.5 to spot dead classes\n",
    "preds05 = (probs >= 0.5).astype(int)\n",
    "per_class_f1 = []\n",
    "for j, name in enumerate(LABEL_META[\"names\"] if \"LABEL_META\" in globals() else LABEL_NAMES):\n",
    "    f = f1_score(labels[:, j], preds05[:, j], zero_division=0)\n",
    "    per_class_f1.append((name, float(f), float(labels[:, j].mean())))\n",
    "per_class_f1_sorted = sorted(per_class_f1, key=lambda x: x[1])\n",
    "print(\"\\nWorst 10 classes @0.5 threshold (name, f1, prevalence):\")\n",
    "for name, f, prev in per_class_f1_sorted[:10]:\n",
    "    print(f\"{name:14s}  f1={f:0.3f}  prev={prev:0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d2cc0-ec01-465a-9d0b-35048121e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 7. THRESHOLD OPTIMIZATION (self-contained + robust)\n",
    "# ===================================================================================\n",
    "print(\"\\nüîç [7/8] Optimizing per-label decision thresholds...\")\n",
    "\n",
    "import os, gc, json, numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "val_ds = DATASETS[\"validation\"] if \"DATASETS\" in globals() else encoded_ds[\"validation\"]\n",
    "\n",
    "print(\"   - Predicting on the validation set...\")\n",
    "pred = trainer.predict(val_ds)\n",
    "logits = pred.predictions\n",
    "labels = pred.label_ids.astype(int)\n",
    "probs  = 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "if \"LABEL_META\" in globals():\n",
    "    label_names = LABEL_META[\"names\"]\n",
    "    num_labels  = LABEL_META[\"num_labels\"]\n",
    "else:\n",
    "    label_names = LABEL_NAMES\n",
    "    num_labels  = len(label_names)\n",
    "\n",
    "base_preds = (probs >= 0.5).astype(int)\n",
    "base_f1_micro = f1_score(labels, base_preds, average=\"micro\", zero_division=0)\n",
    "base_f1_macro = f1_score(labels, base_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"   - Searching best F1 threshold per label...\")\n",
    "grid = np.linspace(0.05, 0.60, 12)\n",
    "optimal_thresholds = np.full(num_labels, 0.5, dtype=np.float32)\n",
    "\n",
    "for j in range(num_labels):\n",
    "    y = labels[:, j]\n",
    "    if y.sum() == 0:\n",
    "        continue\n",
    "    pj = probs[:, j]\n",
    "    fmax, tbest = -1.0, 0.5\n",
    "    for t in grid:\n",
    "        f = f1_score(y, (pj >= t).astype(int), zero_division=0)\n",
    "        if f > fmax:\n",
    "            fmax, tbest = f, t\n",
    "    optimal_thresholds[j] = tbest\n",
    "\n",
    "tuned_preds = (probs >= optimal_thresholds.reshape(1, -1)).astype(int)\n",
    "tuned_f1_micro = f1_score(labels, tuned_preds, average=\"micro\", zero_division=0)\n",
    "tuned_f1_macro = f1_score(labels, tuned_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"\\n--- Validation (0.5 vs tuned thresholds) ---\")\n",
    "print(f\"   F1 Micro @0.5 : {base_f1_micro:.4f}\")\n",
    "print(f\"   F1 Macro @0.5 : {base_f1_macro:.4f}\")\n",
    "print(f\"   F1 Micro tuned: {tuned_f1_micro:.4f}\")\n",
    "print(f\"   F1 Macro tuned: {tuned_f1_macro:.4f}\")\n",
    "if \"neutral\" in label_names:\n",
    "    idx = [i for i, n in enumerate(label_names) if n != \"neutral\"]\n",
    "    f1_macro_no_neutral = f1_score(labels[:, idx], tuned_preds[:, idx], average=\"macro\", zero_division=0)\n",
    "    print(f\"   F1 Macro tuned (no 'neutral'): {f1_macro_no_neutral:.4f}\")\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "np.save(os.path.join(CONFIG[\"output_dir\"], \"val_thresholds.npy\"), optimal_thresholds)\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"val_thresholds.json\"), \"w\") as f:\n",
    "    json.dump(optimal_thresholds.tolist(), f)\n",
    "\n",
    "best_dir = os.path.join(CONFIG[\"output_dir\"], \"best_model\")\n",
    "os.makedirs(best_dir, exist_ok=True)\n",
    "with open(os.path.join(best_dir, \"optimal_thresholds.json\"), \"w\") as f:\n",
    "    json.dump(optimal_thresholds.tolist(), f)\n",
    "\n",
    "print(\"   ‚úÖ Thresholds saved: val_thresholds.npy/json and best_model/optimal_thresholds.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da70ece-0953-427f-9466-709c5f0f5c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# 8. INFERENCE DEMO\n",
    "# ===================================================================================\n",
    "print(\"\\nüéØ [8/8] Running inference demo...\")\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "# Clear memory for inference\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "final_model_path = os.path.join(CONFIG[\"output_dir\"], \"best_model\")\n",
    "with open(os.path.join(final_model_path, \"optimal_thresholds.json\")) as f:\n",
    "    final_thresholds = np.array(json.load(f))\n",
    "\n",
    "# Load model for inference\n",
    "print(\"   - Loading model for inference...\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    CONFIG[\"model_name\"],\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    id2label=ID2LABEL,\n",
    "    label2id=LABEL2ID,\n",
    "    # Don't force dtype\n",
    ")\n",
    "\n",
    "inference_model = PeftModel.from_pretrained(base_model, final_model_path)\n",
    "inference_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inference_model.to(device)\n",
    "\n",
    "test_texts = [\n",
    "    \"I'm so happy and grateful for this amazing day!\",\n",
    "    \"This is really frustrating and annoying.\",\n",
    "    \"I feel a bit anxious but also excited about tomorrow.\",\n",
    "    \"The weather is nice today.\",\n",
    "]\n",
    "\n",
    "print(\"\\n--- Inference Results ---\")\n",
    "with torch.no_grad():\n",
    "    for text in test_texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, \n",
    "                          max_length=CONFIG[\"max_length\"], padding=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        outputs = inference_model(**inputs)\n",
    "        probs = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
    "        \n",
    "        detected_emotions = [LABEL_NAMES[i] for i, p in enumerate(probs) \n",
    "                           if p > final_thresholds[i]]\n",
    "        \n",
    "        top_indices = np.argsort(probs)[-3:][::-1]\n",
    "        top_scores = {LABEL_NAMES[i]: f\"{probs[i]:.3f}\" for i in top_indices}\n",
    "        \n",
    "        print(f\"\\nText: \\\"{text}\\\"\")\n",
    "        print(f\"   -> Top: {top_scores}\")\n",
    "        print(f\"   -> Detected: {detected_emotions if detected_emotions else ['none']}\")\n",
    "\n",
    "print(\"\\n‚úÖ All steps completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4af42-7928-4b50-8811-eeee170b3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7B. Diagnostics ===\n",
    "import numpy as np\n",
    "val_ds = DATASETS[\"validation\"] if \"DATASETS\" in globals() else encoded_ds[\"validation\"]\n",
    "Yv = np.stack(val_ds[\"labels\"])\n",
    "pred = trainer.predict(val_ds)\n",
    "probs = 1/(1+np.exp(-pred.predictions))\n",
    "print(\"Positives per sample (truth):\", Yv.sum(axis=1).mean().round(3))\n",
    "print(\"Positives per sample @0.3  :\", (probs>=0.3).sum(axis=1).mean().round(3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
